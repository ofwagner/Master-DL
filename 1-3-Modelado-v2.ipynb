{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Campaña \"Seguro Vivienda\" de compañía financiera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEWCAYAAABfdFHAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHfhJREFUeJzt3XuYHVWd7vHvS0AU5WpaDAFMQHAO6hglIl5ARhQQHAFHNNEBBjlGFJ7xrjCeGZE5ePDKkVFBkAygXEQRyaM4Gj0qjiNCghHCTQJGaZJJoig3EUl8zx+1GorO7k6n02vvdPN+nmc/XXvVqqpfFU2/qVW1a8s2ERERtWzS6wIiImJiS9BERERVCZqIiKgqQRMREVUlaCIioqoETUREVJWgidiISNpPUv8w88+S9M8buI1pkixp0w1ZT8RIJWhi3JI0S9LPJD0gaWWZfockbeB6fyjpf45y2e9IOqVD+6GS/ntD/7jbPs72v27IOiK6LUET45Kk9wKfAT4BPB3YHjgOeCnwhB6Wdh5wZIewOxK40Pbq7pcU0VsJmhh3JG0NnAK8w/bXbN/nxs9tv9n2Q6XfIZJ+LuleSXdKOrm1jidK+rKk30n6g6RrJW0v6VRgH+Czku6X9NnS/yWlzz3l50uGKO8bwHZlHQPb2hZ4DXBBeb+5pE9K+o2kFWU47EmD9vG95SxtuaRjWu3nSfrfrfeHSlpU9vF2SQeV9qWSXtnqd7KkLw9xPHeQNE/S3ZKWSHpra95ekhaU9a+Q9Onh/ttEdJKgifHoxcDmwBXr6PcAcBSwDXAI8HZJh5V5RwNbAzsBT6U5G3rQ9oeAHwMn2H6K7RMkbQd8Czij9P008C1JTx28QdsPApeW7Q54A3CL7V+U9x8DdgdmAM8EpgL/0ur/9FLbVOBY4HMlrB5D0l404fX+so/7AkvXcUw6uRjoB3YAXg98VNL+Zd5ngM/Y3grYtexbxHpJ0MR4NBn4bXsYStJ/lTOTByXtC2D7h7ZvsP0X29fT/EF9eVnkYZrQeKbtNbYX2r53iO0dAtxm+0u2V9u+GLgF+Nsh+p8PHNE6SzmqtFGG1N4KvNv23bbvAz4KzGot/zBwiu2HbV8J3A88q8N2jgXm2p5f9vEu27cMddA6kbQT8DLgg7b/ZHsR8EWaob6BWp4pabLt+21fvT7rj4AETYxPvwMmty+s236J7W3KvE0AJL1I0g8krZJ0D81Zy+SyyJeA7wCXSFom6eOSNhtiezsAvx7U9muaM4612P5PYBVwqKRdgBcCF5XZfcAWwMISjH8A/qO0P7J/g67l/BF4SodN7QTcPkTNI7UDMBB4A9r7dizN2dctZcjwNRu4vXgcStDEePRT4CHg0HX0uwiYB+xke2vgLEAA5WzhI7b3AF5Ccw1lYLhr8CPNlwHPGNS2M3DXMNu+oKzvSOC7tleU9t8CDwLPtr1NeW1tu1OQrMudNMNZnTxAE2gDnj5Ev2XAdpK2bLU9sm+2b7M9G3gazZDf1yQ9eRS1xuNYgibGHdt/AD4CfF7S6yU9RdImkmYA7T+CW9L8a/1P5XrGmwZmSPobSc+VNAm4l2aIaE2ZvQLYpbWeK4HdJb1J0qaS3gjsAXxzmDIvAF5JM0x2fqv2vwDnAKdLelqpZaqkA0dxKM4FjpG0f9n/qZL+qsxbBMyStJmkmTTXXtZi+07gv4D/U26Q+Guas5gLS21/L6mv1P2HstiaTuuKGEqCJsYl2x8H3gN8AFhJEw5fAD5I84cT4B3AKZLuo7nY3r6Q/XTgazQhczPwI2DgrqzPAK+X9HtJZ9j+Hc0Zz3tphuY+ALzG9m+HqW9pqePJNGdVbR8ElgBXS7oX+B6dr8EMy/Y1wDHA6cA9ZR8Gzrz+meZs5/c0oXxRp3UUs4FpNGc3lwMftj2/zDsIuFHS/TTHZZbtP61vrfH4pnzxWURE1JQzmoiIqCpBExERVSVoIiKiqgRNRERUNWEfEz558mRPmzat12VERIwbCxcu/K3tvnX3XD8TNmimTZvGggULel1GRMS4IWnwEzDGRIbOIiKiqgRNRERUlaCJiIiqEjQREVFVgiYiIqpK0ERERFUJmoiIqCpBExERVSVoIiKiqgn7ZIANMe3Eb/Vku0tPO6Qn242IqClnNBERUVWCJiIiqkrQREREVQmaiIioKkETERFVJWgiIqKqBE1ERFRVLWgkzZW0UtLiVttXJC0qr6WSFpX2aZIebM07q7XMnpJukLRE0hmSVKvmiIgYezU/sHke8FnggoEG228cmJb0KeCeVv/bbc/osJ4zgTnA1cCVwEHAtyvUGxERFVQ7o7F9FXB3p3nlrOQNwMXDrUPSFGAr2z+1bZrQOmysa42IiHp6dY1mH2CF7dtabdMl/VzSjyTtU9qmAv2tPv2lrSNJcyQtkLRg1apVY191RESst14FzWweezazHNjZ9vOB9wAXSdoK6HQ9xkOt1PbZtmfantnX1zemBUdExOh0/aGakjYFXgfsOdBm+yHgoTK9UNLtwO40ZzA7thbfEVjWvWojImJD9eKM5pXALbYfGRKT1CdpUpneBdgNuMP2cuA+SXuX6zpHAVf0oOaIiBilmrc3Xwz8FHiWpH5Jx5ZZs1j7JoB9gesl/QL4GnCc7YEbCd4OfBFYAtxO7jiLiBhXqg2d2Z49RPs/dGi7DLhsiP4LgOeMaXEREdE1eTJARERUlaCJiIiqEjQREVFVgiYiIqpK0ERERFUJmoiIqCpBExERVSVoIiKiqgRNRERUlaCJiIiqEjQREVFVgiYiIqpK0ERERFUJmoiIqCpBExERVSVoIiKiqgRNRERUlaCJiIiqEjQREVFVtaCRNFfSSkmLW20nS7pL0qLyOrg17yRJSyTdKunAVvtBpW2JpBNr1RsREXXUPKM5DzioQ/vptmeU15UAkvYAZgHPLst8XtIkSZOAzwGvBvYAZpe+ERExTmxaa8W2r5I0bYTdDwUusf0Q8CtJS4C9yrwltu8AkHRJ6XvTGJcbERGV9OIazQmSri9Da9uWtqnAna0+/aVtqPaOJM2RtEDSglWrVo113RERMQrdDpozgV2BGcBy4FOlXR36epj2jmyfbXum7Zl9fX0bWmtERIyBakNnndheMTAt6Rzgm+VtP7BTq+uOwLIyPVR7RESMA109o5E0pfX2cGDgjrR5wCxJm0uaDuwGXANcC+wmabqkJ9DcMDCvmzVHRMSGqXZGI+liYD9gsqR+4MPAfpJm0Ax/LQXeBmD7RkmX0lzkXw0cb3tNWc8JwHeAScBc2zfWqjkiIsZezbvOZndoPneY/qcCp3ZovxK4cgxLi4iILsqTASIioqoETUREVJWgiYiIqhI0ERFRVYImIiKqStBERERVCZqIiKgqQRMREVUlaCIioqoETUREVJWgiYiIqhI0ERFRVYImIiKqStBERERVCZqIiKgqQRMREVUlaCIioqoETUREVJWgiYiIqqoFjaS5klZKWtxq+4SkWyRdL+lySduU9mmSHpS0qLzOai2zp6QbJC2RdIYk1ao5IiLGXs0zmvOAgwa1zQeeY/uvgV8CJ7Xm3W57Rnkd12o/E5gD7FZeg9cZEREbsWpBY/sq4O5Bbd+1vbq8vRrYcbh1SJoCbGX7p7YNXAAcVqPeiIioo5fXaN4CfLv1frqkn0v6kaR9SttUoL/Vp7+0dSRpjqQFkhasWrVq7CuOiIj11pOgkfQhYDVwYWlaDuxs+/nAe4CLJG0FdLoe46HWa/ts2zNtz+zr6xvrsiMiYhQ27fYGJR0NvAbYvwyHYfsh4KEyvVDS7cDuNGcw7eG1HYFl3a04IiI2RFfPaCQdBHwQeK3tP7ba+yRNKtO70Fz0v8P2cuA+SXuXu82OAq7oZs0REbFhqp3RSLoY2A+YLKkf+DDNXWabA/PLXcpXlzvM9gVOkbQaWAMcZ3vgRoK309zB9iSaazrt6zoREbGRqxY0tmd3aD53iL6XAZcNMW8B8JwxLC0iIrooTwaIiIiqEjQREVFVgiYiIqpK0ERERFUJmoiIqCpBExERVSVoIiKiqgRNRERUlaCJiIiqEjQREVFVgiYiIqpK0ERERFUJmoiIqCpBExERVY0oaCTtKmnzMr2fpH+UtE3d0iIiYiIY6RnNZcAaSc+k+U6Z6cBF1aqKiIgJY6RB8xfbq4HDgf9r+93AlHplRUTERDHSoHlY0mzgaOCbpW2zOiVFRMREMtKgOQZ4MXCq7V9Jmg58uV5ZERExUYwoaGzfBLwPuEHSc4B+26etazlJcyWtlLS41badpPmSbis/ty3tknSGpCWSrpf0gtYyR5f+t0k6er33MiIiemakd53tB9wGfA74PPBLSfuOYNHzgIMGtZ0IfN/2bsD3y3uAVwO7ldcc4Myy7e2ADwMvAvYCPjwQThERsfEb6dDZp4ADbL/c9r7AgcDp61rI9lXA3YOaDwXOL9PnA4e12i9w42pgG0lTyrbm277b9u+B+awdXhERsZEaadBsZvvWgTe2f8nobwbY3vbysp7lwNNK+1Tgzla//tI2VPtaJM2RtEDSglWrVo2yvIiIGEsjDZoFks4tH9bcT9I5wMIxrkUd2jxM+9qN9tm2Z9qe2dfXN6bFRUTE6Iw0aN4O3Aj8I/BO4CbguFFuc0UZEqP8XFna+4GdWv12BJYN0x4REePAOoNG0iTgXNuftv0624fbPt32Q6Pc5jyaz+NQfl7Raj+q3H22N3BPGVr7DnCApG3LTQAHlLaIiBgHNl1XB9trJPVJeoLtP6/PyiVdDOwHTJbUT3P32GnApZKOBX4DHFG6XwkcDCwB/kjz2R1s3y3pX4FrS79TbA++wSAiIjZS6wyaYinwE0nzgAcGGm1/eriFbM8eYtb+HfoaOH6I9cwF5o6w1oiI2IiMNGiWldcmwJb1yomIiIlmREFj+yO1C4mIiIlpREEj6Qd0uKXY9ivGvKKIiJhQRjp09r7W9BOBvwNWj305EREx0Yx06GzwhzN/IulHFeqJiIgJZqRDZ9u13m4C7Ak8vUpFERExoYx06Gwhjz4OZjXwK+DYWkVFRMTEMdKhs+m1C4mIiIlp2EfQSPpAa/qIQfM+WquoiIiYONb1rLNZremTBs3Ld8JERMQ6rStoNMR0p/cRERFrWVfQeIjpTu8jIiLWsq6bAZ4n6V6as5cnlWnK+ydWrSwiIiaEYYPG9qRuFRIRERPTSL9hMyIiYlQSNBERUVWCJiIiqkrQREREVQmaiIioqutBI+lZkha1XvdKepekkyXd1Wo/uLXMSZKWSLpV0oHdrjkiIkZvpE9vHjO2bwVmAEiaBNwFXA4cA5xu+5Pt/pL2oHkUzrOBHYDvSdrd9pquFh4REaPS66Gz/YHbbf96mD6HApfYfsj2r4AlwF5dqS4iIjZYr4NmFnBx6/0Jkq6XNFfStqVtKnBnq09/aVuLpDmSFkhasGrVqjoVR0TEeulZ0Eh6AvBa4Kul6UxgV5phteXApwa6dli843PWbJ9te6btmX19fWNccUREjEYvz2heDVxnewWA7RW219j+C3AOjw6P9QM7tZbbEVjW1UojImLUehk0s2kNm0ma0pp3OLC4TM8DZknaXNJ0YDfgmq5VGRERG6Trd50BSNoCeBXwtlbzxyXNoBkWWzowz/aNki4FbgJWA8fnjrOIiPGjJ0Fj+4/AUwe1HTlM/1OBU2vXFRERY6/Xd51FRMQEl6CJiIiqEjQREVFVgiYiIqpK0ERERFUJmoiIqCpBExERVSVoIiKiqgRNRERUlaCJiIiqEjQREVFVgiYiIqpK0ERERFUJmoiIqCpBExERVSVoIiKiqgRNRERUlaCJiIiqEjQREVFVz4JG0lJJN0haJGlBadtO0nxJt5Wf25Z2STpD0hJJ10t6Qa/qjoiI9dPrM5q/sT3D9szy/kTg+7Z3A75f3gO8GtitvOYAZ3a90oiIGJVeB81ghwLnl+nzgcNa7Re4cTWwjaQpvSgwIiLWz6Y93LaB70oy8AXbZwPb214OYHu5pKeVvlOBO1vL9pe25e0VSppDc8bDzjvvXLn8iWXaid/qyXaXnnZIT7YbEd3Ty6B5qe1lJUzmS7plmL7q0Oa1GpqwOhtg5syZa82PiIju69nQme1l5edK4HJgL2DFwJBY+bmydO8HdmotviOwrHvVRkTEaPUkaCQ9WdKWA9PAAcBiYB5wdOl2NHBFmZ4HHFXuPtsbuGdgiC0iIjZuvRo62x64XNJADRfZ/g9J1wKXSjoW+A1wROl/JXAwsAT4I3BM90uOiIjR6EnQ2L4DeF6H9t8B+3doN3B8F0rrqV5dkI+IqGlju705IiImmARNRERUlaCJiIiqEjQREVFVgiYiIqpK0ERERFUJmoiIqCpBExERVSVoIiKiqgRNRERUlaCJiIiqEjQREVFVgiYiIqpK0ERERFUJmoiIqCpBExERVSVoIiKiqgRNRERUlaCJiIiquh40knaS9ANJN0u6UdI7S/vJku6StKi8Dm4tc5KkJZJulXRgt2uOiIjR27QH21wNvNf2dZK2BBZKml/mnW77k+3OkvYAZgHPBnYAvidpd9trulp1RESMStfPaGwvt31dmb4PuBmYOswihwKX2H7I9q+AJcBe9SuNiIix0NNrNJKmAc8HflaaTpB0vaS5krYtbVOBO1uL9TNEMEmaI2mBpAWrVq2qVHVERKyPngWNpKcAlwHvsn0vcCawKzADWA58aqBrh8XdaZ22z7Y90/bMvr6+ClVHRMT66knQSNqMJmQutP11ANsrbK+x/RfgHB4dHusHdmotviOwrJv1RkTE6PXirjMB5wI32/50q31Kq9vhwOIyPQ+YJWlzSdOB3YBrulVvRERsmF7cdfZS4EjgBkmLSts/AbMlzaAZFlsKvA3A9o2SLgVuorlj7fjccRYRMX50PWhs/yedr7tcOcwypwKnVisqIiKqyZMBIiKiqgRNRERUlaCJiIiqEjQREVFVgiYiIqpK0ERERFUJmoiIqCpBExERVSVoIiKiqgRNRERUlaCJiIiqEjQREVFVgiYiIqpK0ERERFUJmoiIqKoXX3wW8YhpJ36rZ9teetohPdt2xONJzmgiIqKqnNHE41avzqZyJhWPNzmjiYiIqsZN0Eg6SNKtkpZIOrHX9URExMiMi6EzSZOAzwGvAvqBayXNs31TbyuLWH8ZsovHm3ERNMBewBLbdwBIugQ4FEjQRIxQ7vCLXhkvQTMVuLP1vh940eBOkuYAc8rb+yXdOsrtTQZ+O8ple2U81gzjs+7xWDP0sG59bNSL5lh3z2TgGTVWPF6CRh3avFaDfTZw9gZvTFpge+aGrqebxmPNMD7rHo81w/isezzWDOOz7lLztBrrHi83A/QDO7Xe7wgs61EtERGxHsZL0FwL7CZpuqQnALOAeT2uKSIiRmBcDJ3ZXi3pBOA7wCRgru0bK25yg4ffemA81gzjs+7xWDOMz7rHY80wPuuuVrPstS51REREjJnxMnQWERHjVIImIiKqStC0bEyPuZG0k6QfSLpZ0o2S3lnaT5Z0l6RF5XVwa5mTSu23Sjqw1d7V/ZK0VNINpb4FpW07SfMl3VZ+blvaJemMUtv1kl7QWs/Rpf9tko6uWO+zWsdzkaR7Jb1rYzzWkuZKWilpcattzI6tpD3Lf7slZdlOHy0Yi5o/IemWUtflkrYp7dMkPdg65metq7ah9r9S3WP2O6Hm5qaflbq/ouZGpxo1f6VV71JJi0p794617bya61STgNuBXYAnAL8A9uhhPVOAF5TpLYFfAnsAJwPv69B/j1Lz5sD0si+TerFfwFJg8qC2jwMnlukTgY+V6YOBb9N8Vmpv4GelfTvgjvJz2zK9bZd+D/6b5oNrG92xBvYFXgAsrnFsgWuAF5dlvg28ulLNBwCblumPtWqe1u43aD0daxtq/yvVPWa/E8ClwKwyfRbw9ho1D5r/KeBfun2sc0bzqEcec2P7z8DAY256wvZy29eV6fuAm2mekDCUQ4FLbD9k+1fAEpp92lj261Dg/DJ9PnBYq/0CN64GtpE0BTgQmG/7btu/B+YDB3Whzv2B223/epg+PTvWtq8C7u5QzwYf2zJvK9s/dfOX5ILWusa0Ztvftb26vL2a5rNxQ1pHbUPt/5jXPYz1+p0oZwivAL42lnUPV3PZ5huAi4dbR41jnaB5VKfH3Az3h71rJE0Dng/8rDSdUIYc5rZOXYeqvxf7ZeC7khaqeSwQwPa2l0MTosDTSvvGVDc0n9Fq/4+4sR9rGLtjO7VMD26v7S00/2oeMF3SzyX9SNI+pW242oba/1rG4nfiqcAfWmHbjWO9D7DC9m2ttq4c6wTNo0b0mJtuk/QU4DLgXbbvBc4EdgVmAMtpToVh6Pp7sV8vtf0C4NXA8ZL2HabvRlN3GSN/LfDV0jQejvVw1rfOXhzzDwGrgQtL03JgZ9vPB94DXCRpq17UNoSx+p3oxf7M5rH/iOrasU7QPGqje8yNpM1oQuZC218HsL3C9hrbfwHOoTk1h6Hr7/p+2V5Wfq4ELi81riin5AOn5is3trppgvE62ytgfBzrYqyObT+PHcKqWn+5CeE1wJvLEA1l6Ol3ZXohzfWN3ddR21D7P+bG8HfitzRDmZsOaq+ibOd1wFcG2rp5rBM0j9qoHnNTxlPPBW62/elW+5RWt8OBgbtL5gGzJG0uaTqwG80Fva7ul6QnS9pyYJrmou/iss2Bu5uOBq5o1X2UGnsD95RT8u8AB0jatgxPHFDaanrMv/g29mPdMibHtsy7T9Le5ffvqNa6xpSkg4APAq+1/cdWe5+a759C0i40x/aOddQ21P7XqHtMfidKsP4AeH036gZeCdxi+5Ehsa4e69He3TARXzR36fySJtk/1ONaXkZzuno9sKi8Dga+BNxQ2ucBU1rLfKjUfiutu4W6uV80d9f8orxuHNgezZj094Hbys/tSrtovtTu9rJfM1vregvNRdUlwDGV694C+B2wdattozvWNEG4HHiY5l+ex47lsQVm0vzxvB34LOXpIRVqXkJz7WLgd/us0vfvyu/NL4DrgL9dV21D7X+lusfsd6L8v3JNORZfBTavUXNpPw84blDfrh3rPIImIiKqytBZRERUlaCJiIiqEjQREVFVgiYiIqpK0ERERFUJmpiQJG0v6SJJd5RH4fxU0uGjXNc/rWf/8yS9bVDbYZKuXMdy9w/Rfpyko9anhtayP5Q0czTLRoyVBE1MOOVDZt8ArrK9i+09aT4oN+yDG4exXkFD81mGWYPaBj9DbcRsn2X7gtEsG7ExSNDERPQK4M+2H/l+Ddu/tv1v8Mj3cPxY0nXl9ZLSPkXSVWq+m2OxpH0knQY8qbRdWPq9p8xfLOldHbb/PeCvWo/q2ILmk9nfKO//XtI1ZZ1fGPh0dpl3qqRfSLpa0val7WRJ7yvTz5T0vdLnOkm7StpP0jdb6/ispH8YXJSk2Wq+Y2SxpI+VtknlDGxxmffuDTjuER0laGIiejbNJ52HshJ4lZsHf74ROKO0v4nmUSwzgOcBi2yfCDxoe4btN0vaEzgGeBHNd7y8VdLz2yu3vQb4Os0j2aF5UOcPbN8n6X+Ubb60bGcN8ObS78nA1bafB1wFvLVD7RcCnyt9XkLzKfB1krQDzfe+vILmgZAvlHRYmZ5q+zm2nwv8+0jWF7E+EjQx4Un6XDkDuLY0bQacI+kGmkd/7FHarwWOkXQy8Fw33wM02MuAy20/YPt+mkDZp0O/9vBZe9hsf2BP4Fo133S4P82jSAD+DAycmSyk+WKq9n5sSRMKlwPY/pNbzwlbhxcCP7S9ys2j6S+k+ZKsO4BdJP1bef7YvSNcX8SIJWhiIrqR5lsGAbB9PM0f9L7S9G5gBc1Zy0yabz7EzZdG7QvcBXxpiAvwI/1q458AUyQNnHkM3Agg4PxyhjTD9rNsn1zmPexHnwm1BtiUxxpq26t57P/LTxxp3W6++Ox5wA+B44EvDrlHEaOUoImJ6P8BT5T09lbbFq3prYHlbh71fiTN1+0i6RnAStvn0Dw5eyCsHlbzlQ3QDGkdJmkLNU+nPhz48eACSmBcSvMthFfa/lOZ9X3g9ZKeVra5XdnuOrn5PqL+MuRFeVLwFsCvgT3K+61pQnWwnwEvlzS5XBOaDfxI0mRgE9uXAf/c2ueIMTP4X0wR455tlz/Gp0v6ALAKeIDmsfQAnwcuk3QEzaPaHyjt+wHvl/QwcD/N49EBzgaul3RduU5zHs1TdwG+aPvnQ5RyMfB+mu9WH6jtJkn/i+YbSDehecru8TRhMRJHAl+QdEpZ9gjbd0i6lOaJwrcBa9Vje7mkk8r+iib8rihnXP9eagE4aYR1RIxYnt4cERFVZegsIiKqStBERERVCZqIiKgqQRMREVUlaCIioqoETUREVJWgiYiIqv4/NIN8hksrN5IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2927 entries, 0 to 2926\n",
      "Data columns (total 28 columns):\n",
      "ID_Cliente                             2927 non-null object\n",
      "Fecha_Nacimiento                       2927 non-null object\n",
      "Fecha_Alta                             2927 non-null object\n",
      "Sexo                                   2927 non-null object\n",
      "ID_Zona                                2927 non-null object\n",
      "Productos_Vida                         2927 non-null int64\n",
      "Productos_Vehiculos                    2927 non-null int64\n",
      "Productos_Otros                        2927 non-null int64\n",
      "Gasto_Vida                             2927 non-null float64\n",
      "Gasto_Vehiculos                        2927 non-null float64\n",
      "Gasto_Otros                            2927 non-null float64\n",
      "Tipo_Familia                           2927 non-null float64\n",
      "Tipo_Pareja                            2927 non-null float64\n",
      "Tipo_Soltero                           2927 non-null float64\n",
      "Educacion_Superior                     2927 non-null float64\n",
      "Educacion_Media                        2927 non-null float64\n",
      "Educacion_Baja                         2927 non-null float64\n",
      "Poblacion_Empresario                   2927 non-null float64\n",
      "Poblacion_Funcionario                  2927 non-null float64\n",
      "Poblacion_Trabajador_Cualificado       2927 non-null float64\n",
      "Poblacion_Trabajador_No_Cualificado    2927 non-null float64\n",
      "Vivienda_Propiedad                     2927 non-null float64\n",
      "Vivienda_Alquiler                      2927 non-null float64\n",
      "Medico_Seguro_Privado                  2927 non-null float64\n",
      "Medico_Seguridad_Social                2927 non-null float64\n",
      "Ingresos_Mas_De_40000                  2927 non-null float64\n",
      "Ingresos_De_20000_Hasta_40000          2927 non-null float64\n",
      "Ingresos_Hasta_20000                   2927 non-null float64\n",
      "dtypes: float64(20), int64(3), object(5)\n",
      "memory usage: 663.1+ KB\n",
      "Gasto_Vida\n",
      "Gasto_Vehiculos\n",
      "Gasto_Otros\n",
      "Educacion_Superior\n",
      "Educacion_Baja\n",
      "Poblacion_Empresario\n",
      "Poblacion_Trabajador_No_Cualificado\n",
      "Vivienda_Propiedad\n",
      "Vivienda_Alquiler\n",
      "Medico_Seguro_Privado\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varianza acumulada explicada por cada componente (tanto por uno):  [0.86426151 0.98018988 0.99803623 0.99879546 0.99916202 0.99934778\n",
      " 0.99952203 0.99963271 0.99973099 0.99981113]\n",
      "Varianza acumulada explicada por cada componente (tanto por uno):  [0.86426151 0.98018988]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run 1-2-Preparacion.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es evidente cuál es el mejor tipo de modelo para resolver nuestro problema. Por lo tanto, es recomendable empezar con los modelos más sencillos y estables, los modelos lineales, y después probar con otros más expresivos como los perceptrones multicapa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza las variables seleccionadas o transformadas en el apartado anterior y estudia medidas de calidad como la precisión y el \"recall\" para evaluar cada uno de los modelos. Para ello, se puede dividir el conjunto de datos de entrenamiento en particiones de train y validación (test) de modo que la primera sirva para entrenar los modelos, y la segunda para validar; o bien se puede utilizar una estrategia de cross-validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05419921875"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    variables._get_numeric_data(), targets, test_size=0.3, random_state=42)\n",
    "\n",
    "datos_path = \"./\"\n",
    "clientes_file_2 = \"Clientes_test.csv\"\n",
    "zonas_file = \"Zonas.csv\"\n",
    "\n",
    "clientes2 = pd.read_csv(os.path.join(datos_path, clientes_file_2), sep='\\t')\n",
    "zonas = pd.read_csv(os.path.join(datos_path, zonas_file), sep='\\t')\n",
    "\n",
    "datos2 = pd.merge(clientes2, zonas, on=\"ID_Zona\", how=\"inner\")\n",
    "\n",
    "#targets2 = datos2[\"Seguro_Vivienda\"]\n",
    "#variables2 = datos2.drop([\"Seguro_Vivienda\"], axis=1, inplace=False)\n",
    "\n",
    "#mejor trabajar con 1 y 0\n",
    "y_train = y_train*1\n",
    "y_test = y_test*1\n",
    "\n",
    "\n",
    "\n",
    "X_test_2 = datos2._get_numeric_data()\n",
    "\n",
    "y_test\n",
    "\n",
    "y_train.sum()/y_train.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos no están balanceados, los que contratan es ~6% del total. Por tanto podemos usar class_weight que tanto en Keras como en Scikitlearn lo tienen. En esta práctica usaremos esto ya que en pruebas realizadas los métodos no aprendía bien la contratación del seguro y por tanto he tenido que recurrir a esta forma.  Existen técnicas más complejas como Near Miss.\n",
    "\n",
    "Esta técnica nos hará perder Accuracy pero como veremos seremos capaces de acertar mejor los clientes que contratan seguro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 6.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Así podemos genera la variable class_weight que nos ayuda a cambiar los pesos (importancia) de las observaciones en función de la clase\n",
    "#Aunque algunas funciones sólo funcionan con class_weight = \"balanced\", luego este código sólo es a modo ilustrativo\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "class_weight = class_weight.compute_class_weight({1:6,0:1}\n",
    "                                               ,np.unique(y_train)\n",
    "                                               ,y_train)\n",
    "\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 23) (879, 23) (2048,) (879,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feauture Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "selection = SelectKBest(chi2, k=10)\n",
    "\n",
    "logreg = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                         multi_class='multinomial', C = 1e6, class_weight='balanced') #ponemos un C alto porque no queremos restringir el modelo\n",
    "\n",
    "modelo_logit = Pipeline([('selection', selection), ('logreg', logreg)]).fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.81787109375\n",
      "Accuracy Test:  0.8236632536973834\n"
     ]
    }
   ],
   "source": [
    "print( \"Accuracy Train: \", modelo_logit.score(X_train,y_train))\n",
    "print( \"Accuracy Test: \", modelo_logit.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit(variables._get_numeric_data(), targets)\n",
    "\n",
    "logreg = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                         multi_class='multinomial', C = 1e6, class_weight='balanced') #ponemos un C alto porque no queremos restring'balanced'\n",
    "modelo_logit_pca = Pipeline([('pca', pca), ('logreg', logreg)]).fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.80859375\n",
      "Accuracy Test:  0.8145620022753128\n"
     ]
    }
   ],
   "source": [
    "print( \"Accuracy Train: \", modelo_logit_pca.score(X_train,y_train))\n",
    "print( \"Accuracy Test: \", modelo_logit_pca.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos modelos salen con un score bastante similar, algo mayor usando feature selection.\n",
    "\n",
    "Para terminar calcularemos el recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Logit Entrenamiento:  0.81787109375\n",
      "Recall Logit Test:  0.8236632536973834\n",
      "Recall Logit PCA Entrenamiento:  0.80859375\n",
      "Recall Logit PCA Test:  0.8145620022753128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_method ='weighted'\n",
    "\n",
    "print (\"Recall Logit Entrenamiento: \", recall_score(y_train, modelo_logit.predict(X_train), average=recall_method))\n",
    "print (\"Recall Logit Test: \", recall_score(y_test, modelo_logit.predict(X_test), average=recall_method))\n",
    "\n",
    "print (\"Recall Logit PCA Entrenamiento: \", recall_score(y_train, modelo_logit_pca.predict(X_train), average=recall_method))\n",
    "print (\"Recall Logit PCA Test: \", recall_score(y_test, modelo_logit_pca.predict(X_test), average=recall_method))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si hacemos un recall ponderado vemos que ámbos métodos clasifican bastante bien... aparentemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Logit Entrenamiento:  [0.8167269  0.83783784]\n",
      "Recall Logit Test:  [0.82424242 0.81481481]\n",
      "Recall Logit PCA Entrenamiento:  [0.80743418 0.82882883]\n",
      "Recall Logit PCA Test:  [0.81575758 0.7962963 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_method = None\n",
    "\n",
    "print (\"Recall Logit Entrenamiento: \", recall_score(y_train, modelo_logit.predict(X_train), average=recall_method))\n",
    "print (\"Recall Logit Test: \", recall_score(y_test, modelo_logit.predict(X_test), average=recall_method))\n",
    "\n",
    "print (\"Recall Logit PCA Entrenamiento: \", recall_score(y_train, modelo_logit_pca.predict(X_train), average=recall_method))\n",
    "print (\"Recall Logit PCA Test: \", recall_score(y_test, modelo_logit_pca.predict(X_test), average=recall_method))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la primera fila de Test y Train contiene un False (0), la primera componente es el recall de False, la segunda es True. \n",
    "Como vemos en test le cuesta aprender los True, puede ser que aunque hemos balanceados los datos, no es un balanceado estratificado y es posible que por eso en test no tengamos buenos resultados.\n",
    "Para este propósito habría que recurrir a otro métodos. Esperemos que el Deep Learning nos ayude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression CV con L1 (Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as randint\n",
    "\n",
    "\n",
    "\n",
    "param_dist = { \"C\": randint(0, 1e6) }\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(random_state=0, solver='liblinear',penalty='l1', class_weight='balanced')\n",
    "\n",
    "modelo_logit_RS = RandomizedSearchCV(logreg, param_distributions=param_dist, cv=10).fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.865234375\n",
      "Accuracy Test:  0.8668941979522184\n",
      "Recall Entrenamiento:  [0.86473929 0.87387387]\n",
      "Recall Test:  [0.86787879 0.85185185]\n"
     ]
    }
   ],
   "source": [
    "recall_method = None\n",
    "\n",
    "print( \"Accuracy Train: \", modelo_logit_RS.score(X_train,y_train))\n",
    "print( \"Accuracy Test: \", modelo_logit_RS.score(X_test,y_test))\n",
    "print (\"Recall Entrenamiento: \", recall_score(y_train, modelo_logit_RS.predict(X_train), average=recall_method))\n",
    "print (\"Recall Test: \", recall_score(y_test, modelo_logit_RS.predict(X_test), average=recall_method))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=793639, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=0,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_logit_RS.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notable mejora en Accuracy y Recall, este será el modelo seleccionado para comparar a las redes neuronales en seción 1-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero debemos escalar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "X_scale_train = scale.fit_transform(X_train)\n",
    "X_scale_test = scale.transform(X_test)\n",
    "\n",
    "#X_scale_train = X_scale_train.reshape((len(X_scale_train), np.prod(X_scale_train.shape[1:])))\n",
    "#X_scale_test = X_scale_test.reshape((len(X_scale_test), np.prod(X_scale_test.shape[1:])))\n",
    "\n",
    "#y_cat_train = y_train*1\n",
    "#y_cat_test = y_test*1\n",
    "\n",
    "#Necesitamos este paso para poder probar con dos neuronas en la última capa\n",
    "y_cat_train = to_categorical(y_train.astype(int))\n",
    "y_cat_test = to_categorical(y_test.astype(int))\n",
    "\n",
    "#y_cat_train[1:50]\n",
    "#y_train[1:50]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos algunas funciones de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por lo que veo en las últimas versiones han quitado alguna métrica de Keras, pero en esta ruta están implementadas muchas:\n",
    "# https://github.com/GeekLiB/keras/blob/master/keras/metrics.py\n",
    "# tengo dudas si el recall es correcto, pero luego saldremos de dudas cuando veamos las curvas ROC en el siguiente notebook\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    '''Calculates the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    '''Calculates the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    '''Calculates the F score, the weighted harmonic mean of precision and recall.\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    '''\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "        \n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una sola Capa Oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4))\n",
    "\n",
    "x = Input(shape=(23,))\n",
    "layer = Dense(10, activation='softsign', kernel_initializer='he_uniform')(x)\n",
    "y = Dense(1, activation='sigmoid',kernel_initializer='he_uniform')(layer)\n",
    "mlp = Model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.compile(optimizer='sgd',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', recall, fbeta_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 879 samples\n",
      "Epoch 1/1000\n",
      "2048/2048 [==============================] - 0s 195us/step - loss: 0.5853 - acc: 0.7139 - recall: 0.0317 - fbeta_score: 0.0170 - val_loss: 0.4564 - val_acc: 0.8931 - val_recall: 0.0171 - val_fbeta_score: 0.0133\n",
      "Epoch 2/1000\n",
      "2048/2048 [==============================] - 0s 106us/step - loss: 0.3732 - acc: 0.9316 - recall: 0.0024 - fbeta_score: 0.0024 - val_loss: 0.3349 - val_acc: 0.9374 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.2921 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.2818 - val_acc: 0.9374 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.2525 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.2533 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.2292 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.2356 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.2137 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.2232 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "2048/2048 [==============================] - 0s 82us/step - loss: 0.2024 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.2140 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.1937 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.2067 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.1866 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.2005 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.1804 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.1952 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.1752 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.1906 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.1704 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.1864 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.1660 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.1826 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.1620 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.1791 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.1582 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.1760 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.1548 - acc: 0.9458 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.1731 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.1517 - acc: 0.9453 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 0.1705 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1488 - acc: 0.9458 - recall: 0.0049 - fbeta_score: 0.0049 - val_loss: 0.1681 - val_acc: 0.9386 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "2048/2048 [==============================] - ETA: 0s - loss: 0.1372 - acc: 0.9504 - recall: 0.0072 - fbeta_score: 0.0072       - 0s 86us/step - loss: 0.1462 - acc: 0.9458 - recall: 0.0049 - fbeta_score: 0.0049 - val_loss: 0.1659 - val_acc: 0.9397 - val_recall: 0.0114 - val_fbeta_score: 0.0114\n",
      "Epoch 20/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.1438 - acc: 0.9453 - recall: 0.0049 - fbeta_score: 0.0049 - val_loss: 0.1638 - val_acc: 0.9386 - val_recall: 0.0114 - val_fbeta_score: 0.0114\n",
      "Epoch 21/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1415 - acc: 0.9453 - recall: 0.0098 - fbeta_score: 0.0098 - val_loss: 0.1620 - val_acc: 0.9386 - val_recall: 0.0114 - val_fbeta_score: 0.0114\n",
      "Epoch 22/1000\n",
      "2048/2048 [==============================] - 0s 150us/step - loss: 0.1394 - acc: 0.9463 - recall: 0.0153 - fbeta_score: 0.0161 - val_loss: 0.1601 - val_acc: 0.9374 - val_recall: 0.0114 - val_fbeta_score: 0.0114\n",
      "Epoch 23/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.1375 - acc: 0.9473 - recall: 0.0212 - fbeta_score: 0.0220 - val_loss: 0.1584 - val_acc: 0.9374 - val_recall: 0.0114 - val_fbeta_score: 0.0114\n",
      "Epoch 24/1000\n",
      "2048/2048 [==============================] - 0s 110us/step - loss: 0.1357 - acc: 0.9502 - recall: 0.0399 - fbeta_score: 0.0456 - val_loss: 0.1569 - val_acc: 0.9363 - val_recall: 0.0228 - val_fbeta_score: 0.0228\n",
      "Epoch 25/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.1339 - acc: 0.9497 - recall: 0.0545 - fbeta_score: 0.0560 - val_loss: 0.1553 - val_acc: 0.9363 - val_recall: 0.0284 - val_fbeta_score: 0.0303\n",
      "Epoch 26/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1323 - acc: 0.9502 - recall: 0.0635 - fbeta_score: 0.0651 - val_loss: 0.1539 - val_acc: 0.9374 - val_recall: 0.0341 - val_fbeta_score: 0.0379\n",
      "Epoch 27/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.1308 - acc: 0.9512 - recall: 0.0610 - fbeta_score: 0.0651 - val_loss: 0.1527 - val_acc: 0.9386 - val_recall: 0.0379 - val_fbeta_score: 0.0436\n",
      "Epoch 28/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.1293 - acc: 0.9507 - recall: 0.0586 - fbeta_score: 0.0643 - val_loss: 0.1514 - val_acc: 0.9386 - val_recall: 0.0379 - val_fbeta_score: 0.0436\n",
      "Epoch 29/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1280 - acc: 0.9517 - recall: 0.0684 - fbeta_score: 0.0732 - val_loss: 0.1503 - val_acc: 0.9397 - val_recall: 0.0493 - val_fbeta_score: 0.0550\n",
      "Epoch 30/1000\n",
      "2048/2048 [==============================] - 0s 105us/step - loss: 0.1267 - acc: 0.9536 - recall: 0.0920 - fbeta_score: 0.0952 - val_loss: 0.1493 - val_acc: 0.9397 - val_recall: 0.0493 - val_fbeta_score: 0.0550\n",
      "Epoch 31/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.1255 - acc: 0.9541 - recall: 0.0952 - fbeta_score: 0.0993 - val_loss: 0.1484 - val_acc: 0.9420 - val_recall: 0.0607 - val_fbeta_score: 0.0664\n",
      "Epoch 32/1000\n",
      "2048/2048 [==============================] - 0s 111us/step - loss: 0.1243 - acc: 0.9561 - recall: 0.1034 - fbeta_score: 0.1099 - val_loss: 0.1474 - val_acc: 0.9420 - val_recall: 0.0607 - val_fbeta_score: 0.0664\n",
      "Epoch 33/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.1232 - acc: 0.9556 - recall: 0.1017 - fbeta_score: 0.1024 - val_loss: 0.1464 - val_acc: 0.9408 - val_recall: 0.0607 - val_fbeta_score: 0.0664\n",
      "Epoch 34/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.1221 - acc: 0.9561 - recall: 0.0920 - fbeta_score: 0.0973 - val_loss: 0.1456 - val_acc: 0.9408 - val_recall: 0.0607 - val_fbeta_score: 0.0664\n",
      "Epoch 35/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1211 - acc: 0.9561 - recall: 0.1123 - fbeta_score: 0.1147 - val_loss: 0.1448 - val_acc: 0.9397 - val_recall: 0.0607 - val_fbeta_score: 0.0664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.1201 - acc: 0.9570 - recall: 0.1213 - fbeta_score: 0.1270 - val_loss: 0.1440 - val_acc: 0.9397 - val_recall: 0.0607 - val_fbeta_score: 0.0664\n",
      "Epoch 37/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.1192 - acc: 0.9570 - recall: 0.1270 - fbeta_score: 0.1302 - val_loss: 0.1431 - val_acc: 0.9397 - val_recall: 0.0607 - val_fbeta_score: 0.0664\n",
      "Epoch 38/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.1183 - acc: 0.9570 - recall: 0.1061 - fbeta_score: 0.1150 - val_loss: 0.1424 - val_acc: 0.9386 - val_recall: 0.0607 - val_fbeta_score: 0.0664\n",
      "Epoch 39/1000\n",
      "2048/2048 [==============================] - 0s 82us/step - loss: 0.1174 - acc: 0.9570 - recall: 0.1107 - fbeta_score: 0.1188 - val_loss: 0.1417 - val_acc: 0.9397 - val_recall: 0.0645 - val_fbeta_score: 0.0698\n",
      "Epoch 40/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1166 - acc: 0.9580 - recall: 0.1204 - fbeta_score: 0.1253 - val_loss: 0.1407 - val_acc: 0.9431 - val_recall: 0.0929 - val_fbeta_score: 0.0963\n",
      "Epoch 41/1000\n",
      "2048/2048 [==============================] - 0s 83us/step - loss: 0.1158 - acc: 0.9575 - recall: 0.1217 - fbeta_score: 0.1305 - val_loss: 0.1400 - val_acc: 0.9431 - val_recall: 0.0929 - val_fbeta_score: 0.0963\n",
      "Epoch 42/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.1151 - acc: 0.9575 - recall: 0.1261 - fbeta_score: 0.1315 - val_loss: 0.1394 - val_acc: 0.9431 - val_recall: 0.0967 - val_fbeta_score: 0.1020\n",
      "Epoch 43/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1144 - acc: 0.9585 - recall: 0.1335 - fbeta_score: 0.1375 - val_loss: 0.1388 - val_acc: 0.9443 - val_recall: 0.1024 - val_fbeta_score: 0.1096\n",
      "Epoch 44/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.1137 - acc: 0.9614 - recall: 0.1530 - fbeta_score: 0.1536 - val_loss: 0.1382 - val_acc: 0.9431 - val_recall: 0.0967 - val_fbeta_score: 0.1020\n",
      "Epoch 45/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.1130 - acc: 0.9609 - recall: 0.1416 - fbeta_score: 0.1501 - val_loss: 0.1377 - val_acc: 0.9443 - val_recall: 0.1024 - val_fbeta_score: 0.1096\n",
      "Epoch 46/1000\n",
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.1123 - acc: 0.9614 - recall: 0.1579 - fbeta_score: 0.1636 - val_loss: 0.1372 - val_acc: 0.9443 - val_recall: 0.1024 - val_fbeta_score: 0.1096\n",
      "Epoch 47/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.1117 - acc: 0.9619 - recall: 0.1506 - fbeta_score: 0.1571 - val_loss: 0.1366 - val_acc: 0.9443 - val_recall: 0.1024 - val_fbeta_score: 0.1096\n",
      "Epoch 48/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.1111 - acc: 0.9624 - recall: 0.1628 - fbeta_score: 0.1660 - val_loss: 0.1361 - val_acc: 0.9443 - val_recall: 0.1024 - val_fbeta_score: 0.1096\n",
      "Epoch 49/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.1106 - acc: 0.9619 - recall: 0.1628 - fbeta_score: 0.1709 - val_loss: 0.1358 - val_acc: 0.9443 - val_recall: 0.1024 - val_fbeta_score: 0.1096\n",
      "Epoch 50/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.1101 - acc: 0.9624 - recall: 0.1514 - fbeta_score: 0.1561 - val_loss: 0.1353 - val_acc: 0.9454 - val_recall: 0.1062 - val_fbeta_score: 0.1153\n",
      "Epoch 51/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.1096 - acc: 0.9629 - recall: 0.1638 - fbeta_score: 0.1692 - val_loss: 0.1349 - val_acc: 0.9454 - val_recall: 0.1062 - val_fbeta_score: 0.1153\n",
      "Epoch 52/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1091 - acc: 0.9629 - recall: 0.1701 - fbeta_score: 0.1726 - val_loss: 0.1347 - val_acc: 0.9465 - val_recall: 0.1176 - val_fbeta_score: 0.1267\n",
      "Epoch 53/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.1088 - acc: 0.9629 - recall: 0.1733 - fbeta_score: 0.1782 - val_loss: 0.1344 - val_acc: 0.9465 - val_recall: 0.1176 - val_fbeta_score: 0.1267\n",
      "Epoch 54/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.1083 - acc: 0.9634 - recall: 0.1715 - fbeta_score: 0.1772 - val_loss: 0.1340 - val_acc: 0.9465 - val_recall: 0.1176 - val_fbeta_score: 0.1267\n",
      "Epoch 55/1000\n",
      "2048/2048 [==============================] - 0s 85us/step - loss: 0.1080 - acc: 0.9639 - recall: 0.1408 - fbeta_score: 0.1527 - val_loss: 0.1337 - val_acc: 0.9477 - val_recall: 0.1232 - val_fbeta_score: 0.1342\n",
      "Epoch 56/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.1076 - acc: 0.9648 - recall: 0.1774 - fbeta_score: 0.1834 - val_loss: 0.1332 - val_acc: 0.9477 - val_recall: 0.1232 - val_fbeta_score: 0.1342\n",
      "Epoch 57/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1072 - acc: 0.9648 - recall: 0.1748 - fbeta_score: 0.1821 - val_loss: 0.1333 - val_acc: 0.9477 - val_recall: 0.1232 - val_fbeta_score: 0.1342\n",
      "Epoch 58/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.1069 - acc: 0.9653 - recall: 0.1626 - fbeta_score: 0.1689 - val_loss: 0.1332 - val_acc: 0.9477 - val_recall: 0.1289 - val_fbeta_score: 0.1380\n",
      "Epoch 59/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.1066 - acc: 0.9653 - recall: 0.1725 - fbeta_score: 0.1813 - val_loss: 0.1329 - val_acc: 0.9488 - val_recall: 0.1346 - val_fbeta_score: 0.1456\n",
      "Epoch 60/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.1062 - acc: 0.9653 - recall: 0.1815 - fbeta_score: 0.1829 - val_loss: 0.1326 - val_acc: 0.9488 - val_recall: 0.1346 - val_fbeta_score: 0.1456\n",
      "Epoch 61/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.1059 - acc: 0.9653 - recall: 0.1790 - fbeta_score: 0.1844 - val_loss: 0.1326 - val_acc: 0.9488 - val_recall: 0.1346 - val_fbeta_score: 0.1456\n",
      "Epoch 62/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.1056 - acc: 0.9658 - recall: 0.1899 - fbeta_score: 0.1930 - val_loss: 0.1325 - val_acc: 0.9477 - val_recall: 0.1289 - val_fbeta_score: 0.1380\n",
      "Epoch 63/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.1053 - acc: 0.9658 - recall: 0.1790 - fbeta_score: 0.1846 - val_loss: 0.1323 - val_acc: 0.9477 - val_recall: 0.1289 - val_fbeta_score: 0.1380\n",
      "Epoch 64/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.1051 - acc: 0.9653 - recall: 0.1799 - fbeta_score: 0.1868 - val_loss: 0.1321 - val_acc: 0.9488 - val_recall: 0.1327 - val_fbeta_score: 0.1414\n",
      "Epoch 65/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.1048 - acc: 0.9653 - recall: 0.1693 - fbeta_score: 0.1761 - val_loss: 0.1319 - val_acc: 0.9499 - val_recall: 0.1441 - val_fbeta_score: 0.1528\n",
      "Epoch 66/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1045 - acc: 0.9658 - recall: 0.1919 - fbeta_score: 0.1991 - val_loss: 0.1319 - val_acc: 0.9477 - val_recall: 0.1289 - val_fbeta_score: 0.1380\n",
      "Epoch 67/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.1042 - acc: 0.9658 - recall: 0.1668 - fbeta_score: 0.1789 - val_loss: 0.1314 - val_acc: 0.9511 - val_recall: 0.1555 - val_fbeta_score: 0.1642\n",
      "Epoch 68/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.1040 - acc: 0.9658 - recall: 0.1872 - fbeta_score: 0.1945 - val_loss: 0.1312 - val_acc: 0.9534 - val_recall: 0.1669 - val_fbeta_score: 0.1756\n",
      "Epoch 69/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1037 - acc: 0.9658 - recall: 0.1945 - fbeta_score: 0.2018 - val_loss: 0.1316 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 70/1000\n",
      "2048/2048 [==============================] - 0s 104us/step - loss: 0.1035 - acc: 0.9663 - recall: 0.1961 - fbeta_score: 0.2041 - val_loss: 0.1315 - val_acc: 0.9522 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 71/1000\n",
      "2048/2048 [==============================] - 0s 110us/step - loss: 0.1033 - acc: 0.9663 - recall: 0.1945 - fbeta_score: 0.1986 - val_loss: 0.1316 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 72/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 109us/step - loss: 0.1030 - acc: 0.9663 - recall: 0.1782 - fbeta_score: 0.1854 - val_loss: 0.1316 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 73/1000\n",
      "2048/2048 [==============================] - 0s 128us/step - loss: 0.1028 - acc: 0.9663 - recall: 0.1925 - fbeta_score: 0.1987 - val_loss: 0.1314 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 74/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.1024 - acc: 0.9663 - recall: 0.1978 - fbeta_score: 0.2065 - val_loss: 0.1317 - val_acc: 0.9499 - val_recall: 0.1346 - val_fbeta_score: 0.1418\n",
      "Epoch 75/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.1024 - acc: 0.9668 - recall: 0.1896 - fbeta_score: 0.2000 - val_loss: 0.1314 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 76/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1021 - acc: 0.9668 - recall: 0.1912 - fbeta_score: 0.1961 - val_loss: 0.1309 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 77/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.1019 - acc: 0.9668 - recall: 0.1750 - fbeta_score: 0.1851 - val_loss: 0.1308 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 78/1000\n",
      "2048/2048 [==============================] - 0s 107us/step - loss: 0.1017 - acc: 0.9668 - recall: 0.1904 - fbeta_score: 0.2000 - val_loss: 0.1307 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 79/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.1015 - acc: 0.9668 - recall: 0.1829 - fbeta_score: 0.1864 - val_loss: 0.1307 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 80/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1013 - acc: 0.9668 - recall: 0.1794 - fbeta_score: 0.1848 - val_loss: 0.1306 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 81/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.1011 - acc: 0.9663 - recall: 0.1789 - fbeta_score: 0.1834 - val_loss: 0.1304 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 82/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.1010 - acc: 0.9663 - recall: 0.1919 - fbeta_score: 0.1958 - val_loss: 0.1304 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 83/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1009 - acc: 0.9663 - recall: 0.2148 - fbeta_score: 0.2222 - val_loss: 0.1304 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 84/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.1007 - acc: 0.9668 - recall: 0.2017 - fbeta_score: 0.2065 - val_loss: 0.1302 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 85/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.1005 - acc: 0.9668 - recall: 0.1903 - fbeta_score: 0.1966 - val_loss: 0.1300 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 86/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.1004 - acc: 0.9663 - recall: 0.1896 - fbeta_score: 0.1937 - val_loss: 0.1301 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 87/1000\n",
      "2048/2048 [==============================] - 0s 82us/step - loss: 0.1003 - acc: 0.9668 - recall: 0.1929 - fbeta_score: 0.2002 - val_loss: 0.1300 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 88/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.1001 - acc: 0.9663 - recall: 0.1766 - fbeta_score: 0.1855 - val_loss: 0.1298 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 89/1000\n",
      "2048/2048 [==============================] - 0s 84us/step - loss: 0.1000 - acc: 0.9673 - recall: 0.1896 - fbeta_score: 0.1989 - val_loss: 0.1297 - val_acc: 0.9534 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 90/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0999 - acc: 0.9668 - recall: 0.2091 - fbeta_score: 0.2171 - val_loss: 0.1298 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 91/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0998 - acc: 0.9663 - recall: 0.1948 - fbeta_score: 0.1979 - val_loss: 0.1301 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 92/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0996 - acc: 0.9673 - recall: 0.1937 - fbeta_score: 0.2041 - val_loss: 0.1300 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 93/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0995 - acc: 0.9668 - recall: 0.1831 - fbeta_score: 0.1882 - val_loss: 0.1301 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 94/1000\n",
      "2048/2048 [==============================] - 0s 112us/step - loss: 0.0994 - acc: 0.9673 - recall: 0.1778 - fbeta_score: 0.1806 - val_loss: 0.1301 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 95/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0993 - acc: 0.9678 - recall: 0.2108 - fbeta_score: 0.2155 - val_loss: 0.1303 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 96/1000\n",
      "2048/2048 [==============================] - 0s 86us/step - loss: 0.0992 - acc: 0.9678 - recall: 0.2083 - fbeta_score: 0.2108 - val_loss: 0.1301 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 97/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0991 - acc: 0.9678 - recall: 0.2067 - fbeta_score: 0.2122 - val_loss: 0.1301 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 98/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0990 - acc: 0.9673 - recall: 0.2067 - fbeta_score: 0.2165 - val_loss: 0.1302 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 99/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0989 - acc: 0.9683 - recall: 0.2059 - fbeta_score: 0.2126 - val_loss: 0.1301 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 100/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0987 - acc: 0.9668 - recall: 0.1969 - fbeta_score: 0.2072 - val_loss: 0.1302 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 101/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0987 - acc: 0.9678 - recall: 0.1953 - fbeta_score: 0.2031 - val_loss: 0.1302 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 102/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0985 - acc: 0.9673 - recall: 0.2189 - fbeta_score: 0.2254 - val_loss: 0.1302 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 103/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0985 - acc: 0.9678 - recall: 0.2043 - fbeta_score: 0.2163 - val_loss: 0.1303 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 104/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0984 - acc: 0.9673 - recall: 0.1921 - fbeta_score: 0.1982 - val_loss: 0.1302 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 105/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0982 - acc: 0.9673 - recall: 0.2067 - fbeta_score: 0.2145 - val_loss: 0.1304 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 106/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0981 - acc: 0.9678 - recall: 0.1888 - fbeta_score: 0.1925 - val_loss: 0.1303 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 107/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0980 - acc: 0.9678 - recall: 0.2148 - fbeta_score: 0.2204 - val_loss: 0.1302 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 108/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0980 - acc: 0.9678 - recall: 0.2000 - fbeta_score: 0.2046 - val_loss: 0.1302 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 109/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0978 - acc: 0.9673 - recall: 0.2108 - fbeta_score: 0.2139 - val_loss: 0.1303 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 110/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0978 - acc: 0.9678 - recall: 0.2108 - fbeta_score: 0.2129 - val_loss: 0.1301 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 111/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0976 - acc: 0.9678 - recall: 0.2165 - fbeta_score: 0.2227 - val_loss: 0.1301 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 112/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0975 - acc: 0.9683 - recall: 0.1950 - fbeta_score: 0.2053 - val_loss: 0.1303 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 113/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0974 - acc: 0.9683 - recall: 0.1912 - fbeta_score: 0.2033 - val_loss: 0.1304 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 114/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0974 - acc: 0.9683 - recall: 0.2091 - fbeta_score: 0.2160 - val_loss: 0.1304 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 115/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0972 - acc: 0.9683 - recall: 0.2043 - fbeta_score: 0.2108 - val_loss: 0.1302 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 116/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0971 - acc: 0.9687 - recall: 0.1777 - fbeta_score: 0.1839 - val_loss: 0.1301 - val_acc: 0.9522 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 117/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0970 - acc: 0.9683 - recall: 0.2148 - fbeta_score: 0.2227 - val_loss: 0.1304 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 118/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0969 - acc: 0.9692 - recall: 0.2087 - fbeta_score: 0.2134 - val_loss: 0.1305 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 119/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0968 - acc: 0.9687 - recall: 0.2197 - fbeta_score: 0.2311 - val_loss: 0.1305 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 120/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0968 - acc: 0.9683 - recall: 0.1839 - fbeta_score: 0.1927 - val_loss: 0.1305 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 121/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0966 - acc: 0.9687 - recall: 0.2079 - fbeta_score: 0.2154 - val_loss: 0.1303 - val_acc: 0.9522 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 122/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0965 - acc: 0.9683 - recall: 0.2059 - fbeta_score: 0.2114 - val_loss: 0.1304 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 123/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0965 - acc: 0.9692 - recall: 0.1969 - fbeta_score: 0.2041 - val_loss: 0.1305 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 124/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0963 - acc: 0.9687 - recall: 0.1929 - fbeta_score: 0.1969 - val_loss: 0.1304 - val_acc: 0.9522 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 125/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0962 - acc: 0.9683 - recall: 0.2111 - fbeta_score: 0.2204 - val_loss: 0.1305 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 126/1000\n",
      "2048/2048 [==============================] - 0s 81us/step - loss: 0.0961 - acc: 0.9683 - recall: 0.2277 - fbeta_score: 0.2310 - val_loss: 0.1306 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 127/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0960 - acc: 0.9683 - recall: 0.2100 - fbeta_score: 0.2140 - val_loss: 0.1309 - val_acc: 0.9488 - val_recall: 0.1346 - val_fbeta_score: 0.1418\n",
      "Epoch 128/1000\n",
      "2048/2048 [==============================] - 0s 86us/step - loss: 0.0959 - acc: 0.9692 - recall: 0.1994 - fbeta_score: 0.2065 - val_loss: 0.1309 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 129/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0958 - acc: 0.9687 - recall: 0.2311 - fbeta_score: 0.2350 - val_loss: 0.1308 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 130/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0957 - acc: 0.9687 - recall: 0.1945 - fbeta_score: 0.2031 - val_loss: 0.1307 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 131/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0956 - acc: 0.9683 - recall: 0.2059 - fbeta_score: 0.2106 - val_loss: 0.1306 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 132/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0955 - acc: 0.9687 - recall: 0.2074 - fbeta_score: 0.2122 - val_loss: 0.1305 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 133/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0954 - acc: 0.9687 - recall: 0.2116 - fbeta_score: 0.2192 - val_loss: 0.1306 - val_acc: 0.9511 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 134/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0953 - acc: 0.9687 - recall: 0.2043 - fbeta_score: 0.2139 - val_loss: 0.1307 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 135/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0952 - acc: 0.9687 - recall: 0.1994 - fbeta_score: 0.2095 - val_loss: 0.1307 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 136/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0951 - acc: 0.9687 - recall: 0.2059 - fbeta_score: 0.2165 - val_loss: 0.1309 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 137/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0950 - acc: 0.9697 - recall: 0.2193 - fbeta_score: 0.2277 - val_loss: 0.1310 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 138/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0949 - acc: 0.9692 - recall: 0.2292 - fbeta_score: 0.2314 - val_loss: 0.1308 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 139/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0948 - acc: 0.9692 - recall: 0.2148 - fbeta_score: 0.2238 - val_loss: 0.1310 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 140/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0947 - acc: 0.9687 - recall: 0.2189 - fbeta_score: 0.2287 - val_loss: 0.1309 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 141/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0946 - acc: 0.9697 - recall: 0.2074 - fbeta_score: 0.2122 - val_loss: 0.1308 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 142/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0945 - acc: 0.9692 - recall: 0.2075 - fbeta_score: 0.2139 - val_loss: 0.1310 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 143/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0944 - acc: 0.9697 - recall: 0.2035 - fbeta_score: 0.2072 - val_loss: 0.1311 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 144/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0943 - acc: 0.9697 - recall: 0.2059 - fbeta_score: 0.2122 - val_loss: 0.1309 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 145/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0942 - acc: 0.9683 - recall: 0.2059 - fbeta_score: 0.2165 - val_loss: 0.1308 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 146/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0941 - acc: 0.9692 - recall: 0.2327 - fbeta_score: 0.2360 - val_loss: 0.1309 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 147/1000\n",
      "2048/2048 [==============================] - 0s 82us/step - loss: 0.0940 - acc: 0.9692 - recall: 0.2189 - fbeta_score: 0.2236 - val_loss: 0.1310 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 148/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0939 - acc: 0.9697 - recall: 0.2124 - fbeta_score: 0.2179 - val_loss: 0.1310 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 149/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0938 - acc: 0.9692 - recall: 0.2214 - fbeta_score: 0.2238 - val_loss: 0.1310 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 150/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0937 - acc: 0.9702 - recall: 0.2205 - fbeta_score: 0.2269 - val_loss: 0.1311 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 151/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0936 - acc: 0.9697 - recall: 0.2254 - fbeta_score: 0.2292 - val_loss: 0.1309 - val_acc: 0.9511 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 152/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0935 - acc: 0.9702 - recall: 0.2197 - fbeta_score: 0.2277 - val_loss: 0.1311 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 153/1000\n",
      "2048/2048 [==============================] - 0s 85us/step - loss: 0.0934 - acc: 0.9707 - recall: 0.2303 - fbeta_score: 0.2367 - val_loss: 0.1311 - val_acc: 0.9499 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 154/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0933 - acc: 0.9707 - recall: 0.2375 - fbeta_score: 0.2456 - val_loss: 0.1311 - val_acc: 0.9511 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 155/1000\n",
      "2048/2048 [==============================] - 0s 84us/step - loss: 0.0932 - acc: 0.9702 - recall: 0.2279 - fbeta_score: 0.2301 - val_loss: 0.1310 - val_acc: 0.9511 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 156/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0931 - acc: 0.9702 - recall: 0.2059 - fbeta_score: 0.2155 - val_loss: 0.1311 - val_acc: 0.9499 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 157/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0929 - acc: 0.9707 - recall: 0.2181 - fbeta_score: 0.2223 - val_loss: 0.1309 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 158/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0929 - acc: 0.9697 - recall: 0.1969 - fbeta_score: 0.2096 - val_loss: 0.1311 - val_acc: 0.9499 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 159/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0928 - acc: 0.9707 - recall: 0.2326 - fbeta_score: 0.2363 - val_loss: 0.1312 - val_acc: 0.9499 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 160/1000\n",
      "2048/2048 [==============================] - 0s 83us/step - loss: 0.0926 - acc: 0.9702 - recall: 0.2140 - fbeta_score: 0.2189 - val_loss: 0.1310 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 161/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0926 - acc: 0.9697 - recall: 0.2214 - fbeta_score: 0.2301 - val_loss: 0.1311 - val_acc: 0.9499 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 162/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0925 - acc: 0.9702 - recall: 0.2140 - fbeta_score: 0.2225 - val_loss: 0.1311 - val_acc: 0.9499 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 163/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0923 - acc: 0.9702 - recall: 0.2222 - fbeta_score: 0.2267 - val_loss: 0.1315 - val_acc: 0.9488 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 164/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0923 - acc: 0.9712 - recall: 0.2342 - fbeta_score: 0.2399 - val_loss: 0.1315 - val_acc: 0.9488 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 165/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0921 - acc: 0.9707 - recall: 0.2157 - fbeta_score: 0.2267 - val_loss: 0.1312 - val_acc: 0.9499 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 166/1000\n",
      "2048/2048 [==============================] - 0s 83us/step - loss: 0.0921 - acc: 0.9697 - recall: 0.2238 - fbeta_score: 0.2311 - val_loss: 0.1314 - val_acc: 0.9499 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 167/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0919 - acc: 0.9707 - recall: 0.2112 - fbeta_score: 0.2176 - val_loss: 0.1318 - val_acc: 0.9488 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 168/1000\n",
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.0919 - acc: 0.9707 - recall: 0.2075 - fbeta_score: 0.2137 - val_loss: 0.1316 - val_acc: 0.9499 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 169/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0918 - acc: 0.9707 - recall: 0.2368 - fbeta_score: 0.2409 - val_loss: 0.1319 - val_acc: 0.9477 - val_recall: 0.1346 - val_fbeta_score: 0.1418\n",
      "Epoch 170/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0917 - acc: 0.9702 - recall: 0.2075 - fbeta_score: 0.2126 - val_loss: 0.1318 - val_acc: 0.9499 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 171/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0916 - acc: 0.9697 - recall: 0.2279 - fbeta_score: 0.2327 - val_loss: 0.1319 - val_acc: 0.9488 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 172/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0915 - acc: 0.9702 - recall: 0.2059 - fbeta_score: 0.2088 - val_loss: 0.1317 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 173/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0914 - acc: 0.9707 - recall: 0.2384 - fbeta_score: 0.2376 - val_loss: 0.1317 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 174/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0914 - acc: 0.9702 - recall: 0.2181 - fbeta_score: 0.2187 - val_loss: 0.1318 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 175/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0912 - acc: 0.9707 - recall: 0.2228 - fbeta_score: 0.2308 - val_loss: 0.1317 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 176/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0912 - acc: 0.9702 - recall: 0.2271 - fbeta_score: 0.2326 - val_loss: 0.1317 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 177/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0911 - acc: 0.9712 - recall: 0.2222 - fbeta_score: 0.2244 - val_loss: 0.1319 - val_acc: 0.9499 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 178/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0910 - acc: 0.9707 - recall: 0.2116 - fbeta_score: 0.2163 - val_loss: 0.1318 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 179/1000\n",
      "2048/2048 [==============================] - ETA: 0s - loss: 0.0916 - acc: 0.9698 - recall: 0.2069 - fbeta_score: 0.2226     - 0s 81us/step - loss: 0.0909 - acc: 0.9707 - recall: 0.2116 - fbeta_score: 0.2222 - val_loss: 0.1319 - val_acc: 0.9488 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0908 - acc: 0.9707 - recall: 0.2185 - fbeta_score: 0.2239 - val_loss: 0.1319 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 181/1000\n",
      "2048/2048 [==============================] - 0s 81us/step - loss: 0.0907 - acc: 0.9707 - recall: 0.2051 - fbeta_score: 0.2147 - val_loss: 0.1320 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 182/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0906 - acc: 0.9702 - recall: 0.2401 - fbeta_score: 0.2456 - val_loss: 0.1321 - val_acc: 0.9488 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 183/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0905 - acc: 0.9697 - recall: 0.2157 - fbeta_score: 0.2212 - val_loss: 0.1320 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 184/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0904 - acc: 0.9702 - recall: 0.2327 - fbeta_score: 0.2383 - val_loss: 0.1322 - val_acc: 0.9499 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 185/1000\n",
      "2048/2048 [==============================] - 0s 82us/step - loss: 0.0904 - acc: 0.9712 - recall: 0.2108 - fbeta_score: 0.2217 - val_loss: 0.1321 - val_acc: 0.9488 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 186/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0903 - acc: 0.9702 - recall: 0.2132 - fbeta_score: 0.2202 - val_loss: 0.1321 - val_acc: 0.9499 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 187/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0902 - acc: 0.9707 - recall: 0.2165 - fbeta_score: 0.2271 - val_loss: 0.1321 - val_acc: 0.9499 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 188/1000\n",
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.0901 - acc: 0.9712 - recall: 0.2043 - fbeta_score: 0.2161 - val_loss: 0.1319 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 189/1000\n",
      "2048/2048 [==============================] - 0s 85us/step - loss: 0.0900 - acc: 0.9712 - recall: 0.2279 - fbeta_score: 0.2342 - val_loss: 0.1319 - val_acc: 0.9499 - val_recall: 0.1498 - val_fbeta_score: 0.1566\n",
      "Epoch 190/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0899 - acc: 0.9717 - recall: 0.2212 - fbeta_score: 0.2277 - val_loss: 0.1319 - val_acc: 0.9511 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 191/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0898 - acc: 0.9717 - recall: 0.2310 - fbeta_score: 0.2383 - val_loss: 0.1321 - val_acc: 0.9488 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 192/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0898 - acc: 0.9717 - recall: 0.2409 - fbeta_score: 0.2471 - val_loss: 0.1321 - val_acc: 0.9488 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 193/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0897 - acc: 0.9707 - recall: 0.2298 - fbeta_score: 0.2386 - val_loss: 0.1322 - val_acc: 0.9477 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 194/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0896 - acc: 0.9717 - recall: 0.2295 - fbeta_score: 0.2327 - val_loss: 0.1322 - val_acc: 0.9477 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 195/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0894 - acc: 0.9707 - recall: 0.2132 - fbeta_score: 0.2228 - val_loss: 0.1323 - val_acc: 0.9477 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 196/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0894 - acc: 0.9707 - recall: 0.2507 - fbeta_score: 0.2547 - val_loss: 0.1322 - val_acc: 0.9477 - val_recall: 0.1460 - val_fbeta_score: 0.1532\n",
      "Epoch 197/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0893 - acc: 0.9707 - recall: 0.2165 - fbeta_score: 0.2225 - val_loss: 0.1325 - val_acc: 0.9488 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 198/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0892 - acc: 0.9717 - recall: 0.2319 - fbeta_score: 0.2389 - val_loss: 0.1323 - val_acc: 0.9488 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 199/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0891 - acc: 0.9707 - recall: 0.2250 - fbeta_score: 0.2339 - val_loss: 0.1325 - val_acc: 0.9488 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 200/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0891 - acc: 0.9707 - recall: 0.2210 - fbeta_score: 0.2286 - val_loss: 0.1325 - val_acc: 0.9488 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 201/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0889 - acc: 0.9707 - recall: 0.2311 - fbeta_score: 0.2350 - val_loss: 0.1324 - val_acc: 0.9488 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 202/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0889 - acc: 0.9712 - recall: 0.2240 - fbeta_score: 0.2271 - val_loss: 0.1324 - val_acc: 0.9488 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 203/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0887 - acc: 0.9712 - recall: 0.2360 - fbeta_score: 0.2437 - val_loss: 0.1325 - val_acc: 0.9488 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 204/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0887 - acc: 0.9707 - recall: 0.2083 - fbeta_score: 0.2196 - val_loss: 0.1324 - val_acc: 0.9488 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 205/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0886 - acc: 0.9717 - recall: 0.2205 - fbeta_score: 0.2300 - val_loss: 0.1323 - val_acc: 0.9499 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 206/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0885 - acc: 0.9712 - recall: 0.2181 - fbeta_score: 0.2210 - val_loss: 0.1325 - val_acc: 0.9499 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 207/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0883 - acc: 0.9702 - recall: 0.2041 - fbeta_score: 0.2145 - val_loss: 0.1325 - val_acc: 0.9499 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 208/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0883 - acc: 0.9707 - recall: 0.2271 - fbeta_score: 0.2344 - val_loss: 0.1326 - val_acc: 0.9499 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 209/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0882 - acc: 0.9717 - recall: 0.2197 - fbeta_score: 0.2339 - val_loss: 0.1326 - val_acc: 0.9488 - val_recall: 0.1574 - val_fbeta_score: 0.1646\n",
      "Epoch 210/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0881 - acc: 0.9717 - recall: 0.2220 - fbeta_score: 0.2332 - val_loss: 0.1324 - val_acc: 0.9499 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 211/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0880 - acc: 0.9717 - recall: 0.2204 - fbeta_score: 0.2284 - val_loss: 0.1325 - val_acc: 0.9499 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 212/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0879 - acc: 0.9722 - recall: 0.2318 - fbeta_score: 0.2430 - val_loss: 0.1325 - val_acc: 0.9499 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 213/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0878 - acc: 0.9722 - recall: 0.2570 - fbeta_score: 0.2593 - val_loss: 0.1325 - val_acc: 0.9499 - val_recall: 0.1612 - val_fbeta_score: 0.1680\n",
      "Epoch 214/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0877 - acc: 0.9722 - recall: 0.2178 - fbeta_score: 0.2265 - val_loss: 0.1326 - val_acc: 0.9522 - val_recall: 0.1782 - val_fbeta_score: 0.1870\n",
      "Epoch 215/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0876 - acc: 0.9717 - recall: 0.2326 - fbeta_score: 0.2417 - val_loss: 0.1328 - val_acc: 0.9499 - val_recall: 0.1688 - val_fbeta_score: 0.1760\n",
      "Epoch 216/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0875 - acc: 0.9707 - recall: 0.2253 - fbeta_score: 0.2310 - val_loss: 0.1328 - val_acc: 0.9499 - val_recall: 0.1688 - val_fbeta_score: 0.1760\n",
      "Epoch 217/1000\n",
      "2048/2048 [==============================] - 0s 80us/step - loss: 0.0874 - acc: 0.9712 - recall: 0.2246 - fbeta_score: 0.2358 - val_loss: 0.1327 - val_acc: 0.9511 - val_recall: 0.1725 - val_fbeta_score: 0.1794\n",
      "Epoch 218/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0873 - acc: 0.9722 - recall: 0.2334 - fbeta_score: 0.2397 - val_loss: 0.1328 - val_acc: 0.9499 - val_recall: 0.1688 - val_fbeta_score: 0.1760\n",
      "Epoch 219/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0872 - acc: 0.9722 - recall: 0.2279 - fbeta_score: 0.2373 - val_loss: 0.1328 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1835\n",
      "Epoch 220/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0871 - acc: 0.9717 - recall: 0.2214 - fbeta_score: 0.2332 - val_loss: 0.1331 - val_acc: 0.9499 - val_recall: 0.1688 - val_fbeta_score: 0.1760\n",
      "Epoch 221/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0870 - acc: 0.9717 - recall: 0.2091 - fbeta_score: 0.2155 - val_loss: 0.1330 - val_acc: 0.9499 - val_recall: 0.1688 - val_fbeta_score: 0.1760\n",
      "Epoch 222/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0869 - acc: 0.9717 - recall: 0.2336 - fbeta_score: 0.2383 - val_loss: 0.1330 - val_acc: 0.9499 - val_recall: 0.1688 - val_fbeta_score: 0.1760\n",
      "Epoch 223/1000\n",
      "2048/2048 [==============================] - 0s 82us/step - loss: 0.0868 - acc: 0.9722 - recall: 0.2425 - fbeta_score: 0.2456 - val_loss: 0.1331 - val_acc: 0.9499 - val_recall: 0.1688 - val_fbeta_score: 0.1760\n",
      "Epoch 224/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0868 - acc: 0.9722 - recall: 0.2127 - fbeta_score: 0.2229 - val_loss: 0.1331 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1835\n",
      "Epoch 225/1000\n",
      "2048/2048 [==============================] - 0s 81us/step - loss: 0.0866 - acc: 0.9722 - recall: 0.2360 - fbeta_score: 0.2438 - val_loss: 0.1331 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1835\n",
      "Epoch 226/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0865 - acc: 0.9722 - recall: 0.2173 - fbeta_score: 0.2222 - val_loss: 0.1330 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1835\n",
      "Epoch 227/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0864 - acc: 0.9722 - recall: 0.2389 - fbeta_score: 0.2441 - val_loss: 0.1331 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1835\n",
      "Epoch 228/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0863 - acc: 0.9717 - recall: 0.2344 - fbeta_score: 0.2425 - val_loss: 0.1333 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1835\n",
      "Epoch 229/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0862 - acc: 0.9717 - recall: 0.2588 - fbeta_score: 0.2603 - val_loss: 0.1334 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 230/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0861 - acc: 0.9717 - recall: 0.2425 - fbeta_score: 0.2463 - val_loss: 0.1332 - val_acc: 0.9511 - val_recall: 0.1782 - val_fbeta_score: 0.1847\n",
      "Epoch 231/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0860 - acc: 0.9717 - recall: 0.2515 - fbeta_score: 0.2586 - val_loss: 0.1333 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1835\n",
      "Epoch 232/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0859 - acc: 0.9727 - recall: 0.2279 - fbeta_score: 0.2287 - val_loss: 0.1333 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 233/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0858 - acc: 0.9722 - recall: 0.2336 - fbeta_score: 0.2375 - val_loss: 0.1333 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 234/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0857 - acc: 0.9712 - recall: 0.2197 - fbeta_score: 0.2253 - val_loss: 0.1337 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 235/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0856 - acc: 0.9722 - recall: 0.2465 - fbeta_score: 0.2502 - val_loss: 0.1337 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 236/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0855 - acc: 0.9722 - recall: 0.2344 - fbeta_score: 0.2428 - val_loss: 0.1339 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 237/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0854 - acc: 0.9722 - recall: 0.2417 - fbeta_score: 0.2490 - val_loss: 0.1337 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 238/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0853 - acc: 0.9722 - recall: 0.2220 - fbeta_score: 0.2308 - val_loss: 0.1337 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 239/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0852 - acc: 0.9717 - recall: 0.2371 - fbeta_score: 0.2417 - val_loss: 0.1335 - val_acc: 0.9522 - val_recall: 0.1896 - val_fbeta_score: 0.1961\n",
      "Epoch 240/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0851 - acc: 0.9722 - recall: 0.2318 - fbeta_score: 0.2375 - val_loss: 0.1338 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 241/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0851 - acc: 0.9722 - recall: 0.2375 - fbeta_score: 0.2406 - val_loss: 0.1338 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 242/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0850 - acc: 0.9722 - recall: 0.2246 - fbeta_score: 0.2360 - val_loss: 0.1340 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 243/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0848 - acc: 0.9717 - recall: 0.2490 - fbeta_score: 0.2546 - val_loss: 0.1342 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 244/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0848 - acc: 0.9727 - recall: 0.2464 - fbeta_score: 0.2536 - val_loss: 0.1340 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 245/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0847 - acc: 0.9722 - recall: 0.2368 - fbeta_score: 0.2432 - val_loss: 0.1342 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 246/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0846 - acc: 0.9717 - recall: 0.2384 - fbeta_score: 0.2497 - val_loss: 0.1342 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 247/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0845 - acc: 0.9717 - recall: 0.2287 - fbeta_score: 0.2357 - val_loss: 0.1345 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 248/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0844 - acc: 0.9722 - recall: 0.2314 - fbeta_score: 0.2336 - val_loss: 0.1345 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 249/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0843 - acc: 0.9722 - recall: 0.2498 - fbeta_score: 0.2562 - val_loss: 0.1346 - val_acc: 0.9511 - val_recall: 0.1858 - val_fbeta_score: 0.1926\n",
      "Epoch 250/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0842 - acc: 0.9717 - recall: 0.2246 - fbeta_score: 0.2311 - val_loss: 0.1347 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 251/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0841 - acc: 0.9717 - recall: 0.2132 - fbeta_score: 0.2186 - val_loss: 0.1347 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 252/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.0840 - acc: 0.9722 - recall: 0.2401 - fbeta_score: 0.2454 - val_loss: 0.1348 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 253/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0839 - acc: 0.9727 - recall: 0.2472 - fbeta_score: 0.2521 - val_loss: 0.1348 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 254/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0838 - acc: 0.9722 - recall: 0.2612 - fbeta_score: 0.2637 - val_loss: 0.1350 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 255/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0838 - acc: 0.9722 - recall: 0.2466 - fbeta_score: 0.2537 - val_loss: 0.1348 - val_acc: 0.9511 - val_recall: 0.1858 - val_fbeta_score: 0.1926\n",
      "Epoch 256/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0837 - acc: 0.9727 - recall: 0.2407 - fbeta_score: 0.2495 - val_loss: 0.1348 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 257/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0835 - acc: 0.9727 - recall: 0.2482 - fbeta_score: 0.2523 - val_loss: 0.1349 - val_acc: 0.9499 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 258/1000\n",
      "2048/2048 [==============================] - 0s 83us/step - loss: 0.0835 - acc: 0.9731 - recall: 0.2367 - fbeta_score: 0.2469 - val_loss: 0.1349 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 259/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0834 - acc: 0.9727 - recall: 0.2401 - fbeta_score: 0.2464 - val_loss: 0.1347 - val_acc: 0.9534 - val_recall: 0.1896 - val_fbeta_score: 0.1961\n",
      "Epoch 260/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0833 - acc: 0.9717 - recall: 0.2509 - fbeta_score: 0.2523 - val_loss: 0.1351 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 261/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0832 - acc: 0.9731 - recall: 0.2637 - fbeta_score: 0.2669 - val_loss: 0.1351 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 262/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0831 - acc: 0.9727 - recall: 0.2336 - fbeta_score: 0.2401 - val_loss: 0.1350 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 263/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0831 - acc: 0.9731 - recall: 0.2433 - fbeta_score: 0.2539 - val_loss: 0.1353 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 264/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0830 - acc: 0.9731 - recall: 0.2436 - fbeta_score: 0.2492 - val_loss: 0.1352 - val_acc: 0.9534 - val_recall: 0.1972 - val_fbeta_score: 0.2040\n",
      "Epoch 265/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0828 - acc: 0.9727 - recall: 0.2466 - fbeta_score: 0.2523 - val_loss: 0.1355 - val_acc: 0.9522 - val_recall: 0.1858 - val_fbeta_score: 0.1926\n",
      "Epoch 266/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0828 - acc: 0.9727 - recall: 0.2515 - fbeta_score: 0.2529 - val_loss: 0.1354 - val_acc: 0.9534 - val_recall: 0.1972 - val_fbeta_score: 0.2040\n",
      "Epoch 267/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0827 - acc: 0.9727 - recall: 0.2352 - fbeta_score: 0.2432 - val_loss: 0.1356 - val_acc: 0.9522 - val_recall: 0.1972 - val_fbeta_score: 0.2040\n",
      "Epoch 268/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0826 - acc: 0.9727 - recall: 0.2596 - fbeta_score: 0.2609 - val_loss: 0.1357 - val_acc: 0.9511 - val_recall: 0.1858 - val_fbeta_score: 0.1926\n",
      "Epoch 269/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0825 - acc: 0.9731 - recall: 0.2079 - fbeta_score: 0.2091 - val_loss: 0.1358 - val_acc: 0.9511 - val_recall: 0.1744 - val_fbeta_score: 0.1813\n",
      "Epoch 270/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0824 - acc: 0.9731 - recall: 0.2566 - fbeta_score: 0.2557 - val_loss: 0.1359 - val_acc: 0.9511 - val_recall: 0.1858 - val_fbeta_score: 0.1926\n",
      "Epoch 271/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0823 - acc: 0.9727 - recall: 0.2327 - fbeta_score: 0.2383 - val_loss: 0.1358 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 272/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0822 - acc: 0.9731 - recall: 0.2384 - fbeta_score: 0.2463 - val_loss: 0.1356 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 273/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0822 - acc: 0.9727 - recall: 0.2433 - fbeta_score: 0.2531 - val_loss: 0.1358 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 274/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0821 - acc: 0.9727 - recall: 0.2287 - fbeta_score: 0.2336 - val_loss: 0.1361 - val_acc: 0.9511 - val_recall: 0.1858 - val_fbeta_score: 0.1926\n",
      "Epoch 275/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0819 - acc: 0.9731 - recall: 0.2425 - fbeta_score: 0.2448 - val_loss: 0.1358 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 276/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0819 - acc: 0.9736 - recall: 0.2441 - fbeta_score: 0.2497 - val_loss: 0.1357 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 277/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0818 - acc: 0.9731 - recall: 0.2570 - fbeta_score: 0.2642 - val_loss: 0.1359 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 278/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0818 - acc: 0.9731 - recall: 0.2287 - fbeta_score: 0.2340 - val_loss: 0.1360 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 279/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0817 - acc: 0.9731 - recall: 0.2122 - fbeta_score: 0.2243 - val_loss: 0.1360 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 280/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0816 - acc: 0.9736 - recall: 0.2507 - fbeta_score: 0.2588 - val_loss: 0.1361 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 281/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0814 - acc: 0.9736 - recall: 0.2507 - fbeta_score: 0.2563 - val_loss: 0.1362 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 282/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0814 - acc: 0.9731 - recall: 0.2336 - fbeta_score: 0.2424 - val_loss: 0.1363 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 283/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0813 - acc: 0.9736 - recall: 0.2490 - fbeta_score: 0.2522 - val_loss: 0.1364 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 284/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0812 - acc: 0.9736 - recall: 0.2424 - fbeta_score: 0.2497 - val_loss: 0.1364 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 285/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0811 - acc: 0.9736 - recall: 0.2523 - fbeta_score: 0.2562 - val_loss: 0.1364 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2074\n",
      "Epoch 286/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0810 - acc: 0.9736 - recall: 0.2498 - fbeta_score: 0.2546 - val_loss: 0.1362 - val_acc: 0.9556 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 287/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0810 - acc: 0.9731 - recall: 0.2415 - fbeta_score: 0.2529 - val_loss: 0.1362 - val_acc: 0.9556 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 288/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0809 - acc: 0.9736 - recall: 0.2494 - fbeta_score: 0.2602 - val_loss: 0.1363 - val_acc: 0.9556 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 289/1000\n",
      "2048/2048 [==============================] - 0s 81us/step - loss: 0.0808 - acc: 0.9736 - recall: 0.2441 - fbeta_score: 0.2482 - val_loss: 0.1366 - val_acc: 0.9545 - val_recall: 0.1896 - val_fbeta_score: 0.1983\n",
      "Epoch 290/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0807 - acc: 0.9736 - recall: 0.2507 - fbeta_score: 0.2555 - val_loss: 0.1368 - val_acc: 0.9534 - val_recall: 0.1858 - val_fbeta_score: 0.1949\n",
      "Epoch 291/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0806 - acc: 0.9736 - recall: 0.2523 - fbeta_score: 0.2593 - val_loss: 0.1366 - val_acc: 0.9534 - val_recall: 0.1858 - val_fbeta_score: 0.1949\n",
      "Epoch 292/1000\n",
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.0805 - acc: 0.9736 - recall: 0.2490 - fbeta_score: 0.2554 - val_loss: 0.1367 - val_acc: 0.9556 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 293/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0805 - acc: 0.9736 - recall: 0.2401 - fbeta_score: 0.2448 - val_loss: 0.1367 - val_acc: 0.9556 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 294/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0804 - acc: 0.9736 - recall: 0.2507 - fbeta_score: 0.2562 - val_loss: 0.1366 - val_acc: 0.9556 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 295/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0803 - acc: 0.9736 - recall: 0.2527 - fbeta_score: 0.2624 - val_loss: 0.1367 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 296/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0802 - acc: 0.9736 - recall: 0.2327 - fbeta_score: 0.2389 - val_loss: 0.1368 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 297/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0801 - acc: 0.9736 - recall: 0.2261 - fbeta_score: 0.2321 - val_loss: 0.1370 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 298/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0800 - acc: 0.9736 - recall: 0.2550 - fbeta_score: 0.2655 - val_loss: 0.1369 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 299/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0799 - acc: 0.9741 - recall: 0.2505 - fbeta_score: 0.2537 - val_loss: 0.1368 - val_acc: 0.9556 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 300/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0798 - acc: 0.9736 - recall: 0.2604 - fbeta_score: 0.2630 - val_loss: 0.1367 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 301/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0797 - acc: 0.9731 - recall: 0.2266 - fbeta_score: 0.2374 - val_loss: 0.1369 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 302/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0797 - acc: 0.9741 - recall: 0.2401 - fbeta_score: 0.2458 - val_loss: 0.1369 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 303/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0796 - acc: 0.9741 - recall: 0.2362 - fbeta_score: 0.2447 - val_loss: 0.1369 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 304/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0795 - acc: 0.9741 - recall: 0.2563 - fbeta_score: 0.2619 - val_loss: 0.1369 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 305/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0794 - acc: 0.9736 - recall: 0.2466 - fbeta_score: 0.2521 - val_loss: 0.1371 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 306/1000\n",
      "2048/2048 [==============================] - 0s 81us/step - loss: 0.0792 - acc: 0.9741 - recall: 0.2417 - fbeta_score: 0.2479 - val_loss: 0.1373 - val_acc: 0.9534 - val_recall: 0.1896 - val_fbeta_score: 0.1983\n",
      "Epoch 307/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0792 - acc: 0.9741 - recall: 0.2507 - fbeta_score: 0.2563 - val_loss: 0.1372 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 308/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0791 - acc: 0.9736 - recall: 0.2515 - fbeta_score: 0.2588 - val_loss: 0.1372 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 309/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0790 - acc: 0.9741 - recall: 0.2450 - fbeta_score: 0.2562 - val_loss: 0.1372 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 310/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0789 - acc: 0.9741 - recall: 0.2409 - fbeta_score: 0.2472 - val_loss: 0.1370 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 311/1000\n",
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.0788 - acc: 0.9731 - recall: 0.2458 - fbeta_score: 0.2528 - val_loss: 0.1373 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 312/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0787 - acc: 0.9741 - recall: 0.2303 - fbeta_score: 0.2415 - val_loss: 0.1373 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 313/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0786 - acc: 0.9741 - recall: 0.2409 - fbeta_score: 0.2454 - val_loss: 0.1377 - val_acc: 0.9534 - val_recall: 0.1896 - val_fbeta_score: 0.1983\n",
      "Epoch 314/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0786 - acc: 0.9736 - recall: 0.2287 - fbeta_score: 0.2350 - val_loss: 0.1376 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 315/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0785 - acc: 0.9741 - recall: 0.2620 - fbeta_score: 0.2653 - val_loss: 0.1377 - val_acc: 0.9534 - val_recall: 0.1896 - val_fbeta_score: 0.1983\n",
      "Epoch 316/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0784 - acc: 0.9736 - recall: 0.2458 - fbeta_score: 0.2547 - val_loss: 0.1377 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 317/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0782 - acc: 0.9741 - recall: 0.2515 - fbeta_score: 0.2578 - val_loss: 0.1375 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 318/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0782 - acc: 0.9741 - recall: 0.2470 - fbeta_score: 0.2540 - val_loss: 0.1378 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 319/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0781 - acc: 0.9736 - recall: 0.2611 - fbeta_score: 0.2655 - val_loss: 0.1378 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 320/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0780 - acc: 0.9741 - recall: 0.2383 - fbeta_score: 0.2424 - val_loss: 0.1379 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 321/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0779 - acc: 0.9741 - recall: 0.2531 - fbeta_score: 0.2580 - val_loss: 0.1378 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 322/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0779 - acc: 0.9741 - recall: 0.2421 - fbeta_score: 0.2500 - val_loss: 0.1379 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 323/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0777 - acc: 0.9741 - recall: 0.2741 - fbeta_score: 0.2738 - val_loss: 0.1378 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0776 - acc: 0.9741 - recall: 0.2350 - fbeta_score: 0.2415 - val_loss: 0.1378 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 325/1000\n",
      "2048/2048 [==============================] - 0s 83us/step - loss: 0.0775 - acc: 0.9741 - recall: 0.2515 - fbeta_score: 0.2570 - val_loss: 0.1378 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 326/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0774 - acc: 0.9731 - recall: 0.2425 - fbeta_score: 0.2482 - val_loss: 0.1380 - val_acc: 0.9556 - val_recall: 0.2124 - val_fbeta_score: 0.2211\n",
      "Epoch 327/1000\n",
      "2048/2048 [==============================] - 0s 81us/step - loss: 0.0773 - acc: 0.9741 - recall: 0.2490 - fbeta_score: 0.2529 - val_loss: 0.1383 - val_acc: 0.9545 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 328/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0773 - acc: 0.9746 - recall: 0.2482 - fbeta_score: 0.2541 - val_loss: 0.1382 - val_acc: 0.9556 - val_recall: 0.2124 - val_fbeta_score: 0.2211\n",
      "Epoch 329/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0772 - acc: 0.9731 - recall: 0.2510 - fbeta_score: 0.2612 - val_loss: 0.1384 - val_acc: 0.9556 - val_recall: 0.2124 - val_fbeta_score: 0.2211\n",
      "Epoch 330/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0771 - acc: 0.9741 - recall: 0.2507 - fbeta_score: 0.2588 - val_loss: 0.1384 - val_acc: 0.9556 - val_recall: 0.2124 - val_fbeta_score: 0.2211\n",
      "Epoch 331/1000\n",
      "2048/2048 [==============================] - 0s 86us/step - loss: 0.0770 - acc: 0.9741 - recall: 0.2441 - fbeta_score: 0.2489 - val_loss: 0.1383 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2211\n",
      "Epoch 332/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0769 - acc: 0.9741 - recall: 0.2367 - fbeta_score: 0.2415 - val_loss: 0.1383 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2211\n",
      "Epoch 333/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0768 - acc: 0.9731 - recall: 0.2197 - fbeta_score: 0.2267 - val_loss: 0.1381 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 334/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0767 - acc: 0.9746 - recall: 0.2336 - fbeta_score: 0.2432 - val_loss: 0.1382 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 335/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0766 - acc: 0.9736 - recall: 0.2563 - fbeta_score: 0.2607 - val_loss: 0.1382 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 336/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0765 - acc: 0.9746 - recall: 0.2523 - fbeta_score: 0.2586 - val_loss: 0.1386 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 337/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0765 - acc: 0.9746 - recall: 0.2563 - fbeta_score: 0.2637 - val_loss: 0.1385 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2211\n",
      "Epoch 338/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0764 - acc: 0.9746 - recall: 0.2661 - fbeta_score: 0.2733 - val_loss: 0.1384 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2211\n",
      "Epoch 339/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0763 - acc: 0.9746 - recall: 0.2563 - fbeta_score: 0.2633 - val_loss: 0.1384 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 340/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0762 - acc: 0.9756 - recall: 0.2775 - fbeta_score: 0.2829 - val_loss: 0.1387 - val_acc: 0.9534 - val_recall: 0.2010 - val_fbeta_score: 0.2097\n",
      "Epoch 341/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0761 - acc: 0.9746 - recall: 0.2686 - fbeta_score: 0.2754 - val_loss: 0.1386 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2211\n",
      "Epoch 342/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0760 - acc: 0.9756 - recall: 0.2708 - fbeta_score: 0.2747 - val_loss: 0.1384 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2211\n",
      "Epoch 343/1000\n",
      "2048/2048 [==============================] - 0s 85us/step - loss: 0.0759 - acc: 0.9741 - recall: 0.2596 - fbeta_score: 0.2643 - val_loss: 0.1384 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 344/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0759 - acc: 0.9756 - recall: 0.2627 - fbeta_score: 0.2668 - val_loss: 0.1387 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 345/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0758 - acc: 0.9746 - recall: 0.2596 - fbeta_score: 0.2723 - val_loss: 0.1387 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 346/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0757 - acc: 0.9756 - recall: 0.2725 - fbeta_score: 0.2804 - val_loss: 0.1387 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 347/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0756 - acc: 0.9751 - recall: 0.2596 - fbeta_score: 0.2660 - val_loss: 0.1386 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 348/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0755 - acc: 0.9751 - recall: 0.2310 - fbeta_score: 0.2399 - val_loss: 0.1389 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 349/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0754 - acc: 0.9761 - recall: 0.2832 - fbeta_score: 0.2865 - val_loss: 0.1387 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 350/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0753 - acc: 0.9746 - recall: 0.2604 - fbeta_score: 0.2677 - val_loss: 0.1389 - val_acc: 0.9545 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 351/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0753 - acc: 0.9756 - recall: 0.2620 - fbeta_score: 0.2643 - val_loss: 0.1387 - val_acc: 0.9556 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 352/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0752 - acc: 0.9761 - recall: 0.2393 - fbeta_score: 0.2505 - val_loss: 0.1388 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 353/1000\n",
      "2048/2048 [==============================] - 0s 105us/step - loss: 0.0751 - acc: 0.9746 - recall: 0.2726 - fbeta_score: 0.2770 - val_loss: 0.1392 - val_acc: 0.9545 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 354/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0750 - acc: 0.9761 - recall: 0.2848 - fbeta_score: 0.2879 - val_loss: 0.1388 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 355/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0749 - acc: 0.9761 - recall: 0.3044 - fbeta_score: 0.3073 - val_loss: 0.1392 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 356/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0748 - acc: 0.9751 - recall: 0.2554 - fbeta_score: 0.2664 - val_loss: 0.1390 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 357/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0748 - acc: 0.9766 - recall: 0.2669 - fbeta_score: 0.2668 - val_loss: 0.1390 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 358/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0747 - acc: 0.9756 - recall: 0.2718 - fbeta_score: 0.2765 - val_loss: 0.1389 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 359/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0746 - acc: 0.9756 - recall: 0.2519 - fbeta_score: 0.2573 - val_loss: 0.1393 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 360/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0745 - acc: 0.9766 - recall: 0.2651 - fbeta_score: 0.2676 - val_loss: 0.1391 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 361/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0744 - acc: 0.9761 - recall: 0.2734 - fbeta_score: 0.2827 - val_loss: 0.1394 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 362/1000\n",
      "2048/2048 [==============================] - 0s 83us/step - loss: 0.0743 - acc: 0.9761 - recall: 0.2669 - fbeta_score: 0.2700 - val_loss: 0.1391 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 363/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0743 - acc: 0.9756 - recall: 0.2743 - fbeta_score: 0.2793 - val_loss: 0.1392 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 364/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0742 - acc: 0.9766 - recall: 0.2710 - fbeta_score: 0.2751 - val_loss: 0.1392 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 365/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0741 - acc: 0.9775 - recall: 0.2677 - fbeta_score: 0.2731 - val_loss: 0.1391 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 366/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0741 - acc: 0.9761 - recall: 0.2596 - fbeta_score: 0.2690 - val_loss: 0.1393 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 367/1000\n",
      "2048/2048 [==============================] - 0s 82us/step - loss: 0.0740 - acc: 0.9771 - recall: 0.2925 - fbeta_score: 0.2962 - val_loss: 0.1393 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 368/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0739 - acc: 0.9766 - recall: 0.2612 - fbeta_score: 0.2700 - val_loss: 0.1394 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 369/1000\n",
      "2048/2048 [==============================] - 0s 81us/step - loss: 0.0738 - acc: 0.9771 - recall: 0.2645 - fbeta_score: 0.2682 - val_loss: 0.1396 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 370/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0737 - acc: 0.9766 - recall: 0.2946 - fbeta_score: 0.2977 - val_loss: 0.1396 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 371/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0736 - acc: 0.9771 - recall: 0.2775 - fbeta_score: 0.2808 - val_loss: 0.1396 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 372/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0736 - acc: 0.9766 - recall: 0.2783 - fbeta_score: 0.2863 - val_loss: 0.1396 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 373/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0735 - acc: 0.9775 - recall: 0.2876 - fbeta_score: 0.2962 - val_loss: 0.1395 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 374/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0734 - acc: 0.9766 - recall: 0.2535 - fbeta_score: 0.2635 - val_loss: 0.1394 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 375/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0733 - acc: 0.9771 - recall: 0.2718 - fbeta_score: 0.2741 - val_loss: 0.1392 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 376/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0733 - acc: 0.9771 - recall: 0.2775 - fbeta_score: 0.2824 - val_loss: 0.1391 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 377/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0732 - acc: 0.9771 - recall: 0.2450 - fbeta_score: 0.2495 - val_loss: 0.1393 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 378/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0731 - acc: 0.9775 - recall: 0.2759 - fbeta_score: 0.2842 - val_loss: 0.1395 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 379/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0731 - acc: 0.9771 - recall: 0.2588 - fbeta_score: 0.2603 - val_loss: 0.1396 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 380/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0730 - acc: 0.9775 - recall: 0.2537 - fbeta_score: 0.2630 - val_loss: 0.1396 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 381/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0729 - acc: 0.9775 - recall: 0.2904 - fbeta_score: 0.2926 - val_loss: 0.1400 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 382/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0728 - acc: 0.9771 - recall: 0.2710 - fbeta_score: 0.2782 - val_loss: 0.1399 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 383/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0728 - acc: 0.9775 - recall: 0.2588 - fbeta_score: 0.2660 - val_loss: 0.1401 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 384/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0727 - acc: 0.9775 - recall: 0.3092 - fbeta_score: 0.3109 - val_loss: 0.1400 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 385/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0726 - acc: 0.9771 - recall: 0.2879 - fbeta_score: 0.2878 - val_loss: 0.1401 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 386/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0726 - acc: 0.9771 - recall: 0.2696 - fbeta_score: 0.2757 - val_loss: 0.1401 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 387/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0725 - acc: 0.9775 - recall: 0.2725 - fbeta_score: 0.2725 - val_loss: 0.1401 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 388/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0724 - acc: 0.9775 - recall: 0.2718 - fbeta_score: 0.2731 - val_loss: 0.1402 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 389/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0723 - acc: 0.9775 - recall: 0.2596 - fbeta_score: 0.2653 - val_loss: 0.1403 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 390/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0722 - acc: 0.9775 - recall: 0.2892 - fbeta_score: 0.2956 - val_loss: 0.1402 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 391/1000\n",
      "2048/2048 [==============================] - 0s 111us/step - loss: 0.0722 - acc: 0.9775 - recall: 0.2922 - fbeta_score: 0.2995 - val_loss: 0.1401 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 392/1000\n",
      "2048/2048 [==============================] - 0s 111us/step - loss: 0.0721 - acc: 0.9775 - recall: 0.2637 - fbeta_score: 0.2710 - val_loss: 0.1404 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 393/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0720 - acc: 0.9771 - recall: 0.2759 - fbeta_score: 0.2847 - val_loss: 0.1405 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 394/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0720 - acc: 0.9771 - recall: 0.2604 - fbeta_score: 0.2652 - val_loss: 0.1405 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 395/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0719 - acc: 0.9780 - recall: 0.2804 - fbeta_score: 0.2799 - val_loss: 0.1405 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 396/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0718 - acc: 0.9780 - recall: 0.2775 - fbeta_score: 0.2796 - val_loss: 0.1408 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 397/1000\n",
      "2048/2048 [==============================] - 0s 82us/step - loss: 0.0718 - acc: 0.9775 - recall: 0.2904 - fbeta_score: 0.2951 - val_loss: 0.1408 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 398/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0717 - acc: 0.9780 - recall: 0.2550 - fbeta_score: 0.2611 - val_loss: 0.1407 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 399/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0716 - acc: 0.9775 - recall: 0.2669 - fbeta_score: 0.2765 - val_loss: 0.1408 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 400/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0716 - acc: 0.9780 - recall: 0.2816 - fbeta_score: 0.2796 - val_loss: 0.1407 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 401/1000\n",
      "2048/2048 [==============================] - 0s 82us/step - loss: 0.0715 - acc: 0.9785 - recall: 0.2734 - fbeta_score: 0.2826 - val_loss: 0.1407 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 402/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0714 - acc: 0.9780 - recall: 0.2543 - fbeta_score: 0.2579 - val_loss: 0.1409 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 403/1000\n",
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.0714 - acc: 0.9780 - recall: 0.2555 - fbeta_score: 0.2635 - val_loss: 0.1408 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 404/1000\n",
      "2048/2048 [==============================] - 0s 86us/step - loss: 0.0713 - acc: 0.9780 - recall: 0.2554 - fbeta_score: 0.2576 - val_loss: 0.1408 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 405/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0713 - acc: 0.9785 - recall: 0.2572 - fbeta_score: 0.2633 - val_loss: 0.1408 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 406/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0711 - acc: 0.9775 - recall: 0.2881 - fbeta_score: 0.2887 - val_loss: 0.1408 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 407/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0711 - acc: 0.9785 - recall: 0.3158 - fbeta_score: 0.3148 - val_loss: 0.1410 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 408/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0710 - acc: 0.9790 - recall: 0.2881 - fbeta_score: 0.2923 - val_loss: 0.1410 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 409/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0710 - acc: 0.9780 - recall: 0.2783 - fbeta_score: 0.2845 - val_loss: 0.1410 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 410/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0709 - acc: 0.9780 - recall: 0.2930 - fbeta_score: 0.2967 - val_loss: 0.1409 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 411/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0708 - acc: 0.9780 - recall: 0.2861 - fbeta_score: 0.2928 - val_loss: 0.1411 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 412/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0708 - acc: 0.9771 - recall: 0.2547 - fbeta_score: 0.2598 - val_loss: 0.1414 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 413/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0707 - acc: 0.9785 - recall: 0.2840 - fbeta_score: 0.2902 - val_loss: 0.1413 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 414/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0706 - acc: 0.9785 - recall: 0.2783 - fbeta_score: 0.2822 - val_loss: 0.1411 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 415/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0705 - acc: 0.9785 - recall: 0.2820 - fbeta_score: 0.2840 - val_loss: 0.1416 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 416/1000\n",
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.0705 - acc: 0.9780 - recall: 0.2920 - fbeta_score: 0.2967 - val_loss: 0.1412 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 417/1000\n",
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.0705 - acc: 0.9780 - recall: 0.2712 - fbeta_score: 0.2737 - val_loss: 0.1413 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 418/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0704 - acc: 0.9790 - recall: 0.2726 - fbeta_score: 0.2773 - val_loss: 0.1414 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 419/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0703 - acc: 0.9785 - recall: 0.2832 - fbeta_score: 0.2894 - val_loss: 0.1414 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 420/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0703 - acc: 0.9785 - recall: 0.2977 - fbeta_score: 0.3024 - val_loss: 0.1415 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 421/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0702 - acc: 0.9780 - recall: 0.3015 - fbeta_score: 0.2986 - val_loss: 0.1417 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 422/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0701 - acc: 0.9775 - recall: 0.2695 - fbeta_score: 0.2767 - val_loss: 0.1415 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 423/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0701 - acc: 0.9790 - recall: 0.2938 - fbeta_score: 0.2985 - val_loss: 0.1417 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 424/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0700 - acc: 0.9795 - recall: 0.2962 - fbeta_score: 0.3018 - val_loss: 0.1420 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 425/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0699 - acc: 0.9795 - recall: 0.2716 - fbeta_score: 0.2731 - val_loss: 0.1422 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 426/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0699 - acc: 0.9790 - recall: 0.2896 - fbeta_score: 0.2959 - val_loss: 0.1420 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 427/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0698 - acc: 0.9785 - recall: 0.2848 - fbeta_score: 0.2856 - val_loss: 0.1421 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 428/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0698 - acc: 0.9780 - recall: 0.2791 - fbeta_score: 0.2832 - val_loss: 0.1418 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 429/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0697 - acc: 0.9800 - recall: 0.3084 - fbeta_score: 0.3180 - val_loss: 0.1419 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 430/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0696 - acc: 0.9790 - recall: 0.2930 - fbeta_score: 0.2965 - val_loss: 0.1422 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 431/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0696 - acc: 0.9790 - recall: 0.2832 - fbeta_score: 0.2881 - val_loss: 0.1423 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 432/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0695 - acc: 0.9790 - recall: 0.2896 - fbeta_score: 0.2928 - val_loss: 0.1426 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 433/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0695 - acc: 0.9790 - recall: 0.2840 - fbeta_score: 0.2926 - val_loss: 0.1422 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 434/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0694 - acc: 0.9785 - recall: 0.2767 - fbeta_score: 0.2869 - val_loss: 0.1419 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 435/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0693 - acc: 0.9790 - recall: 0.2799 - fbeta_score: 0.2824 - val_loss: 0.1423 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 436/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0693 - acc: 0.9790 - recall: 0.2791 - fbeta_score: 0.2871 - val_loss: 0.1422 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 437/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0692 - acc: 0.9785 - recall: 0.2778 - fbeta_score: 0.2814 - val_loss: 0.1425 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 438/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0692 - acc: 0.9790 - recall: 0.2942 - fbeta_score: 0.3002 - val_loss: 0.1425 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 439/1000\n",
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.0691 - acc: 0.9800 - recall: 0.2708 - fbeta_score: 0.2801 - val_loss: 0.1426 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 440/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0690 - acc: 0.9790 - recall: 0.2766 - fbeta_score: 0.2776 - val_loss: 0.1424 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 441/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0690 - acc: 0.9795 - recall: 0.2995 - fbeta_score: 0.3015 - val_loss: 0.1426 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 442/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0689 - acc: 0.9795 - recall: 0.2987 - fbeta_score: 0.2969 - val_loss: 0.1427 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 443/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0689 - acc: 0.9805 - recall: 0.2763 - fbeta_score: 0.2853 - val_loss: 0.1428 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 444/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0688 - acc: 0.9790 - recall: 0.2753 - fbeta_score: 0.2807 - val_loss: 0.1427 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 445/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0687 - acc: 0.9795 - recall: 0.2782 - fbeta_score: 0.2829 - val_loss: 0.1427 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 446/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0687 - acc: 0.9790 - recall: 0.2648 - fbeta_score: 0.2756 - val_loss: 0.1425 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 447/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0686 - acc: 0.9805 - recall: 0.2767 - fbeta_score: 0.2821 - val_loss: 0.1427 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 448/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0685 - acc: 0.9795 - recall: 0.2741 - fbeta_score: 0.2793 - val_loss: 0.1431 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 449/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0685 - acc: 0.9795 - recall: 0.3068 - fbeta_score: 0.3075 - val_loss: 0.1432 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 450/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0684 - acc: 0.9785 - recall: 0.2946 - fbeta_score: 0.2992 - val_loss: 0.1434 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 451/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0684 - acc: 0.9780 - recall: 0.2765 - fbeta_score: 0.2830 - val_loss: 0.1431 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 452/1000\n",
      "2048/2048 [==============================] - 0s 84us/step - loss: 0.0683 - acc: 0.9795 - recall: 0.2905 - fbeta_score: 0.2913 - val_loss: 0.1430 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 453/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0683 - acc: 0.9795 - recall: 0.2897 - fbeta_score: 0.2936 - val_loss: 0.1429 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 454/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0682 - acc: 0.9795 - recall: 0.2795 - fbeta_score: 0.2858 - val_loss: 0.1428 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 455/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0682 - acc: 0.9800 - recall: 0.3132 - fbeta_score: 0.3203 - val_loss: 0.1430 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 456/1000\n",
      "2048/2048 [==============================] - 0s 118us/step - loss: 0.0681 - acc: 0.9800 - recall: 0.3068 - fbeta_score: 0.3081 - val_loss: 0.1433 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 457/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0680 - acc: 0.9800 - recall: 0.2936 - fbeta_score: 0.2982 - val_loss: 0.1431 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 458/1000\n",
      "2048/2048 [==============================] - 0s 104us/step - loss: 0.0680 - acc: 0.9795 - recall: 0.2881 - fbeta_score: 0.2900 - val_loss: 0.1432 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 459/1000\n",
      "2048/2048 [==============================] - 0s 110us/step - loss: 0.0679 - acc: 0.9780 - recall: 0.2845 - fbeta_score: 0.2908 - val_loss: 0.1433 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 460/1000\n",
      "2048/2048 [==============================] - 0s 123us/step - loss: 0.0679 - acc: 0.9795 - recall: 0.2686 - fbeta_score: 0.2733 - val_loss: 0.1431 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 461/1000\n",
      "2048/2048 [==============================] - 0s 120us/step - loss: 0.0678 - acc: 0.9790 - recall: 0.2860 - fbeta_score: 0.2889 - val_loss: 0.1436 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 462/1000\n",
      "2048/2048 [==============================] - 0s 130us/step - loss: 0.0677 - acc: 0.9800 - recall: 0.2576 - fbeta_score: 0.2649 - val_loss: 0.1437 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 463/1000\n",
      "2048/2048 [==============================] - 0s 123us/step - loss: 0.0677 - acc: 0.9795 - recall: 0.2995 - fbeta_score: 0.3057 - val_loss: 0.1436 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 464/1000\n",
      "2048/2048 [==============================] - 0s 125us/step - loss: 0.0677 - acc: 0.9795 - recall: 0.3034 - fbeta_score: 0.3058 - val_loss: 0.1437 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 465/1000\n",
      "2048/2048 [==============================] - 0s 125us/step - loss: 0.0676 - acc: 0.9785 - recall: 0.2767 - fbeta_score: 0.2812 - val_loss: 0.1435 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 466/1000\n",
      "2048/2048 [==============================] - 0s 126us/step - loss: 0.0675 - acc: 0.9805 - recall: 0.2828 - fbeta_score: 0.2876 - val_loss: 0.1434 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 467/1000\n",
      "2048/2048 [==============================] - 0s 126us/step - loss: 0.0674 - acc: 0.9795 - recall: 0.2783 - fbeta_score: 0.2830 - val_loss: 0.1431 - val_acc: 0.9556 - val_recall: 0.2237 - val_fbeta_score: 0.2344\n",
      "Epoch 468/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 124us/step - loss: 0.0674 - acc: 0.9795 - recall: 0.2909 - fbeta_score: 0.2949 - val_loss: 0.1431 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 469/1000\n",
      "2048/2048 [==============================] - 0s 107us/step - loss: 0.0674 - acc: 0.9800 - recall: 0.3034 - fbeta_score: 0.3120 - val_loss: 0.1433 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 470/1000\n",
      "2048/2048 [==============================] - 0s 113us/step - loss: 0.0673 - acc: 0.9790 - recall: 0.3263 - fbeta_score: 0.3296 - val_loss: 0.1434 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 471/1000\n",
      "2048/2048 [==============================] - 0s 114us/step - loss: 0.0673 - acc: 0.9795 - recall: 0.2979 - fbeta_score: 0.3034 - val_loss: 0.1434 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 472/1000\n",
      "2048/2048 [==============================] - 0s 117us/step - loss: 0.0672 - acc: 0.9805 - recall: 0.2840 - fbeta_score: 0.2889 - val_loss: 0.1433 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 473/1000\n",
      "2048/2048 [==============================] - 0s 114us/step - loss: 0.0671 - acc: 0.9800 - recall: 0.3115 - fbeta_score: 0.3136 - val_loss: 0.1436 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 474/1000\n",
      "2048/2048 [==============================] - 0s 121us/step - loss: 0.0671 - acc: 0.9795 - recall: 0.3035 - fbeta_score: 0.3018 - val_loss: 0.1437 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 475/1000\n",
      "2048/2048 [==============================] - 0s 124us/step - loss: 0.0670 - acc: 0.9805 - recall: 0.2936 - fbeta_score: 0.2965 - val_loss: 0.1437 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 476/1000\n",
      "2048/2048 [==============================] - 0s 126us/step - loss: 0.0669 - acc: 0.9795 - recall: 0.2808 - fbeta_score: 0.2845 - val_loss: 0.1439 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 477/1000\n",
      "2048/2048 [==============================] - 0s 140us/step - loss: 0.0669 - acc: 0.9800 - recall: 0.2847 - fbeta_score: 0.2907 - val_loss: 0.1442 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 478/1000\n",
      "2048/2048 [==============================] - 0s 134us/step - loss: 0.0668 - acc: 0.9800 - recall: 0.3221 - fbeta_score: 0.3268 - val_loss: 0.1443 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 479/1000\n",
      "2048/2048 [==============================] - 0s 104us/step - loss: 0.0668 - acc: 0.9790 - recall: 0.2629 - fbeta_score: 0.2638 - val_loss: 0.1442 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 480/1000\n",
      "2048/2048 [==============================] - 0s 117us/step - loss: 0.0667 - acc: 0.9795 - recall: 0.2722 - fbeta_score: 0.2775 - val_loss: 0.1442 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 481/1000\n",
      "2048/2048 [==============================] - 0s 129us/step - loss: 0.0667 - acc: 0.9805 - recall: 0.3011 - fbeta_score: 0.3050 - val_loss: 0.1441 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 482/1000\n",
      "2048/2048 [==============================] - 0s 184us/step - loss: 0.0667 - acc: 0.9795 - recall: 0.2944 - fbeta_score: 0.2948 - val_loss: 0.1441 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 483/1000\n",
      "2048/2048 [==============================] - 0s 233us/step - loss: 0.0665 - acc: 0.9795 - recall: 0.2840 - fbeta_score: 0.2886 - val_loss: 0.1439 - val_acc: 0.9556 - val_recall: 0.2237 - val_fbeta_score: 0.2344\n",
      "Epoch 484/1000\n",
      "2048/2048 [==============================] - 0s 152us/step - loss: 0.0665 - acc: 0.9795 - recall: 0.2812 - fbeta_score: 0.2838 - val_loss: 0.1440 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 485/1000\n",
      "2048/2048 [==============================] - 0s 107us/step - loss: 0.0664 - acc: 0.9800 - recall: 0.2881 - fbeta_score: 0.2922 - val_loss: 0.1441 - val_acc: 0.9545 - val_recall: 0.2181 - val_fbeta_score: 0.2287\n",
      "Epoch 486/1000\n",
      "2048/2048 [==============================] - 0s 116us/step - loss: 0.0664 - acc: 0.9795 - recall: 0.2954 - fbeta_score: 0.2983 - val_loss: 0.1439 - val_acc: 0.9556 - val_recall: 0.2237 - val_fbeta_score: 0.2344\n",
      "Epoch 487/1000\n",
      "2048/2048 [==============================] - 0s 104us/step - loss: 0.0663 - acc: 0.9795 - recall: 0.3027 - fbeta_score: 0.3076 - val_loss: 0.1441 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 488/1000\n",
      "2048/2048 [==============================] - 0s 125us/step - loss: 0.0662 - acc: 0.9795 - recall: 0.3076 - fbeta_score: 0.3091 - val_loss: 0.1437 - val_acc: 0.9556 - val_recall: 0.2237 - val_fbeta_score: 0.2344\n",
      "Epoch 489/1000\n",
      "2048/2048 [==============================] - 0s 110us/step - loss: 0.0662 - acc: 0.9800 - recall: 0.2832 - fbeta_score: 0.2943 - val_loss: 0.1439 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 490/1000\n",
      "2048/2048 [==============================] - 0s 138us/step - loss: 0.0661 - acc: 0.9795 - recall: 0.2692 - fbeta_score: 0.2757 - val_loss: 0.1438 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2230\n",
      "Epoch 491/1000\n",
      "2048/2048 [==============================] - 0s 119us/step - loss: 0.0661 - acc: 0.9795 - recall: 0.2840 - fbeta_score: 0.2930 - val_loss: 0.1439 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2230\n",
      "Epoch 492/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0660 - acc: 0.9800 - recall: 0.3125 - fbeta_score: 0.3174 - val_loss: 0.1441 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 493/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0660 - acc: 0.9800 - recall: 0.3060 - fbeta_score: 0.3115 - val_loss: 0.1442 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 494/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0659 - acc: 0.9800 - recall: 0.2938 - fbeta_score: 0.2985 - val_loss: 0.1443 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 495/1000\n",
      "2048/2048 [==============================] - 0s 219us/step - loss: 0.0658 - acc: 0.9795 - recall: 0.2856 - fbeta_score: 0.2917 - val_loss: 0.1440 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 496/1000\n",
      "2048/2048 [==============================] - 0s 106us/step - loss: 0.0658 - acc: 0.9800 - recall: 0.2790 - fbeta_score: 0.2811 - val_loss: 0.1440 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 497/1000\n",
      "2048/2048 [==============================] - 0s 107us/step - loss: 0.0657 - acc: 0.9810 - recall: 0.2934 - fbeta_score: 0.3004 - val_loss: 0.1439 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 498/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0657 - acc: 0.9790 - recall: 0.2839 - fbeta_score: 0.2898 - val_loss: 0.1442 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 499/1000\n",
      "2048/2048 [==============================] - 0s 103us/step - loss: 0.0656 - acc: 0.9800 - recall: 0.2995 - fbeta_score: 0.3039 - val_loss: 0.1443 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 500/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0655 - acc: 0.9795 - recall: 0.2995 - fbeta_score: 0.3073 - val_loss: 0.1441 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2230\n",
      "Epoch 501/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0655 - acc: 0.9800 - recall: 0.2944 - fbeta_score: 0.2967 - val_loss: 0.1441 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2230\n",
      "Epoch 502/1000\n",
      "2048/2048 [==============================] - 0s 110us/step - loss: 0.0654 - acc: 0.9795 - recall: 0.2905 - fbeta_score: 0.2930 - val_loss: 0.1440 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2230\n",
      "Epoch 503/1000\n",
      "2048/2048 [==============================] - 0s 104us/step - loss: 0.0654 - acc: 0.9805 - recall: 0.3107 - fbeta_score: 0.3161 - val_loss: 0.1441 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 504/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0653 - acc: 0.9795 - recall: 0.2767 - fbeta_score: 0.2837 - val_loss: 0.1442 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 505/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0652 - acc: 0.9795 - recall: 0.2791 - fbeta_score: 0.2855 - val_loss: 0.1442 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2230\n",
      "Epoch 506/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0652 - acc: 0.9800 - recall: 0.3050 - fbeta_score: 0.3081 - val_loss: 0.1443 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 507/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0651 - acc: 0.9795 - recall: 0.2743 - fbeta_score: 0.2812 - val_loss: 0.1442 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 508/1000\n",
      "2048/2048 [==============================] - 0s 148us/step - loss: 0.0650 - acc: 0.9805 - recall: 0.2987 - fbeta_score: 0.3073 - val_loss: 0.1444 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 509/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0650 - acc: 0.9810 - recall: 0.3215 - fbeta_score: 0.3205 - val_loss: 0.1446 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 510/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0649 - acc: 0.9805 - recall: 0.2897 - fbeta_score: 0.2992 - val_loss: 0.1443 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 511/1000\n",
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.0649 - acc: 0.9800 - recall: 0.2708 - fbeta_score: 0.2762 - val_loss: 0.1442 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 512/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0648 - acc: 0.9800 - recall: 0.3091 - fbeta_score: 0.3114 - val_loss: 0.1440 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2230\n",
      "Epoch 513/1000\n",
      "2048/2048 [==============================] - 0s 83us/step - loss: 0.0647 - acc: 0.9805 - recall: 0.2873 - fbeta_score: 0.2956 - val_loss: 0.1443 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 514/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0647 - acc: 0.9800 - recall: 0.2881 - fbeta_score: 0.2946 - val_loss: 0.1443 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 515/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0646 - acc: 0.9810 - recall: 0.3229 - fbeta_score: 0.3281 - val_loss: 0.1447 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 516/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0646 - acc: 0.9795 - recall: 0.3044 - fbeta_score: 0.3089 - val_loss: 0.1444 - val_acc: 0.9534 - val_recall: 0.2086 - val_fbeta_score: 0.2196\n",
      "Epoch 517/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0645 - acc: 0.9805 - recall: 0.2734 - fbeta_score: 0.2819 - val_loss: 0.1443 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 518/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0644 - acc: 0.9800 - recall: 0.2879 - fbeta_score: 0.2917 - val_loss: 0.1442 - val_acc: 0.9534 - val_recall: 0.2086 - val_fbeta_score: 0.2196\n",
      "Epoch 519/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0644 - acc: 0.9800 - recall: 0.2865 - fbeta_score: 0.2896 - val_loss: 0.1445 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 520/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0643 - acc: 0.9795 - recall: 0.2965 - fbeta_score: 0.2993 - val_loss: 0.1446 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 521/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0643 - acc: 0.9810 - recall: 0.3066 - fbeta_score: 0.3105 - val_loss: 0.1444 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 522/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0642 - acc: 0.9805 - recall: 0.3055 - fbeta_score: 0.3117 - val_loss: 0.1442 - val_acc: 0.9545 - val_recall: 0.2124 - val_fbeta_score: 0.2230\n",
      "Epoch 523/1000\n",
      "2048/2048 [==============================] - 0s 126us/step - loss: 0.0642 - acc: 0.9810 - recall: 0.3052 - fbeta_score: 0.3107 - val_loss: 0.1446 - val_acc: 0.9545 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 524/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0641 - acc: 0.9810 - recall: 0.3035 - fbeta_score: 0.3057 - val_loss: 0.1446 - val_acc: 0.9545 - val_recall: 0.2067 - val_fbeta_score: 0.2173\n",
      "Epoch 525/1000\n",
      "2048/2048 [==============================] - 0s 113us/step - loss: 0.0641 - acc: 0.9805 - recall: 0.3206 - fbeta_score: 0.3197 - val_loss: 0.1447 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 526/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0640 - acc: 0.9805 - recall: 0.2873 - fbeta_score: 0.2967 - val_loss: 0.1446 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 527/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0639 - acc: 0.9810 - recall: 0.2954 - fbeta_score: 0.2998 - val_loss: 0.1449 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 528/1000\n",
      "2048/2048 [==============================] - 0s 141us/step - loss: 0.0638 - acc: 0.9805 - recall: 0.3223 - fbeta_score: 0.3206 - val_loss: 0.1450 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 529/1000\n",
      "2048/2048 [==============================] - 0s 107us/step - loss: 0.0638 - acc: 0.9805 - recall: 0.2952 - fbeta_score: 0.3006 - val_loss: 0.1452 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 530/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0638 - acc: 0.9810 - recall: 0.3092 - fbeta_score: 0.3133 - val_loss: 0.1451 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 531/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0637 - acc: 0.9795 - recall: 0.2938 - fbeta_score: 0.3000 - val_loss: 0.1452 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 532/1000\n",
      "2048/2048 [==============================] - ETA: 0s - loss: 0.0585 - acc: 0.9827 - recall: 0.3010 - fbeta_score: 0.3055   - 0s 94us/step - loss: 0.0636 - acc: 0.9810 - recall: 0.3027 - fbeta_score: 0.3077 - val_loss: 0.1451 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 533/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0636 - acc: 0.9805 - recall: 0.3092 - fbeta_score: 0.3122 - val_loss: 0.1451 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 534/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0635 - acc: 0.9805 - recall: 0.3035 - fbeta_score: 0.3097 - val_loss: 0.1451 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 535/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0635 - acc: 0.9810 - recall: 0.2873 - fbeta_score: 0.2909 - val_loss: 0.1451 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 536/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0634 - acc: 0.9810 - recall: 0.2987 - fbeta_score: 0.3050 - val_loss: 0.1450 - val_acc: 0.9534 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 537/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0634 - acc: 0.9805 - recall: 0.2840 - fbeta_score: 0.2897 - val_loss: 0.1451 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 538/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0633 - acc: 0.9805 - recall: 0.3040 - fbeta_score: 0.3056 - val_loss: 0.1455 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 539/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0632 - acc: 0.9810 - recall: 0.2946 - fbeta_score: 0.2974 - val_loss: 0.1450 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 540/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0632 - acc: 0.9810 - recall: 0.3296 - fbeta_score: 0.3345 - val_loss: 0.1452 - val_acc: 0.9556 - val_recall: 0.2086 - val_fbeta_score: 0.2196\n",
      "Epoch 541/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0632 - acc: 0.9800 - recall: 0.2795 - fbeta_score: 0.2858 - val_loss: 0.1453 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 542/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0631 - acc: 0.9805 - recall: 0.2946 - fbeta_score: 0.2995 - val_loss: 0.1453 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 543/1000\n",
      "2048/2048 [==============================] - ETA: 0s - loss: 0.0597 - acc: 0.9825 - recall: 0.3107 - fbeta_score: 0.31 - 0s 91us/step - loss: 0.0630 - acc: 0.9805 - recall: 0.3149 - fbeta_score: 0.3174 - val_loss: 0.1455 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 544/1000\n",
      "2048/2048 [==============================] - 0s 131us/step - loss: 0.0630 - acc: 0.9805 - recall: 0.2734 - fbeta_score: 0.2803 - val_loss: 0.1454 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 545/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0629 - acc: 0.9805 - recall: 0.2873 - fbeta_score: 0.2894 - val_loss: 0.1459 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 546/1000\n",
      "2048/2048 [==============================] - 0s 157us/step - loss: 0.0629 - acc: 0.9805 - recall: 0.3109 - fbeta_score: 0.3132 - val_loss: 0.1455 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 547/1000\n",
      "2048/2048 [==============================] - 0s 107us/step - loss: 0.0628 - acc: 0.9810 - recall: 0.2938 - fbeta_score: 0.3001 - val_loss: 0.1460 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 548/1000\n",
      "2048/2048 [==============================] - 0s 131us/step - loss: 0.0628 - acc: 0.9805 - recall: 0.3148 - fbeta_score: 0.3179 - val_loss: 0.1458 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 549/1000\n",
      "2048/2048 [==============================] - 0s 114us/step - loss: 0.0627 - acc: 0.9805 - recall: 0.3335 - fbeta_score: 0.3363 - val_loss: 0.1459 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 550/1000\n",
      "2048/2048 [==============================] - 0s 106us/step - loss: 0.0626 - acc: 0.9800 - recall: 0.2962 - fbeta_score: 0.2998 - val_loss: 0.1455 - val_acc: 0.9556 - val_recall: 0.2086 - val_fbeta_score: 0.2196\n",
      "Epoch 551/1000\n",
      "2048/2048 [==============================] - 0s 113us/step - loss: 0.0626 - acc: 0.9805 - recall: 0.3018 - fbeta_score: 0.3062 - val_loss: 0.1456 - val_acc: 0.9556 - val_recall: 0.2086 - val_fbeta_score: 0.2196\n",
      "Epoch 552/1000\n",
      "2048/2048 [==============================] - 0s 106us/step - loss: 0.0626 - acc: 0.9800 - recall: 0.3019 - fbeta_score: 0.3035 - val_loss: 0.1457 - val_acc: 0.9556 - val_recall: 0.2086 - val_fbeta_score: 0.2196\n",
      "Epoch 553/1000\n",
      "2048/2048 [==============================] - 0s 139us/step - loss: 0.0625 - acc: 0.9805 - recall: 0.2765 - fbeta_score: 0.2816 - val_loss: 0.1460 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 554/1000\n",
      "2048/2048 [==============================] - 0s 112us/step - loss: 0.0625 - acc: 0.9805 - recall: 0.2839 - fbeta_score: 0.2885 - val_loss: 0.1460 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 555/1000\n",
      "2048/2048 [==============================] - 0s 155us/step - loss: 0.0624 - acc: 0.9805 - recall: 0.3052 - fbeta_score: 0.3071 - val_loss: 0.1462 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 556/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0624 - acc: 0.9805 - recall: 0.3003 - fbeta_score: 0.3016 - val_loss: 0.1463 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 557/1000\n",
      "2048/2048 [==============================] - 0s 124us/step - loss: 0.0623 - acc: 0.9805 - recall: 0.2989 - fbeta_score: 0.3033 - val_loss: 0.1467 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 558/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0623 - acc: 0.9805 - recall: 0.3117 - fbeta_score: 0.3156 - val_loss: 0.1465 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 559/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0622 - acc: 0.9805 - recall: 0.3205 - fbeta_score: 0.3245 - val_loss: 0.1464 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 560/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0622 - acc: 0.9805 - recall: 0.2952 - fbeta_score: 0.2991 - val_loss: 0.1465 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 561/1000\n",
      "2048/2048 [==============================] - ETA: 0s - loss: 0.0665 - acc: 0.9788 - recall: 0.2998 - fbeta_score: 0.3036   - 0s 98us/step - loss: 0.0621 - acc: 0.9805 - recall: 0.2889 - fbeta_score: 0.2923 - val_loss: 0.1465 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 562/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0621 - acc: 0.9810 - recall: 0.3003 - fbeta_score: 0.3013 - val_loss: 0.1466 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 563/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0620 - acc: 0.9805 - recall: 0.2791 - fbeta_score: 0.2879 - val_loss: 0.1466 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 564/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0619 - acc: 0.9800 - recall: 0.2844 - fbeta_score: 0.2887 - val_loss: 0.1468 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 565/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0619 - acc: 0.9805 - recall: 0.2954 - fbeta_score: 0.2982 - val_loss: 0.1468 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 566/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0618 - acc: 0.9805 - recall: 0.3076 - fbeta_score: 0.3107 - val_loss: 0.1467 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 567/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0618 - acc: 0.9805 - recall: 0.3068 - fbeta_score: 0.3117 - val_loss: 0.1468 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 568/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0617 - acc: 0.9805 - recall: 0.3019 - fbeta_score: 0.3073 - val_loss: 0.1468 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 569/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0617 - acc: 0.9805 - recall: 0.2871 - fbeta_score: 0.2912 - val_loss: 0.1470 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 570/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0616 - acc: 0.9800 - recall: 0.2922 - fbeta_score: 0.3008 - val_loss: 0.1474 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 571/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0616 - acc: 0.9805 - recall: 0.2999 - fbeta_score: 0.3002 - val_loss: 0.1472 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 572/1000\n",
      "2048/2048 [==============================] - 0s 105us/step - loss: 0.0615 - acc: 0.9800 - recall: 0.3076 - fbeta_score: 0.3149 - val_loss: 0.1474 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 573/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0615 - acc: 0.9805 - recall: 0.2969 - fbeta_score: 0.3006 - val_loss: 0.1475 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 574/1000\n",
      "2048/2048 [==============================] - ETA: 0s - loss: 0.0620 - acc: 0.9806 - recall: 0.2927 - fbeta_score: 0.2992 - 0s 120us/step - loss: 0.0614 - acc: 0.9810 - recall: 0.2873 - fbeta_score: 0.2936 - val_loss: 0.1476 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 575/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 118us/step - loss: 0.0614 - acc: 0.9805 - recall: 0.2912 - fbeta_score: 0.2948 - val_loss: 0.1477 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 576/1000\n",
      "2048/2048 [==============================] - 0s 123us/step - loss: 0.0613 - acc: 0.9805 - recall: 0.2930 - fbeta_score: 0.2998 - val_loss: 0.1476 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 577/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0612 - acc: 0.9805 - recall: 0.2859 - fbeta_score: 0.2926 - val_loss: 0.1476 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 578/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0612 - acc: 0.9805 - recall: 0.3057 - fbeta_score: 0.3080 - val_loss: 0.1477 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 579/1000\n",
      "2048/2048 [==============================] - 0s 108us/step - loss: 0.0611 - acc: 0.9805 - recall: 0.3166 - fbeta_score: 0.3156 - val_loss: 0.1478 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 580/1000\n",
      "2048/2048 [==============================] - 0s 136us/step - loss: 0.0611 - acc: 0.9805 - recall: 0.3141 - fbeta_score: 0.3191 - val_loss: 0.1478 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 581/1000\n",
      "2048/2048 [==============================] - 0s 132us/step - loss: 0.0610 - acc: 0.9805 - recall: 0.3182 - fbeta_score: 0.3221 - val_loss: 0.1481 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 582/1000\n",
      "2048/2048 [==============================] - 0s 104us/step - loss: 0.0609 - acc: 0.9805 - recall: 0.3267 - fbeta_score: 0.3298 - val_loss: 0.1482 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 583/1000\n",
      "2048/2048 [==============================] - 0s 105us/step - loss: 0.0609 - acc: 0.9805 - recall: 0.2979 - fbeta_score: 0.3035 - val_loss: 0.1483 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 584/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0608 - acc: 0.9814 - recall: 0.3242 - fbeta_score: 0.3304 - val_loss: 0.1481 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 585/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0608 - acc: 0.9810 - recall: 0.3044 - fbeta_score: 0.3073 - val_loss: 0.1481 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 586/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0607 - acc: 0.9805 - recall: 0.3003 - fbeta_score: 0.3049 - val_loss: 0.1484 - val_acc: 0.9522 - val_recall: 0.1934 - val_fbeta_score: 0.2006\n",
      "Epoch 587/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0607 - acc: 0.9810 - recall: 0.2931 - fbeta_score: 0.2982 - val_loss: 0.1485 - val_acc: 0.9522 - val_recall: 0.1934 - val_fbeta_score: 0.2006\n",
      "Epoch 588/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0606 - acc: 0.9805 - recall: 0.2944 - fbeta_score: 0.2975 - val_loss: 0.1486 - val_acc: 0.9522 - val_recall: 0.1934 - val_fbeta_score: 0.2006\n",
      "Epoch 589/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0606 - acc: 0.9814 - recall: 0.3007 - fbeta_score: 0.3018 - val_loss: 0.1487 - val_acc: 0.9522 - val_recall: 0.1934 - val_fbeta_score: 0.2006\n",
      "Epoch 590/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0605 - acc: 0.9805 - recall: 0.3188 - fbeta_score: 0.3226 - val_loss: 0.1486 - val_acc: 0.9522 - val_recall: 0.1934 - val_fbeta_score: 0.2006\n",
      "Epoch 591/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0604 - acc: 0.9810 - recall: 0.3011 - fbeta_score: 0.3018 - val_loss: 0.1491 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 592/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0604 - acc: 0.9814 - recall: 0.3418 - fbeta_score: 0.3418 - val_loss: 0.1489 - val_acc: 0.9522 - val_recall: 0.1934 - val_fbeta_score: 0.2006\n",
      "Epoch 593/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0604 - acc: 0.9810 - recall: 0.2909 - fbeta_score: 0.2968 - val_loss: 0.1488 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 594/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0603 - acc: 0.9795 - recall: 0.3084 - fbeta_score: 0.3083 - val_loss: 0.1489 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 595/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0602 - acc: 0.9805 - recall: 0.3166 - fbeta_score: 0.3215 - val_loss: 0.1488 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 596/1000\n",
      "2048/2048 [==============================] - 0s 145us/step - loss: 0.0601 - acc: 0.9800 - recall: 0.2946 - fbeta_score: 0.2983 - val_loss: 0.1488 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 597/1000\n",
      "2048/2048 [==============================] - 0s 125us/step - loss: 0.0600 - acc: 0.9810 - recall: 0.3158 - fbeta_score: 0.3173 - val_loss: 0.1489 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 598/1000\n",
      "2048/2048 [==============================] - 0s 126us/step - loss: 0.0600 - acc: 0.9805 - recall: 0.3343 - fbeta_score: 0.3366 - val_loss: 0.1492 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 599/1000\n",
      "2048/2048 [==============================] - 0s 129us/step - loss: 0.0600 - acc: 0.9819 - recall: 0.2952 - fbeta_score: 0.3021 - val_loss: 0.1493 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 600/1000\n",
      "2048/2048 [==============================] - 0s 131us/step - loss: 0.0599 - acc: 0.9819 - recall: 0.3113 - fbeta_score: 0.3116 - val_loss: 0.1494 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 601/1000\n",
      "2048/2048 [==============================] - 0s 120us/step - loss: 0.0598 - acc: 0.9810 - recall: 0.3304 - fbeta_score: 0.3311 - val_loss: 0.1492 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 602/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0598 - acc: 0.9810 - recall: 0.3101 - fbeta_score: 0.3133 - val_loss: 0.1495 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 603/1000\n",
      "2048/2048 [==============================] - 0s 103us/step - loss: 0.0597 - acc: 0.9805 - recall: 0.3158 - fbeta_score: 0.3153 - val_loss: 0.1499 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 604/1000\n",
      "2048/2048 [==============================] - 0s 103us/step - loss: 0.0597 - acc: 0.9819 - recall: 0.3060 - fbeta_score: 0.3099 - val_loss: 0.1499 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 605/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0596 - acc: 0.9810 - recall: 0.3182 - fbeta_score: 0.3158 - val_loss: 0.1498 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 606/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0595 - acc: 0.9805 - recall: 0.3394 - fbeta_score: 0.3392 - val_loss: 0.1500 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 607/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0595 - acc: 0.9810 - recall: 0.3015 - fbeta_score: 0.3076 - val_loss: 0.1499 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 608/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0594 - acc: 0.9800 - recall: 0.2995 - fbeta_score: 0.3057 - val_loss: 0.1499 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 609/1000\n",
      "2048/2048 [==============================] - 0s 103us/step - loss: 0.0593 - acc: 0.9800 - recall: 0.3328 - fbeta_score: 0.3311 - val_loss: 0.1501 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 610/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0593 - acc: 0.9819 - recall: 0.3394 - fbeta_score: 0.3449 - val_loss: 0.1500 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 611/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0592 - acc: 0.9805 - recall: 0.3115 - fbeta_score: 0.3148 - val_loss: 0.1502 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 612/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0591 - acc: 0.9810 - recall: 0.2835 - fbeta_score: 0.2863 - val_loss: 0.1500 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 613/1000\n",
      "2048/2048 [==============================] - 0s 112us/step - loss: 0.0591 - acc: 0.9814 - recall: 0.3418 - fbeta_score: 0.3451 - val_loss: 0.1501 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 614/1000\n",
      "2048/2048 [==============================] - 0s 106us/step - loss: 0.0590 - acc: 0.9810 - recall: 0.3245 - fbeta_score: 0.3285 - val_loss: 0.1503 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 615/1000\n",
      "2048/2048 [==============================] - 0s 121us/step - loss: 0.0589 - acc: 0.9814 - recall: 0.3027 - fbeta_score: 0.3091 - val_loss: 0.1506 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 616/1000\n",
      "2048/2048 [==============================] - 0s 120us/step - loss: 0.0589 - acc: 0.9805 - recall: 0.3136 - fbeta_score: 0.3131 - val_loss: 0.1505 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 617/1000\n",
      "2048/2048 [==============================] - 0s 120us/step - loss: 0.0588 - acc: 0.9810 - recall: 0.3011 - fbeta_score: 0.3073 - val_loss: 0.1501 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 618/1000\n",
      "2048/2048 [==============================] - 0s 122us/step - loss: 0.0588 - acc: 0.9824 - recall: 0.3239 - fbeta_score: 0.3263 - val_loss: 0.1503 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 619/1000\n",
      "2048/2048 [==============================] - 0s 124us/step - loss: 0.0587 - acc: 0.9819 - recall: 0.3158 - fbeta_score: 0.3164 - val_loss: 0.1508 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 620/1000\n",
      "2048/2048 [==============================] - 0s 112us/step - loss: 0.0587 - acc: 0.9810 - recall: 0.2991 - fbeta_score: 0.2980 - val_loss: 0.1510 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 621/1000\n",
      "2048/2048 [==============================] - 0s 111us/step - loss: 0.0586 - acc: 0.9810 - recall: 0.2958 - fbeta_score: 0.2987 - val_loss: 0.1509 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 622/1000\n",
      "2048/2048 [==============================] - 0s 110us/step - loss: 0.0586 - acc: 0.9810 - recall: 0.3003 - fbeta_score: 0.3036 - val_loss: 0.1508 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 623/1000\n",
      "2048/2048 [==============================] - 0s 124us/step - loss: 0.0585 - acc: 0.9819 - recall: 0.3304 - fbeta_score: 0.3351 - val_loss: 0.1511 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 624/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0584 - acc: 0.9805 - recall: 0.3001 - fbeta_score: 0.3034 - val_loss: 0.1509 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 625/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0584 - acc: 0.9805 - recall: 0.3027 - fbeta_score: 0.3092 - val_loss: 0.1508 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 626/1000\n",
      "2048/2048 [==============================] - 0s 121us/step - loss: 0.0583 - acc: 0.9810 - recall: 0.3109 - fbeta_score: 0.3130 - val_loss: 0.1509 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 627/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0582 - acc: 0.9814 - recall: 0.3068 - fbeta_score: 0.3105 - val_loss: 0.1513 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 628/1000\n",
      "2048/2048 [==============================] - 0s 114us/step - loss: 0.0582 - acc: 0.9814 - recall: 0.3206 - fbeta_score: 0.3190 - val_loss: 0.1511 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 629/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0582 - acc: 0.9819 - recall: 0.3262 - fbeta_score: 0.3244 - val_loss: 0.1513 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 630/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0581 - acc: 0.9814 - recall: 0.3125 - fbeta_score: 0.3153 - val_loss: 0.1515 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 631/1000\n",
      "2048/2048 [==============================] - 0s 104us/step - loss: 0.0580 - acc: 0.9819 - recall: 0.3312 - fbeta_score: 0.3285 - val_loss: 0.1519 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 632/1000\n",
      "2048/2048 [==============================] - 0s 157us/step - loss: 0.0580 - acc: 0.9814 - recall: 0.3223 - fbeta_score: 0.3219 - val_loss: 0.1518 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 633/1000\n",
      "2048/2048 [==============================] - 0s 123us/step - loss: 0.0579 - acc: 0.9819 - recall: 0.3149 - fbeta_score: 0.3180 - val_loss: 0.1517 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 634/1000\n",
      "2048/2048 [==============================] - 0s 134us/step - loss: 0.0579 - acc: 0.9824 - recall: 0.3345 - fbeta_score: 0.3311 - val_loss: 0.1517 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 635/1000\n",
      "2048/2048 [==============================] - 0s 126us/step - loss: 0.0578 - acc: 0.9819 - recall: 0.3123 - fbeta_score: 0.3160 - val_loss: 0.1517 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 636/1000\n",
      "2048/2048 [==============================] - 0s 134us/step - loss: 0.0578 - acc: 0.9824 - recall: 0.3377 - fbeta_score: 0.3376 - val_loss: 0.1519 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 637/1000\n",
      "2048/2048 [==============================] - 0s 118us/step - loss: 0.0577 - acc: 0.9805 - recall: 0.3060 - fbeta_score: 0.3097 - val_loss: 0.1518 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 638/1000\n",
      "2048/2048 [==============================] - 0s 121us/step - loss: 0.0576 - acc: 0.9819 - recall: 0.3280 - fbeta_score: 0.3286 - val_loss: 0.1521 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 639/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0576 - acc: 0.9824 - recall: 0.3215 - fbeta_score: 0.3211 - val_loss: 0.1521 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 640/1000\n",
      "2048/2048 [==============================] - 0s 103us/step - loss: 0.0575 - acc: 0.9814 - recall: 0.3201 - fbeta_score: 0.3249 - val_loss: 0.1520 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 641/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0575 - acc: 0.9824 - recall: 0.3149 - fbeta_score: 0.3193 - val_loss: 0.1521 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 642/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0574 - acc: 0.9819 - recall: 0.3345 - fbeta_score: 0.3351 - val_loss: 0.1521 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 643/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0574 - acc: 0.9819 - recall: 0.3190 - fbeta_score: 0.3219 - val_loss: 0.1520 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 644/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0573 - acc: 0.9814 - recall: 0.3084 - fbeta_score: 0.3083 - val_loss: 0.1521 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 645/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0573 - acc: 0.9819 - recall: 0.3141 - fbeta_score: 0.3171 - val_loss: 0.1522 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 646/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0572 - acc: 0.9814 - recall: 0.3003 - fbeta_score: 0.3037 - val_loss: 0.1524 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 647/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0572 - acc: 0.9814 - recall: 0.3026 - fbeta_score: 0.3024 - val_loss: 0.1526 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 648/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0571 - acc: 0.9829 - recall: 0.3052 - fbeta_score: 0.3053 - val_loss: 0.1527 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 649/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0571 - acc: 0.9819 - recall: 0.3369 - fbeta_score: 0.3421 - val_loss: 0.1528 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 650/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0570 - acc: 0.9814 - recall: 0.3188 - fbeta_score: 0.3237 - val_loss: 0.1526 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 651/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0570 - acc: 0.9819 - recall: 0.3019 - fbeta_score: 0.3071 - val_loss: 0.1527 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 652/1000\n",
      "2048/2048 [==============================] - 0s 106us/step - loss: 0.0569 - acc: 0.9814 - recall: 0.3046 - fbeta_score: 0.3040 - val_loss: 0.1528 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 653/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0569 - acc: 0.9819 - recall: 0.3198 - fbeta_score: 0.3219 - val_loss: 0.1529 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 654/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0568 - acc: 0.9814 - recall: 0.3228 - fbeta_score: 0.3287 - val_loss: 0.1528 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 655/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0568 - acc: 0.9814 - recall: 0.3368 - fbeta_score: 0.3382 - val_loss: 0.1528 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 656/1000\n",
      "2048/2048 [==============================] - 0s 86us/step - loss: 0.0567 - acc: 0.9819 - recall: 0.3333 - fbeta_score: 0.3284 - val_loss: 0.1530 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 657/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0566 - acc: 0.9819 - recall: 0.3117 - fbeta_score: 0.3172 - val_loss: 0.1528 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 658/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0566 - acc: 0.9819 - recall: 0.3320 - fbeta_score: 0.3351 - val_loss: 0.1531 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 659/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0565 - acc: 0.9819 - recall: 0.3394 - fbeta_score: 0.3446 - val_loss: 0.1530 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 660/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0565 - acc: 0.9824 - recall: 0.3132 - fbeta_score: 0.3172 - val_loss: 0.1533 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 661/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0564 - acc: 0.9829 - recall: 0.3109 - fbeta_score: 0.3139 - val_loss: 0.1535 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 662/1000\n",
      "2048/2048 [==============================] - 0s 109us/step - loss: 0.0564 - acc: 0.9814 - recall: 0.3125 - fbeta_score: 0.3151 - val_loss: 0.1534 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 663/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0563 - acc: 0.9819 - recall: 0.3231 - fbeta_score: 0.3260 - val_loss: 0.1534 - val_acc: 0.9511 - val_recall: 0.1820 - val_fbeta_score: 0.1892\n",
      "Epoch 664/1000\n",
      "2048/2048 [==============================] - 0s 105us/step - loss: 0.0563 - acc: 0.9819 - recall: 0.3149 - fbeta_score: 0.3166 - val_loss: 0.1534 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 665/1000\n",
      "2048/2048 [==============================] - 0s 103us/step - loss: 0.0562 - acc: 0.9829 - recall: 0.3182 - fbeta_score: 0.3223 - val_loss: 0.1536 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 666/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0562 - acc: 0.9810 - recall: 0.2897 - fbeta_score: 0.2938 - val_loss: 0.1535 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 667/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0561 - acc: 0.9829 - recall: 0.2861 - fbeta_score: 0.2862 - val_loss: 0.1538 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 668/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0560 - acc: 0.9814 - recall: 0.3461 - fbeta_score: 0.3528 - val_loss: 0.1539 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 669/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0560 - acc: 0.9824 - recall: 0.3394 - fbeta_score: 0.3369 - val_loss: 0.1540 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 670/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0559 - acc: 0.9819 - recall: 0.3172 - fbeta_score: 0.3171 - val_loss: 0.1540 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 671/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0559 - acc: 0.9819 - recall: 0.3182 - fbeta_score: 0.3247 - val_loss: 0.1541 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 672/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0558 - acc: 0.9819 - recall: 0.3304 - fbeta_score: 0.3285 - val_loss: 0.1543 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 673/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0557 - acc: 0.9824 - recall: 0.3231 - fbeta_score: 0.3236 - val_loss: 0.1542 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 674/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0557 - acc: 0.9819 - recall: 0.3239 - fbeta_score: 0.3276 - val_loss: 0.1544 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 675/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0556 - acc: 0.9824 - recall: 0.3206 - fbeta_score: 0.3262 - val_loss: 0.1543 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 676/1000\n",
      "2048/2048 [==============================] - 0s 104us/step - loss: 0.0556 - acc: 0.9829 - recall: 0.3376 - fbeta_score: 0.3389 - val_loss: 0.1542 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 677/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0555 - acc: 0.9829 - recall: 0.3092 - fbeta_score: 0.3145 - val_loss: 0.1541 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 678/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0554 - acc: 0.9819 - recall: 0.3271 - fbeta_score: 0.3278 - val_loss: 0.1540 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 679/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0554 - acc: 0.9819 - recall: 0.3426 - fbeta_score: 0.3424 - val_loss: 0.1542 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 680/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0553 - acc: 0.9824 - recall: 0.3312 - fbeta_score: 0.3327 - val_loss: 0.1544 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 681/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0552 - acc: 0.9824 - recall: 0.3288 - fbeta_score: 0.3333 - val_loss: 0.1544 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 682/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0552 - acc: 0.9829 - recall: 0.3174 - fbeta_score: 0.3206 - val_loss: 0.1545 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 683/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0551 - acc: 0.9829 - recall: 0.3109 - fbeta_score: 0.3096 - val_loss: 0.1547 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 684/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0550 - acc: 0.9824 - recall: 0.3149 - fbeta_score: 0.3148 - val_loss: 0.1544 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 685/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0550 - acc: 0.9824 - recall: 0.3270 - fbeta_score: 0.3252 - val_loss: 0.1544 - val_acc: 0.9545 - val_recall: 0.2029 - val_fbeta_score: 0.2139\n",
      "Epoch 686/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0549 - acc: 0.9834 - recall: 0.3174 - fbeta_score: 0.3216 - val_loss: 0.1545 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 687/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0548 - acc: 0.9834 - recall: 0.3176 - fbeta_score: 0.3212 - val_loss: 0.1548 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 688/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0548 - acc: 0.9834 - recall: 0.3255 - fbeta_score: 0.3244 - val_loss: 0.1545 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 689/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0547 - acc: 0.9829 - recall: 0.3149 - fbeta_score: 0.3141 - val_loss: 0.1547 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 690/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0546 - acc: 0.9824 - recall: 0.3385 - fbeta_score: 0.3361 - val_loss: 0.1546 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 691/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0546 - acc: 0.9829 - recall: 0.3247 - fbeta_score: 0.3288 - val_loss: 0.1549 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 692/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0545 - acc: 0.9829 - recall: 0.3491 - fbeta_score: 0.3442 - val_loss: 0.1550 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 693/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0544 - acc: 0.9824 - recall: 0.2974 - fbeta_score: 0.2978 - val_loss: 0.1549 - val_acc: 0.9534 - val_recall: 0.1991 - val_fbeta_score: 0.2082\n",
      "Epoch 694/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0544 - acc: 0.9834 - recall: 0.3286 - fbeta_score: 0.3317 - val_loss: 0.1546 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 695/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0543 - acc: 0.9829 - recall: 0.3239 - fbeta_score: 0.3278 - val_loss: 0.1545 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 696/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0542 - acc: 0.9834 - recall: 0.2991 - fbeta_score: 0.3043 - val_loss: 0.1547 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 697/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0542 - acc: 0.9834 - recall: 0.3296 - fbeta_score: 0.3297 - val_loss: 0.1546 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 698/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0541 - acc: 0.9834 - recall: 0.3121 - fbeta_score: 0.3131 - val_loss: 0.1548 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 699/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0540 - acc: 0.9829 - recall: 0.3026 - fbeta_score: 0.3070 - val_loss: 0.1545 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 700/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0539 - acc: 0.9834 - recall: 0.3410 - fbeta_score: 0.3377 - val_loss: 0.1547 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 701/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0539 - acc: 0.9834 - recall: 0.3027 - fbeta_score: 0.3068 - val_loss: 0.1546 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 702/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0538 - acc: 0.9839 - recall: 0.3426 - fbeta_score: 0.3447 - val_loss: 0.1543 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 703/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0537 - acc: 0.9834 - recall: 0.3459 - fbeta_score: 0.3483 - val_loss: 0.1547 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 704/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0536 - acc: 0.9829 - recall: 0.3328 - fbeta_score: 0.3327 - val_loss: 0.1544 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 705/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0536 - acc: 0.9834 - recall: 0.3296 - fbeta_score: 0.3328 - val_loss: 0.1545 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 706/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0535 - acc: 0.9834 - recall: 0.3319 - fbeta_score: 0.3333 - val_loss: 0.1545 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 707/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0535 - acc: 0.9834 - recall: 0.3003 - fbeta_score: 0.3042 - val_loss: 0.1546 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 708/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0533 - acc: 0.9834 - recall: 0.3174 - fbeta_score: 0.3221 - val_loss: 0.1547 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 709/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0532 - acc: 0.9839 - recall: 0.3426 - fbeta_score: 0.3465 - val_loss: 0.1543 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 710/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0532 - acc: 0.9844 - recall: 0.3426 - fbeta_score: 0.3496 - val_loss: 0.1543 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 711/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0531 - acc: 0.9834 - recall: 0.3149 - fbeta_score: 0.3158 - val_loss: 0.1543 - val_acc: 0.9522 - val_recall: 0.1877 - val_fbeta_score: 0.1968\n",
      "Epoch 712/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0530 - acc: 0.9834 - recall: 0.3353 - fbeta_score: 0.3382 - val_loss: 0.1542 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 713/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0529 - acc: 0.9834 - recall: 0.3345 - fbeta_score: 0.3368 - val_loss: 0.1545 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 714/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0528 - acc: 0.9839 - recall: 0.3418 - fbeta_score: 0.3426 - val_loss: 0.1544 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 715/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0527 - acc: 0.9839 - recall: 0.3166 - fbeta_score: 0.3203 - val_loss: 0.1548 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 716/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0526 - acc: 0.9839 - recall: 0.3206 - fbeta_score: 0.3245 - val_loss: 0.1545 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 717/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0525 - acc: 0.9839 - recall: 0.3271 - fbeta_score: 0.3255 - val_loss: 0.1541 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 718/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0525 - acc: 0.9849 - recall: 0.3066 - fbeta_score: 0.3114 - val_loss: 0.1543 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 719/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0523 - acc: 0.9849 - recall: 0.3589 - fbeta_score: 0.3589 - val_loss: 0.1544 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 720/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0523 - acc: 0.9844 - recall: 0.2985 - fbeta_score: 0.3053 - val_loss: 0.1544 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 721/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0522 - acc: 0.9849 - recall: 0.3294 - fbeta_score: 0.3333 - val_loss: 0.1544 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 722/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0521 - acc: 0.9849 - recall: 0.3473 - fbeta_score: 0.3478 - val_loss: 0.1544 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 723/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0520 - acc: 0.9849 - recall: 0.3369 - fbeta_score: 0.3369 - val_loss: 0.1547 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 724/1000\n",
      "2048/2048 [==============================] - 0s 82us/step - loss: 0.0519 - acc: 0.9849 - recall: 0.3398 - fbeta_score: 0.3452 - val_loss: 0.1549 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 725/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0519 - acc: 0.9849 - recall: 0.3532 - fbeta_score: 0.3589 - val_loss: 0.1550 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 726/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0518 - acc: 0.9849 - recall: 0.3247 - fbeta_score: 0.3285 - val_loss: 0.1550 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 727/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0517 - acc: 0.9854 - recall: 0.3385 - fbeta_score: 0.3392 - val_loss: 0.1554 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 728/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0516 - acc: 0.9854 - recall: 0.3243 - fbeta_score: 0.3287 - val_loss: 0.1550 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 729/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0516 - acc: 0.9854 - recall: 0.3223 - fbeta_score: 0.3280 - val_loss: 0.1549 - val_acc: 0.9511 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 730/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0515 - acc: 0.9854 - recall: 0.3140 - fbeta_score: 0.3180 - val_loss: 0.1549 - val_acc: 0.9499 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 731/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0514 - acc: 0.9854 - recall: 0.3638 - fbeta_score: 0.3652 - val_loss: 0.1549 - val_acc: 0.9499 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 732/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0513 - acc: 0.9849 - recall: 0.3475 - fbeta_score: 0.3496 - val_loss: 0.1548 - val_acc: 0.9499 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 733/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0512 - acc: 0.9854 - recall: 0.3158 - fbeta_score: 0.3132 - val_loss: 0.1551 - val_acc: 0.9511 - val_recall: 0.1991 - val_fbeta_score: 0.2044\n",
      "Epoch 734/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0511 - acc: 0.9849 - recall: 0.3319 - fbeta_score: 0.3356 - val_loss: 0.1551 - val_acc: 0.9511 - val_recall: 0.1991 - val_fbeta_score: 0.2044\n",
      "Epoch 735/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0510 - acc: 0.9858 - recall: 0.3280 - fbeta_score: 0.3286 - val_loss: 0.1553 - val_acc: 0.9511 - val_recall: 0.1991 - val_fbeta_score: 0.2044\n",
      "Epoch 736/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0510 - acc: 0.9858 - recall: 0.3547 - fbeta_score: 0.3553 - val_loss: 0.1550 - val_acc: 0.9511 - val_recall: 0.1991 - val_fbeta_score: 0.2044\n",
      "Epoch 737/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0509 - acc: 0.9849 - recall: 0.3343 - fbeta_score: 0.3382 - val_loss: 0.1548 - val_acc: 0.9499 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 738/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0508 - acc: 0.9854 - recall: 0.3564 - fbeta_score: 0.3630 - val_loss: 0.1547 - val_acc: 0.9499 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 739/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0508 - acc: 0.9854 - recall: 0.3161 - fbeta_score: 0.3245 - val_loss: 0.1553 - val_acc: 0.9488 - val_recall: 0.1877 - val_fbeta_score: 0.1930\n",
      "Epoch 740/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0506 - acc: 0.9854 - recall: 0.3547 - fbeta_score: 0.3563 - val_loss: 0.1556 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 741/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0506 - acc: 0.9854 - recall: 0.3376 - fbeta_score: 0.3389 - val_loss: 0.1555 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1987\n",
      "Epoch 742/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0505 - acc: 0.9849 - recall: 0.3369 - fbeta_score: 0.3385 - val_loss: 0.1553 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 743/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0505 - acc: 0.9849 - recall: 0.3357 - fbeta_score: 0.3404 - val_loss: 0.1554 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1987\n",
      "Epoch 744/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0504 - acc: 0.9854 - recall: 0.3368 - fbeta_score: 0.3398 - val_loss: 0.1555 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1987\n",
      "Epoch 745/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0503 - acc: 0.9854 - recall: 0.3227 - fbeta_score: 0.3222 - val_loss: 0.1554 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 746/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0503 - acc: 0.9854 - recall: 0.3540 - fbeta_score: 0.3595 - val_loss: 0.1558 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 747/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0502 - acc: 0.9849 - recall: 0.3174 - fbeta_score: 0.3193 - val_loss: 0.1556 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 748/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0501 - acc: 0.9863 - recall: 0.3263 - fbeta_score: 0.3301 - val_loss: 0.1556 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 749/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0501 - acc: 0.9858 - recall: 0.3540 - fbeta_score: 0.3532 - val_loss: 0.1559 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 750/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0500 - acc: 0.9858 - recall: 0.3481 - fbeta_score: 0.3473 - val_loss: 0.1559 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 751/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0500 - acc: 0.9863 - recall: 0.3263 - fbeta_score: 0.3301 - val_loss: 0.1557 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 752/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0499 - acc: 0.9858 - recall: 0.3353 - fbeta_score: 0.3384 - val_loss: 0.1559 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 753/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0498 - acc: 0.9858 - recall: 0.3351 - fbeta_score: 0.3366 - val_loss: 0.1559 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 754/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0498 - acc: 0.9863 - recall: 0.3532 - fbeta_score: 0.3569 - val_loss: 0.1561 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 755/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0498 - acc: 0.9858 - recall: 0.3040 - fbeta_score: 0.3116 - val_loss: 0.1561 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 756/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0497 - acc: 0.9863 - recall: 0.3359 - fbeta_score: 0.3366 - val_loss: 0.1565 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 757/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0496 - acc: 0.9858 - recall: 0.3320 - fbeta_score: 0.3356 - val_loss: 0.1567 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 758/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0496 - acc: 0.9863 - recall: 0.3734 - fbeta_score: 0.3747 - val_loss: 0.1565 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 759/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0495 - acc: 0.9858 - recall: 0.3442 - fbeta_score: 0.3498 - val_loss: 0.1565 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 760/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0494 - acc: 0.9858 - recall: 0.3377 - fbeta_score: 0.3416 - val_loss: 0.1567 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 761/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0494 - acc: 0.9854 - recall: 0.3158 - fbeta_score: 0.3213 - val_loss: 0.1564 - val_acc: 0.9511 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 762/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0493 - acc: 0.9863 - recall: 0.3328 - fbeta_score: 0.3333 - val_loss: 0.1564 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 763/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0492 - acc: 0.9858 - recall: 0.3190 - fbeta_score: 0.3177 - val_loss: 0.1570 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 764/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0492 - acc: 0.9858 - recall: 0.3271 - fbeta_score: 0.3270 - val_loss: 0.1568 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 765/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0491 - acc: 0.9858 - recall: 0.3311 - fbeta_score: 0.3350 - val_loss: 0.1566 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 766/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0491 - acc: 0.9863 - recall: 0.3556 - fbeta_score: 0.3621 - val_loss: 0.1566 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 767/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0490 - acc: 0.9863 - recall: 0.3540 - fbeta_score: 0.3589 - val_loss: 0.1566 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 768/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0490 - acc: 0.9863 - recall: 0.3320 - fbeta_score: 0.3337 - val_loss: 0.1566 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 769/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0489 - acc: 0.9858 - recall: 0.3333 - fbeta_score: 0.3378 - val_loss: 0.1572 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 770/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0489 - acc: 0.9863 - recall: 0.3385 - fbeta_score: 0.3398 - val_loss: 0.1571 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 771/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0488 - acc: 0.9858 - recall: 0.3442 - fbeta_score: 0.3499 - val_loss: 0.1574 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 772/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0488 - acc: 0.9863 - recall: 0.3345 - fbeta_score: 0.3351 - val_loss: 0.1576 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 773/1000\n",
      "2048/2048 [==============================] - 0s 86us/step - loss: 0.0487 - acc: 0.9863 - recall: 0.3605 - fbeta_score: 0.3621 - val_loss: 0.1575 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 774/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0487 - acc: 0.9863 - recall: 0.3587 - fbeta_score: 0.3602 - val_loss: 0.1576 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 775/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0486 - acc: 0.9854 - recall: 0.3402 - fbeta_score: 0.3382 - val_loss: 0.1577 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 776/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0485 - acc: 0.9863 - recall: 0.3392 - fbeta_score: 0.3390 - val_loss: 0.1580 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 777/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0484 - acc: 0.9858 - recall: 0.3239 - fbeta_score: 0.3289 - val_loss: 0.1585 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 778/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0485 - acc: 0.9863 - recall: 0.3361 - fbeta_score: 0.3410 - val_loss: 0.1580 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 779/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0484 - acc: 0.9858 - recall: 0.3376 - fbeta_score: 0.3433 - val_loss: 0.1580 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 780/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0484 - acc: 0.9863 - recall: 0.3469 - fbeta_score: 0.3520 - val_loss: 0.1583 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 781/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0483 - acc: 0.9854 - recall: 0.3475 - fbeta_score: 0.3490 - val_loss: 0.1583 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 782/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0482 - acc: 0.9863 - recall: 0.3563 - fbeta_score: 0.3535 - val_loss: 0.1584 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 783/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0482 - acc: 0.9863 - recall: 0.3433 - fbeta_score: 0.3447 - val_loss: 0.1584 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 784/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0481 - acc: 0.9863 - recall: 0.3481 - fbeta_score: 0.3490 - val_loss: 0.1588 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 785/1000\n",
      "2048/2048 [==============================] - 0s 104us/step - loss: 0.0481 - acc: 0.9863 - recall: 0.3092 - fbeta_score: 0.3141 - val_loss: 0.1590 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 786/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0481 - acc: 0.9858 - recall: 0.3148 - fbeta_score: 0.3171 - val_loss: 0.1589 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 787/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0480 - acc: 0.9868 - recall: 0.3612 - fbeta_score: 0.3675 - val_loss: 0.1592 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 788/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0479 - acc: 0.9863 - recall: 0.3410 - fbeta_score: 0.3447 - val_loss: 0.1588 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 789/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0479 - acc: 0.9868 - recall: 0.3288 - fbeta_score: 0.3312 - val_loss: 0.1589 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 790/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0478 - acc: 0.9863 - recall: 0.3385 - fbeta_score: 0.3394 - val_loss: 0.1589 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 791/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0478 - acc: 0.9858 - recall: 0.3475 - fbeta_score: 0.3498 - val_loss: 0.1593 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 792/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0477 - acc: 0.9863 - recall: 0.3467 - fbeta_score: 0.3499 - val_loss: 0.1593 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 793/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0477 - acc: 0.9868 - recall: 0.3573 - fbeta_score: 0.3636 - val_loss: 0.1594 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 794/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0476 - acc: 0.9868 - recall: 0.3654 - fbeta_score: 0.3708 - val_loss: 0.1595 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 795/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0476 - acc: 0.9858 - recall: 0.3459 - fbeta_score: 0.3442 - val_loss: 0.1597 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 796/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0476 - acc: 0.9863 - recall: 0.3337 - fbeta_score: 0.3415 - val_loss: 0.1598 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 797/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0475 - acc: 0.9868 - recall: 0.3418 - fbeta_score: 0.3434 - val_loss: 0.1599 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 798/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0474 - acc: 0.9868 - recall: 0.3524 - fbeta_score: 0.3547 - val_loss: 0.1600 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 799/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0474 - acc: 0.9868 - recall: 0.3442 - fbeta_score: 0.3441 - val_loss: 0.1604 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 800/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0473 - acc: 0.9868 - recall: 0.3646 - fbeta_score: 0.3685 - val_loss: 0.1601 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 801/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0472 - acc: 0.9868 - recall: 0.3343 - fbeta_score: 0.3358 - val_loss: 0.1606 - val_acc: 0.9522 - val_recall: 0.2029 - val_fbeta_score: 0.2101\n",
      "Epoch 802/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0473 - acc: 0.9868 - recall: 0.3564 - fbeta_score: 0.3573 - val_loss: 0.1606 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 803/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0472 - acc: 0.9863 - recall: 0.3359 - fbeta_score: 0.3351 - val_loss: 0.1606 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 804/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0471 - acc: 0.9868 - recall: 0.3127 - fbeta_score: 0.3141 - val_loss: 0.1604 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 805/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0471 - acc: 0.9863 - recall: 0.3498 - fbeta_score: 0.3503 - val_loss: 0.1607 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 806/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0471 - acc: 0.9863 - recall: 0.3630 - fbeta_score: 0.3643 - val_loss: 0.1609 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 807/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0470 - acc: 0.9863 - recall: 0.3262 - fbeta_score: 0.3298 - val_loss: 0.1610 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 808/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0470 - acc: 0.9863 - recall: 0.3361 - fbeta_score: 0.3398 - val_loss: 0.1614 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 809/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0469 - acc: 0.9863 - recall: 0.3324 - fbeta_score: 0.3391 - val_loss: 0.1615 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 810/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0469 - acc: 0.9868 - recall: 0.3174 - fbeta_score: 0.3211 - val_loss: 0.1612 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 811/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0468 - acc: 0.9863 - recall: 0.3469 - fbeta_score: 0.3515 - val_loss: 0.1613 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 812/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0468 - acc: 0.9868 - recall: 0.3589 - fbeta_score: 0.3589 - val_loss: 0.1615 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 813/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0467 - acc: 0.9863 - recall: 0.3394 - fbeta_score: 0.3400 - val_loss: 0.1614 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 814/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0467 - acc: 0.9863 - recall: 0.3237 - fbeta_score: 0.3262 - val_loss: 0.1616 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 815/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0466 - acc: 0.9863 - recall: 0.3237 - fbeta_score: 0.3289 - val_loss: 0.1616 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 816/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0466 - acc: 0.9868 - recall: 0.3381 - fbeta_score: 0.3401 - val_loss: 0.1615 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 817/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0465 - acc: 0.9863 - recall: 0.3490 - fbeta_score: 0.3511 - val_loss: 0.1614 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 818/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0465 - acc: 0.9863 - recall: 0.3459 - fbeta_score: 0.3477 - val_loss: 0.1617 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 819/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0464 - acc: 0.9863 - recall: 0.3219 - fbeta_score: 0.3245 - val_loss: 0.1617 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 820/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0464 - acc: 0.9863 - recall: 0.3255 - fbeta_score: 0.3287 - val_loss: 0.1620 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 821/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0463 - acc: 0.9868 - recall: 0.3499 - fbeta_score: 0.3557 - val_loss: 0.1622 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 822/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0463 - acc: 0.9863 - recall: 0.3573 - fbeta_score: 0.3587 - val_loss: 0.1623 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 823/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0462 - acc: 0.9868 - recall: 0.3441 - fbeta_score: 0.3496 - val_loss: 0.1626 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 824/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0462 - acc: 0.9868 - recall: 0.3518 - fbeta_score: 0.3564 - val_loss: 0.1628 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 825/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0461 - acc: 0.9863 - recall: 0.3540 - fbeta_score: 0.3574 - val_loss: 0.1627 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 826/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0461 - acc: 0.9863 - recall: 0.3528 - fbeta_score: 0.3556 - val_loss: 0.1628 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0461 - acc: 0.9863 - recall: 0.3384 - fbeta_score: 0.3428 - val_loss: 0.1627 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 828/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0460 - acc: 0.9873 - recall: 0.3475 - fbeta_score: 0.3490 - val_loss: 0.1630 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 829/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0460 - acc: 0.9863 - recall: 0.3556 - fbeta_score: 0.3545 - val_loss: 0.1633 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 830/1000\n",
      "2048/2048 [==============================] - 0s 92us/step - loss: 0.0459 - acc: 0.9863 - recall: 0.3400 - fbeta_score: 0.3436 - val_loss: 0.1636 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 831/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0459 - acc: 0.9868 - recall: 0.3125 - fbeta_score: 0.3177 - val_loss: 0.1634 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 832/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0458 - acc: 0.9863 - recall: 0.3564 - fbeta_score: 0.3602 - val_loss: 0.1633 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 833/1000\n",
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0457 - acc: 0.9863 - recall: 0.3499 - fbeta_score: 0.3538 - val_loss: 0.1633 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 834/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0458 - acc: 0.9868 - recall: 0.3613 - fbeta_score: 0.3613 - val_loss: 0.1632 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 835/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0456 - acc: 0.9868 - recall: 0.3491 - fbeta_score: 0.3499 - val_loss: 0.1638 - val_acc: 0.9534 - val_recall: 0.2067 - val_fbeta_score: 0.2135\n",
      "Epoch 836/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0456 - acc: 0.9863 - recall: 0.3343 - fbeta_score: 0.3348 - val_loss: 0.1637 - val_acc: 0.9511 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 837/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0456 - acc: 0.9863 - recall: 0.3141 - fbeta_score: 0.3182 - val_loss: 0.1640 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 838/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0455 - acc: 0.9863 - recall: 0.3198 - fbeta_score: 0.3193 - val_loss: 0.1640 - val_acc: 0.9511 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 839/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0455 - acc: 0.9863 - recall: 0.3319 - fbeta_score: 0.3322 - val_loss: 0.1640 - val_acc: 0.9511 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 840/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0454 - acc: 0.9868 - recall: 0.3646 - fbeta_score: 0.3669 - val_loss: 0.1640 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 841/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0454 - acc: 0.9868 - recall: 0.3416 - fbeta_score: 0.3439 - val_loss: 0.1638 - val_acc: 0.9511 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 842/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0454 - acc: 0.9863 - recall: 0.3320 - fbeta_score: 0.3385 - val_loss: 0.1643 - val_acc: 0.9511 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 843/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0453 - acc: 0.9868 - recall: 0.3685 - fbeta_score: 0.3714 - val_loss: 0.1643 - val_acc: 0.9511 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 844/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0453 - acc: 0.9863 - recall: 0.3385 - fbeta_score: 0.3431 - val_loss: 0.1642 - val_acc: 0.9511 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 845/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0452 - acc: 0.9868 - recall: 0.3542 - fbeta_score: 0.3548 - val_loss: 0.1641 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 846/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0452 - acc: 0.9863 - recall: 0.3384 - fbeta_score: 0.3467 - val_loss: 0.1647 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 847/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0452 - acc: 0.9868 - recall: 0.3385 - fbeta_score: 0.3389 - val_loss: 0.1645 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 848/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0451 - acc: 0.9863 - recall: 0.3532 - fbeta_score: 0.3540 - val_loss: 0.1647 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 849/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0451 - acc: 0.9868 - recall: 0.3441 - fbeta_score: 0.3451 - val_loss: 0.1647 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 850/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0450 - acc: 0.9863 - recall: 0.3735 - fbeta_score: 0.3768 - val_loss: 0.1649 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 851/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0450 - acc: 0.9863 - recall: 0.3304 - fbeta_score: 0.3311 - val_loss: 0.1650 - val_acc: 0.9511 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 852/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0450 - acc: 0.9868 - recall: 0.3442 - fbeta_score: 0.3451 - val_loss: 0.1649 - val_acc: 0.9511 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 853/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0449 - acc: 0.9868 - recall: 0.3695 - fbeta_score: 0.3701 - val_loss: 0.1652 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 854/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0449 - acc: 0.9868 - recall: 0.3613 - fbeta_score: 0.3605 - val_loss: 0.1647 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 855/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0448 - acc: 0.9868 - recall: 0.3467 - fbeta_score: 0.3467 - val_loss: 0.1652 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 856/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0448 - acc: 0.9868 - recall: 0.3416 - fbeta_score: 0.3447 - val_loss: 0.1653 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 857/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0447 - acc: 0.9863 - recall: 0.3357 - fbeta_score: 0.3369 - val_loss: 0.1655 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 858/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0447 - acc: 0.9868 - recall: 0.3579 - fbeta_score: 0.3577 - val_loss: 0.1654 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 859/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0447 - acc: 0.9868 - recall: 0.3548 - fbeta_score: 0.3604 - val_loss: 0.1656 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 860/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0446 - acc: 0.9868 - recall: 0.3308 - fbeta_score: 0.3346 - val_loss: 0.1654 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 861/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0446 - acc: 0.9868 - recall: 0.3320 - fbeta_score: 0.3320 - val_loss: 0.1656 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 862/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0445 - acc: 0.9868 - recall: 0.3506 - fbeta_score: 0.3490 - val_loss: 0.1658 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 863/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 93us/step - loss: 0.0445 - acc: 0.9873 - recall: 0.3524 - fbeta_score: 0.3574 - val_loss: 0.1658 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 864/1000\n",
      "2048/2048 [==============================] - 0s 106us/step - loss: 0.0445 - acc: 0.9868 - recall: 0.3328 - fbeta_score: 0.3408 - val_loss: 0.1659 - val_acc: 0.9522 - val_recall: 0.2067 - val_fbeta_score: 0.2116\n",
      "Epoch 865/1000\n",
      "2048/2048 [==============================] - 0s 147us/step - loss: 0.0444 - acc: 0.9868 - recall: 0.3573 - fbeta_score: 0.3620 - val_loss: 0.1656 - val_acc: 0.9522 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 866/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0444 - acc: 0.9868 - recall: 0.3408 - fbeta_score: 0.3423 - val_loss: 0.1659 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 867/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0444 - acc: 0.9868 - recall: 0.3597 - fbeta_score: 0.3602 - val_loss: 0.1657 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 868/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0443 - acc: 0.9863 - recall: 0.3441 - fbeta_score: 0.3496 - val_loss: 0.1661 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 869/1000\n",
      "2048/2048 [==============================] - 0s 91us/step - loss: 0.0443 - acc: 0.9868 - recall: 0.3335 - fbeta_score: 0.3359 - val_loss: 0.1665 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 870/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0442 - acc: 0.9868 - recall: 0.3418 - fbeta_score: 0.3437 - val_loss: 0.1664 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 871/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0442 - acc: 0.9868 - recall: 0.3210 - fbeta_score: 0.3257 - val_loss: 0.1666 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 872/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0441 - acc: 0.9868 - recall: 0.3630 - fbeta_score: 0.3626 - val_loss: 0.1668 - val_acc: 0.9522 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 873/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0441 - acc: 0.9868 - recall: 0.3426 - fbeta_score: 0.3473 - val_loss: 0.1666 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 874/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0441 - acc: 0.9868 - recall: 0.3585 - fbeta_score: 0.3613 - val_loss: 0.1666 - val_acc: 0.9522 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 875/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0440 - acc: 0.9868 - recall: 0.3573 - fbeta_score: 0.3604 - val_loss: 0.1665 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 876/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0440 - acc: 0.9868 - recall: 0.3369 - fbeta_score: 0.3385 - val_loss: 0.1664 - val_acc: 0.9522 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 877/1000\n",
      "2048/2048 [==============================] - 0s 87us/step - loss: 0.0439 - acc: 0.9868 - recall: 0.3681 - fbeta_score: 0.3702 - val_loss: 0.1662 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 878/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0439 - acc: 0.9868 - recall: 0.3564 - fbeta_score: 0.3564 - val_loss: 0.1666 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 879/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0439 - acc: 0.9868 - recall: 0.3359 - fbeta_score: 0.3376 - val_loss: 0.1668 - val_acc: 0.9522 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 880/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0439 - acc: 0.9868 - recall: 0.3188 - fbeta_score: 0.3245 - val_loss: 0.1672 - val_acc: 0.9522 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 881/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0438 - acc: 0.9868 - recall: 0.3442 - fbeta_score: 0.3498 - val_loss: 0.1671 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 882/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0438 - acc: 0.9868 - recall: 0.3402 - fbeta_score: 0.3398 - val_loss: 0.1672 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 883/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0437 - acc: 0.9868 - recall: 0.3503 - fbeta_score: 0.3533 - val_loss: 0.1672 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 884/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0437 - acc: 0.9863 - recall: 0.3524 - fbeta_score: 0.3547 - val_loss: 0.1674 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 885/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0437 - acc: 0.9868 - recall: 0.3638 - fbeta_score: 0.3695 - val_loss: 0.1671 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 886/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0436 - acc: 0.9868 - recall: 0.3587 - fbeta_score: 0.3610 - val_loss: 0.1673 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 887/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0436 - acc: 0.9868 - recall: 0.3498 - fbeta_score: 0.3530 - val_loss: 0.1674 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 888/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0436 - acc: 0.9873 - recall: 0.3418 - fbeta_score: 0.3439 - val_loss: 0.1676 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 889/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0435 - acc: 0.9868 - recall: 0.3752 - fbeta_score: 0.3768 - val_loss: 0.1675 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 890/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0435 - acc: 0.9868 - recall: 0.3573 - fbeta_score: 0.3628 - val_loss: 0.1676 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 891/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0435 - acc: 0.9868 - recall: 0.3414 - fbeta_score: 0.3401 - val_loss: 0.1675 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 892/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0434 - acc: 0.9868 - recall: 0.3613 - fbeta_score: 0.3604 - val_loss: 0.1678 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 893/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0434 - acc: 0.9868 - recall: 0.3581 - fbeta_score: 0.3555 - val_loss: 0.1679 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 894/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0434 - acc: 0.9868 - recall: 0.3451 - fbeta_score: 0.3457 - val_loss: 0.1679 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 895/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0433 - acc: 0.9868 - recall: 0.3530 - fbeta_score: 0.3577 - val_loss: 0.1677 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 896/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0433 - acc: 0.9868 - recall: 0.3491 - fbeta_score: 0.3499 - val_loss: 0.1680 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 897/1000\n",
      "2048/2048 [==============================] - 0s 103us/step - loss: 0.0432 - acc: 0.9868 - recall: 0.3560 - fbeta_score: 0.3588 - val_loss: 0.1681 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 898/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0432 - acc: 0.9868 - recall: 0.3548 - fbeta_score: 0.3613 - val_loss: 0.1683 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 899/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0432 - acc: 0.9873 - recall: 0.3687 - fbeta_score: 0.3711 - val_loss: 0.1685 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 900/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0431 - acc: 0.9868 - recall: 0.3434 - fbeta_score: 0.3447 - val_loss: 0.1685 - val_acc: 0.9511 - val_recall: 0.1953 - val_fbeta_score: 0.2002\n",
      "Epoch 901/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0431 - acc: 0.9868 - recall: 0.3617 - fbeta_score: 0.3614 - val_loss: 0.1684 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 902/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0431 - acc: 0.9868 - recall: 0.3502 - fbeta_score: 0.3538 - val_loss: 0.1681 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 903/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0430 - acc: 0.9868 - recall: 0.3442 - fbeta_score: 0.3514 - val_loss: 0.1682 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 904/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0430 - acc: 0.9868 - recall: 0.3250 - fbeta_score: 0.3266 - val_loss: 0.1684 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 905/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0430 - acc: 0.9868 - recall: 0.3499 - fbeta_score: 0.3529 - val_loss: 0.1684 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 906/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0429 - acc: 0.9868 - recall: 0.3467 - fbeta_score: 0.3467 - val_loss: 0.1683 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 907/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0429 - acc: 0.9868 - recall: 0.3426 - fbeta_score: 0.3441 - val_loss: 0.1684 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 908/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0428 - acc: 0.9868 - recall: 0.3271 - fbeta_score: 0.3324 - val_loss: 0.1684 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 909/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0428 - acc: 0.9868 - recall: 0.3880 - fbeta_score: 0.3919 - val_loss: 0.1688 - val_acc: 0.9499 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 910/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0428 - acc: 0.9868 - recall: 0.3426 - fbeta_score: 0.3481 - val_loss: 0.1687 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 911/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0427 - acc: 0.9868 - recall: 0.3703 - fbeta_score: 0.3703 - val_loss: 0.1686 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 912/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0427 - acc: 0.9868 - recall: 0.3414 - fbeta_score: 0.3457 - val_loss: 0.1685 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 913/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0427 - acc: 0.9868 - recall: 0.3687 - fbeta_score: 0.3670 - val_loss: 0.1685 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 914/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0426 - acc: 0.9868 - recall: 0.3340 - fbeta_score: 0.3371 - val_loss: 0.1689 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 915/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0426 - acc: 0.9868 - recall: 0.3608 - fbeta_score: 0.3607 - val_loss: 0.1690 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 916/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0426 - acc: 0.9868 - recall: 0.3491 - fbeta_score: 0.3516 - val_loss: 0.1689 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 917/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0425 - acc: 0.9873 - recall: 0.3750 - fbeta_score: 0.3732 - val_loss: 0.1692 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 918/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0425 - acc: 0.9868 - recall: 0.3231 - fbeta_score: 0.3262 - val_loss: 0.1688 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 919/1000\n",
      "2048/2048 [==============================] - 0s 95us/step - loss: 0.0425 - acc: 0.9868 - recall: 0.3530 - fbeta_score: 0.3555 - val_loss: 0.1692 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 920/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0425 - acc: 0.9868 - recall: 0.3311 - fbeta_score: 0.3341 - val_loss: 0.1692 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 921/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0424 - acc: 0.9868 - recall: 0.3455 - fbeta_score: 0.3483 - val_loss: 0.1692 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 922/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0424 - acc: 0.9868 - recall: 0.3552 - fbeta_score: 0.3574 - val_loss: 0.1695 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 923/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0423 - acc: 0.9868 - recall: 0.3255 - fbeta_score: 0.3281 - val_loss: 0.1694 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 924/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0423 - acc: 0.9863 - recall: 0.3563 - fbeta_score: 0.3561 - val_loss: 0.1693 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 925/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0423 - acc: 0.9868 - recall: 0.3483 - fbeta_score: 0.3534 - val_loss: 0.1694 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 926/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0422 - acc: 0.9868 - recall: 0.3505 - fbeta_score: 0.3499 - val_loss: 0.1695 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 927/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0422 - acc: 0.9873 - recall: 0.3245 - fbeta_score: 0.3301 - val_loss: 0.1697 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 928/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0422 - acc: 0.9868 - recall: 0.3499 - fbeta_score: 0.3521 - val_loss: 0.1698 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 929/1000\n",
      "2048/2048 [==============================] - 0s 104us/step - loss: 0.0422 - acc: 0.9868 - recall: 0.3514 - fbeta_score: 0.3560 - val_loss: 0.1697 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 930/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0421 - acc: 0.9868 - recall: 0.3441 - fbeta_score: 0.3480 - val_loss: 0.1697 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 931/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0421 - acc: 0.9868 - recall: 0.3605 - fbeta_score: 0.3659 - val_loss: 0.1697 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 932/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0421 - acc: 0.9868 - recall: 0.3451 - fbeta_score: 0.3473 - val_loss: 0.1700 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 933/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0420 - acc: 0.9868 - recall: 0.3416 - fbeta_score: 0.3437 - val_loss: 0.1701 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 934/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0420 - acc: 0.9868 - recall: 0.3638 - fbeta_score: 0.3669 - val_loss: 0.1702 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 935/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0420 - acc: 0.9868 - recall: 0.3174 - fbeta_score: 0.3219 - val_loss: 0.1703 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 936/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0420 - acc: 0.9868 - recall: 0.3231 - fbeta_score: 0.3278 - val_loss: 0.1704 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 937/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0419 - acc: 0.9868 - recall: 0.3426 - fbeta_score: 0.3415 - val_loss: 0.1705 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 938/1000\n",
      "2048/2048 [==============================] - 0s 85us/step - loss: 0.0419 - acc: 0.9868 - recall: 0.3296 - fbeta_score: 0.3341 - val_loss: 0.1707 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 939/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0418 - acc: 0.9873 - recall: 0.3784 - fbeta_score: 0.3760 - val_loss: 0.1705 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 940/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0418 - acc: 0.9863 - recall: 0.3402 - fbeta_score: 0.3392 - val_loss: 0.1702 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 941/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0418 - acc: 0.9873 - recall: 0.3337 - fbeta_score: 0.3374 - val_loss: 0.1705 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 942/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0417 - acc: 0.9868 - recall: 0.3467 - fbeta_score: 0.3451 - val_loss: 0.1710 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 943/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0417 - acc: 0.9868 - recall: 0.3479 - fbeta_score: 0.3460 - val_loss: 0.1707 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 944/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0417 - acc: 0.9868 - recall: 0.3394 - fbeta_score: 0.3402 - val_loss: 0.1705 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 945/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0417 - acc: 0.9878 - recall: 0.3540 - fbeta_score: 0.3581 - val_loss: 0.1709 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 946/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0416 - acc: 0.9868 - recall: 0.3495 - fbeta_score: 0.3554 - val_loss: 0.1711 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 947/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0416 - acc: 0.9868 - recall: 0.3524 - fbeta_score: 0.3529 - val_loss: 0.1711 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 948/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0416 - acc: 0.9868 - recall: 0.3646 - fbeta_score: 0.3652 - val_loss: 0.1711 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 949/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0416 - acc: 0.9868 - recall: 0.3343 - fbeta_score: 0.3421 - val_loss: 0.1710 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 950/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0415 - acc: 0.9868 - recall: 0.3140 - fbeta_score: 0.3197 - val_loss: 0.1710 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 951/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0415 - acc: 0.9868 - recall: 0.3491 - fbeta_score: 0.3464 - val_loss: 0.1711 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 952/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0415 - acc: 0.9878 - recall: 0.3833 - fbeta_score: 0.3864 - val_loss: 0.1715 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 953/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0414 - acc: 0.9868 - recall: 0.3361 - fbeta_score: 0.3350 - val_loss: 0.1715 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 954/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0414 - acc: 0.9868 - recall: 0.3597 - fbeta_score: 0.3636 - val_loss: 0.1713 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 955/1000\n",
      "2048/2048 [==============================] - 0s 108us/step - loss: 0.0414 - acc: 0.9873 - recall: 0.3866 - fbeta_score: 0.3880 - val_loss: 0.1715 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 956/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0414 - acc: 0.9868 - recall: 0.3426 - fbeta_score: 0.3444 - val_loss: 0.1714 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 957/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0414 - acc: 0.9868 - recall: 0.3564 - fbeta_score: 0.3541 - val_loss: 0.1717 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 958/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0413 - acc: 0.9878 - recall: 0.3345 - fbeta_score: 0.3410 - val_loss: 0.1716 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 959/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0413 - acc: 0.9873 - recall: 0.3620 - fbeta_score: 0.3682 - val_loss: 0.1716 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 960/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0412 - acc: 0.9868 - recall: 0.3581 - fbeta_score: 0.3605 - val_loss: 0.1720 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 961/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0412 - acc: 0.9868 - recall: 0.3560 - fbeta_score: 0.3590 - val_loss: 0.1718 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 962/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0412 - acc: 0.9868 - recall: 0.3304 - fbeta_score: 0.3325 - val_loss: 0.1717 - val_acc: 0.9522 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 963/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0411 - acc: 0.9873 - recall: 0.3323 - fbeta_score: 0.3355 - val_loss: 0.1720 - val_acc: 0.9511 - val_recall: 0.1915 - val_fbeta_score: 0.1968\n",
      "Epoch 964/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0411 - acc: 0.9873 - recall: 0.3491 - fbeta_score: 0.3522 - val_loss: 0.1721 - val_acc: 0.9522 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 965/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0411 - acc: 0.9863 - recall: 0.3408 - fbeta_score: 0.3428 - val_loss: 0.1721 - val_acc: 0.9522 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 966/1000\n",
      "2048/2048 [==============================] - 0s 100us/step - loss: 0.0411 - acc: 0.9868 - recall: 0.3339 - fbeta_score: 0.3401 - val_loss: 0.1716 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 967/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0410 - acc: 0.9883 - recall: 0.3658 - fbeta_score: 0.3678 - val_loss: 0.1717 - val_acc: 0.9522 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 968/1000\n",
      "2048/2048 [==============================] - 0s 103us/step - loss: 0.0410 - acc: 0.9873 - recall: 0.3491 - fbeta_score: 0.3548 - val_loss: 0.1717 - val_acc: 0.9522 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 969/1000\n",
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0410 - acc: 0.9878 - recall: 0.3809 - fbeta_score: 0.3831 - val_loss: 0.1719 - val_acc: 0.9522 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 970/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0410 - acc: 0.9873 - recall: 0.3351 - fbeta_score: 0.3433 - val_loss: 0.1718 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 971/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 94us/step - loss: 0.0409 - acc: 0.9868 - recall: 0.3524 - fbeta_score: 0.3561 - val_loss: 0.1719 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 972/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0409 - acc: 0.9878 - recall: 0.3499 - fbeta_score: 0.3522 - val_loss: 0.1719 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 973/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0409 - acc: 0.9888 - recall: 0.3182 - fbeta_score: 0.3242 - val_loss: 0.1721 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 974/1000\n",
      "2048/2048 [==============================] - 0s 83us/step - loss: 0.0408 - acc: 0.9873 - recall: 0.3359 - fbeta_score: 0.3352 - val_loss: 0.1724 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 975/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0408 - acc: 0.9863 - recall: 0.3487 - fbeta_score: 0.3514 - val_loss: 0.1723 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 976/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0408 - acc: 0.9873 - recall: 0.3630 - fbeta_score: 0.3691 - val_loss: 0.1721 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 977/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0408 - acc: 0.9878 - recall: 0.3516 - fbeta_score: 0.3563 - val_loss: 0.1723 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 978/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0408 - acc: 0.9883 - recall: 0.3400 - fbeta_score: 0.3437 - val_loss: 0.1725 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 979/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0407 - acc: 0.9873 - recall: 0.3465 - fbeta_score: 0.3451 - val_loss: 0.1727 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 980/1000\n",
      "2048/2048 [==============================] - 0s 106us/step - loss: 0.0407 - acc: 0.9868 - recall: 0.3734 - fbeta_score: 0.3781 - val_loss: 0.1725 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 981/1000\n",
      "2048/2048 [==============================] - 0s 105us/step - loss: 0.0407 - acc: 0.9873 - recall: 0.3662 - fbeta_score: 0.3659 - val_loss: 0.1725 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 982/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0406 - acc: 0.9883 - recall: 0.3665 - fbeta_score: 0.3694 - val_loss: 0.1728 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 983/1000\n",
      "2048/2048 [==============================] - 0s 102us/step - loss: 0.0406 - acc: 0.9873 - recall: 0.3491 - fbeta_score: 0.3532 - val_loss: 0.1727 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 984/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0406 - acc: 0.9873 - recall: 0.3490 - fbeta_score: 0.3470 - val_loss: 0.1730 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 985/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0406 - acc: 0.9873 - recall: 0.3532 - fbeta_score: 0.3561 - val_loss: 0.1733 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 986/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0406 - acc: 0.9883 - recall: 0.3400 - fbeta_score: 0.3428 - val_loss: 0.1733 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 987/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0405 - acc: 0.9868 - recall: 0.3426 - fbeta_score: 0.3392 - val_loss: 0.1730 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 988/1000\n",
      "2048/2048 [==============================] - 0s 97us/step - loss: 0.0405 - acc: 0.9868 - recall: 0.3247 - fbeta_score: 0.3293 - val_loss: 0.1730 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 989/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0405 - acc: 0.9878 - recall: 0.3857 - fbeta_score: 0.3864 - val_loss: 0.1731 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 990/1000\n",
      "2048/2048 [==============================] - 0s 89us/step - loss: 0.0404 - acc: 0.9878 - recall: 0.3711 - fbeta_score: 0.3719 - val_loss: 0.1733 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 991/1000\n",
      "2048/2048 [==============================] - 0s 96us/step - loss: 0.0404 - acc: 0.9878 - recall: 0.3288 - fbeta_score: 0.3283 - val_loss: 0.1732 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 992/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0404 - acc: 0.9878 - recall: 0.3457 - fbeta_score: 0.3472 - val_loss: 0.1735 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 993/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0404 - acc: 0.9873 - recall: 0.3394 - fbeta_score: 0.3382 - val_loss: 0.1733 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 994/1000\n",
      "2048/2048 [==============================] - 0s 90us/step - loss: 0.0403 - acc: 0.9878 - recall: 0.3734 - fbeta_score: 0.3708 - val_loss: 0.1731 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 995/1000\n",
      "2048/2048 [==============================] - 0s 88us/step - loss: 0.0403 - acc: 0.9873 - recall: 0.3532 - fbeta_score: 0.3556 - val_loss: 0.1733 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 996/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0403 - acc: 0.9883 - recall: 0.3487 - fbeta_score: 0.3499 - val_loss: 0.1733 - val_acc: 0.9511 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 997/1000\n",
      "2048/2048 [==============================] - 0s 98us/step - loss: 0.0403 - acc: 0.9878 - recall: 0.3516 - fbeta_score: 0.3522 - val_loss: 0.1736 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 998/1000\n",
      "2048/2048 [==============================] - 0s 101us/step - loss: 0.0402 - acc: 0.9883 - recall: 0.3547 - fbeta_score: 0.3584 - val_loss: 0.1736 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 999/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0402 - acc: 0.9873 - recall: 0.3369 - fbeta_score: 0.3424 - val_loss: 0.1736 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n",
      "Epoch 1000/1000\n",
      "2048/2048 [==============================] - 0s 99us/step - loss: 0.0402 - acc: 0.9893 - recall: 0.3662 - fbeta_score: 0.3701 - val_loss: 0.1739 - val_acc: 0.9499 - val_recall: 0.1972 - val_fbeta_score: 0.2025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19163424550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_scale_train, y_train,\n",
    "                epochs=1000,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_scale_test, y_test), class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con una sola capa oculta de 10 unidades conseguimos una precisión mayor que con los modelos basados en regresión logística, pero empora bastante el recall. \n",
    "\n",
    "Como función de activación de las capas ocultas usamos \"softsign\" ya que nos ha dado mejores resultados que \"relu\", la capa de salida al ser de clasificación usa una función de activación \"sigmoid\"\n",
    "\n",
    "Para inicializar usamos \"he_uniform\" que nos ayuda con el \"Vanishing Gradient\"\n",
    "\n",
    "Para los siguientes modelos tambien escalaremos los pesos de las capas ocultas para evitar el Covariate Shift\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Capa (Deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4))\n",
    "\n",
    "x = Input(shape=(23,))\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform')(x)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform')(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform')(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform')(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "y = Dense(1, activation='sigmoid',kernel_initializer='he_uniform')(layer)\n",
    "mlp2 = Model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2.compile(optimizer='sgd',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', recall, fbeta_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1843 samples, validate on 205 samples\n",
      "Epoch 1/1000\n",
      "1843/1843 [==============================] - 1s 798us/step - loss: 0.4630 - acc: 0.8014 - recall: 0.1881 - fbeta_score: 0.1332 - val_loss: 0.2829 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 2/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.2305 - acc: 0.9468 - recall: 0.0868 - fbeta_score: 0.0940 - val_loss: 0.2035 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 3/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.1777 - acc: 0.9533 - recall: 0.0959 - fbeta_score: 0.1002 - val_loss: 0.1823 - val_acc: 0.9415 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 4/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.1555 - acc: 0.9490 - recall: 0.0868 - fbeta_score: 0.0913 - val_loss: 0.1812 - val_acc: 0.9415 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 5/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.1432 - acc: 0.9506 - recall: 0.1017 - fbeta_score: 0.1053 - val_loss: 0.1754 - val_acc: 0.9463 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 6/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.1287 - acc: 0.9550 - recall: 0.1248 - fbeta_score: 0.1284 - val_loss: 0.1624 - val_acc: 0.9512 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 7/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.1235 - acc: 0.9560 - recall: 0.1248 - fbeta_score: 0.1302 - val_loss: 0.1683 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 8/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.1136 - acc: 0.9588 - recall: 0.1619 - fbeta_score: 0.1673 - val_loss: 0.1613 - val_acc: 0.9463 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 9/1000\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1166 - acc: 0.9588 - recall: 0.1564 - fbeta_score: 0.1624 - val_loss: 0.1666 - val_acc: 0.9512 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 10/1000\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1139 - acc: 0.9582 - recall: 0.1302 - fbeta_score: 0.1355 - val_loss: 0.1525 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 11/1000\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.0976 - acc: 0.9653 - recall: 0.2053 - fbeta_score: 0.2105 - val_loss: 0.1538 - val_acc: 0.9512 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 12/1000\n",
      "1843/1843 [==============================] - 0s 263us/step - loss: 0.0931 - acc: 0.9669 - recall: 0.2179 - fbeta_score: 0.2241 - val_loss: 0.1695 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 13/1000\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.0950 - acc: 0.9636 - recall: 0.2130 - fbeta_score: 0.2190 - val_loss: 0.1689 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 14/1000\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 0.0943 - acc: 0.9658 - recall: 0.1872 - fbeta_score: 0.1970 - val_loss: 0.1619 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 15/1000\n",
      "1843/1843 [==============================] - 0s 255us/step - loss: 0.0857 - acc: 0.9647 - recall: 0.2505 - fbeta_score: 0.2568 - val_loss: 0.1637 - val_acc: 0.9463 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 16/1000\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.0814 - acc: 0.9669 - recall: 0.2035 - fbeta_score: 0.2112 - val_loss: 0.1503 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 17/1000\n",
      "1843/1843 [==============================] - 0s 255us/step - loss: 0.0819 - acc: 0.9718 - recall: 0.2487 - fbeta_score: 0.2541 - val_loss: 0.1775 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 18/1000\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.0838 - acc: 0.9680 - recall: 0.2568 - fbeta_score: 0.2601 - val_loss: 0.1875 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 19/1000\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.0737 - acc: 0.9712 - recall: 0.2487 - fbeta_score: 0.2594 - val_loss: 0.1510 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 20/1000\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.0814 - acc: 0.9691 - recall: 0.2306 - fbeta_score: 0.2413 - val_loss: 0.1397 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 21/1000\n",
      "1843/1843 [==============================] - 0s 258us/step - loss: 0.0754 - acc: 0.9702 - recall: 0.2618 - fbeta_score: 0.2644 - val_loss: 0.1533 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 22/1000\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.0768 - acc: 0.9729 - recall: 0.2686 - fbeta_score: 0.2762 - val_loss: 0.1523 - val_acc: 0.9463 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 23/1000\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.0736 - acc: 0.9729 - recall: 0.2749 - fbeta_score: 0.2811 - val_loss: 0.1399 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 24/1000\n",
      "1843/1843 [==============================] - 0s 269us/step - loss: 0.0693 - acc: 0.9756 - recall: 0.2849 - fbeta_score: 0.2926 - val_loss: 0.1509 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 25/1000\n",
      "1843/1843 [==============================] - 0s 254us/step - loss: 0.0642 - acc: 0.9788 - recall: 0.3237 - fbeta_score: 0.3274 - val_loss: 0.1450 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 26/1000\n",
      "1843/1843 [==============================] - 0s 258us/step - loss: 0.0673 - acc: 0.9740 - recall: 0.2758 - fbeta_score: 0.2776 - val_loss: 0.1687 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 27/1000\n",
      "1843/1843 [==============================] - 0s 258us/step - loss: 0.0588 - acc: 0.9788 - recall: 0.3048 - fbeta_score: 0.3064 - val_loss: 0.1638 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 28/1000\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.0570 - acc: 0.9805 - recall: 0.3228 - fbeta_score: 0.3256 - val_loss: 0.1518 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 29/1000\n",
      "1843/1843 [==============================] - 0s 263us/step - loss: 0.0688 - acc: 0.9745 - recall: 0.2595 - fbeta_score: 0.2666 - val_loss: 0.1620 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 30/1000\n",
      "1843/1843 [==============================] - 1s 299us/step - loss: 0.0627 - acc: 0.9761 - recall: 0.3129 - fbeta_score: 0.3162 - val_loss: 0.1664 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 31/1000\n",
      "1843/1843 [==============================] - 0s 250us/step - loss: 0.0555 - acc: 0.9799 - recall: 0.3048 - fbeta_score: 0.3154 - val_loss: 0.1760 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 32/1000\n",
      "1843/1843 [==============================] - 1s 376us/step - loss: 0.0607 - acc: 0.9767 - recall: 0.2876 - fbeta_score: 0.2910 - val_loss: 0.1532 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 33/1000\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.0483 - acc: 0.9826 - recall: 0.3518 - fbeta_score: 0.3536 - val_loss: 0.1653 - val_acc: 0.9366 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 34/1000\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.0508 - acc: 0.9821 - recall: 0.3237 - fbeta_score: 0.3299 - val_loss: 0.1812 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 35/1000\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.0516 - acc: 0.9853 - recall: 0.3653 - fbeta_score: 0.3699 - val_loss: 0.1758 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 36/1000\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.0521 - acc: 0.9826 - recall: 0.3165 - fbeta_score: 0.3247 - val_loss: 0.1781 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 37/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0489 - acc: 0.9826 - recall: 0.3509 - fbeta_score: 0.3588 - val_loss: 0.1540 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 38/1000\n",
      "1843/1843 [==============================] - 1s 337us/step - loss: 0.0504 - acc: 0.9843 - recall: 0.3572 - fbeta_score: 0.3599 - val_loss: 0.1698 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 39/1000\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 0.0435 - acc: 0.9843 - recall: 0.3445 - fbeta_score: 0.3491 - val_loss: 0.1690 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 40/1000\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.0519 - acc: 0.9810 - recall: 0.3256 - fbeta_score: 0.3326 - val_loss: 0.1900 - val_acc: 0.9366 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 41/1000\n",
      "1843/1843 [==============================] - 0s 260us/step - loss: 0.0597 - acc: 0.9761 - recall: 0.3003 - fbeta_score: 0.3038 - val_loss: 0.1920 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 42/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0517 - acc: 0.9783 - recall: 0.3455 - fbeta_score: 0.3527 - val_loss: 0.1967 - val_acc: 0.9366 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 43/1000\n",
      "1843/1843 [==============================] - 0s 182us/step - loss: 0.0523 - acc: 0.9799 - recall: 0.3156 - fbeta_score: 0.3219 - val_loss: 0.1722 - val_acc: 0.9512 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 44/1000\n",
      "1843/1843 [==============================] - 0s 176us/step - loss: 0.0458 - acc: 0.9843 - recall: 0.3644 - fbeta_score: 0.3715 - val_loss: 0.1802 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 45/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0388 - acc: 0.9859 - recall: 0.3572 - fbeta_score: 0.3650 - val_loss: 0.1700 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 46/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0461 - acc: 0.9848 - recall: 0.3482 - fbeta_score: 0.3516 - val_loss: 0.1850 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 47/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0452 - acc: 0.9826 - recall: 0.3527 - fbeta_score: 0.3597 - val_loss: 0.3768 - val_acc: 0.8829 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 48/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0524 - acc: 0.9810 - recall: 0.3337 - fbeta_score: 0.3344 - val_loss: 0.1984 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 49/1000\n",
      "1843/1843 [==============================] - 0s 182us/step - loss: 0.0478 - acc: 0.9799 - recall: 0.3154 - fbeta_score: 0.3207 - val_loss: 0.1992 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 50/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0400 - acc: 0.9870 - recall: 0.3798 - fbeta_score: 0.3834 - val_loss: 0.1802 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 51/1000\n",
      "1843/1843 [==============================] - 0s 172us/step - loss: 0.0527 - acc: 0.9826 - recall: 0.3292 - fbeta_score: 0.3351 - val_loss: 0.1645 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 52/1000\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.0368 - acc: 0.9875 - recall: 0.3825 - fbeta_score: 0.3816 - val_loss: 0.1867 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 53/1000\n",
      "1843/1843 [==============================] - 0s 172us/step - loss: 0.0384 - acc: 0.9843 - recall: 0.3400 - fbeta_score: 0.3480 - val_loss: 0.1655 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 54/1000\n",
      "1843/1843 [==============================] - 0s 173us/step - loss: 0.0362 - acc: 0.9870 - recall: 0.3884 - fbeta_score: 0.3925 - val_loss: 0.1721 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 55/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0379 - acc: 0.9864 - recall: 0.3500 - fbeta_score: 0.3570 - val_loss: 0.1746 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 56/1000\n",
      "1843/1843 [==============================] - 0s 172us/step - loss: 0.0371 - acc: 0.9875 - recall: 0.3653 - fbeta_score: 0.3686 - val_loss: 0.1716 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 57/1000\n",
      "1843/1843 [==============================] - 0s 181us/step - loss: 0.0343 - acc: 0.9881 - recall: 0.3744 - fbeta_score: 0.3780 - val_loss: 0.2210 - val_acc: 0.9366 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 58/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0385 - acc: 0.9864 - recall: 0.3753 - fbeta_score: 0.3787 - val_loss: 0.1875 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 59/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0392 - acc: 0.9881 - recall: 0.3518 - fbeta_score: 0.3572 - val_loss: 0.1764 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 60/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0227 - acc: 0.9951 - recall: 0.4069 - fbeta_score: 0.4069 - val_loss: 0.1952 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 61/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0403 - acc: 0.9875 - recall: 0.3748 - fbeta_score: 0.3798 - val_loss: 0.1768 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 62/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0344 - acc: 0.9886 - recall: 0.3525 - fbeta_score: 0.3561 - val_loss: 0.1983 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 63/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0288 - acc: 0.9924 - recall: 0.3812 - fbeta_score: 0.3827 - val_loss: 0.2164 - val_acc: 0.9317 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 64/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0312 - acc: 0.9913 - recall: 0.3952 - fbeta_score: 0.3992 - val_loss: 0.1742 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 65/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0264 - acc: 0.9919 - recall: 0.3970 - fbeta_score: 0.4022 - val_loss: 0.1756 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 66/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0278 - acc: 0.9913 - recall: 0.4305 - fbeta_score: 0.4337 - val_loss: 0.1946 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 67/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0315 - acc: 0.9881 - recall: 0.3735 - fbeta_score: 0.3789 - val_loss: 0.1965 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 68/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0354 - acc: 0.9886 - recall: 0.3670 - fbeta_score: 0.3715 - val_loss: 0.2125 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 69/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0325 - acc: 0.9897 - recall: 0.3753 - fbeta_score: 0.3823 - val_loss: 0.1921 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 70/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0324 - acc: 0.9881 - recall: 0.3635 - fbeta_score: 0.3688 - val_loss: 0.2406 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 71/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0277 - acc: 0.9902 - recall: 0.3735 - fbeta_score: 0.3795 - val_loss: 0.1881 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 72/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0277 - acc: 0.9908 - recall: 0.3626 - fbeta_score: 0.3663 - val_loss: 0.1902 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0249 - acc: 0.9908 - recall: 0.4015 - fbeta_score: 0.4051 - val_loss: 0.1936 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 74/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0314 - acc: 0.9886 - recall: 0.3798 - fbeta_score: 0.3834 - val_loss: 0.2288 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 75/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0349 - acc: 0.9875 - recall: 0.3566 - fbeta_score: 0.3597 - val_loss: 0.2051 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 76/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0328 - acc: 0.9886 - recall: 0.3586 - fbeta_score: 0.3630 - val_loss: 0.1964 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 77/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0274 - acc: 0.9891 - recall: 0.3907 - fbeta_score: 0.3943 - val_loss: 0.2275 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 78/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0332 - acc: 0.9881 - recall: 0.3581 - fbeta_score: 0.3652 - val_loss: 0.2032 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 79/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0354 - acc: 0.9886 - recall: 0.3880 - fbeta_score: 0.3892 - val_loss: 0.1702 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 80/1000\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.0351 - acc: 0.9897 - recall: 0.4151 - fbeta_score: 0.4142 - val_loss: 0.2114 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 81/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0365 - acc: 0.9881 - recall: 0.3653 - fbeta_score: 0.3722 - val_loss: 0.2002 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 82/1000\n",
      "1843/1843 [==============================] - 0s 177us/step - loss: 0.0289 - acc: 0.9891 - recall: 0.3880 - fbeta_score: 0.3923 - val_loss: 0.2314 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 83/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0325 - acc: 0.9886 - recall: 0.3549 - fbeta_score: 0.3574 - val_loss: 0.1702 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 84/1000\n",
      "1843/1843 [==============================] - 0s 176us/step - loss: 0.0354 - acc: 0.9875 - recall: 0.3744 - fbeta_score: 0.3742 - val_loss: 0.1747 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 85/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0271 - acc: 0.9908 - recall: 0.3673 - fbeta_score: 0.3724 - val_loss: 0.1938 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 86/1000\n",
      "1843/1843 [==============================] - 0s 182us/step - loss: 0.0257 - acc: 0.9919 - recall: 0.3907 - fbeta_score: 0.3943 - val_loss: 0.1889 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 87/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0305 - acc: 0.9886 - recall: 0.3572 - fbeta_score: 0.3626 - val_loss: 0.1747 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 88/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0262 - acc: 0.9902 - recall: 0.3762 - fbeta_score: 0.3811 - val_loss: 0.1904 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 89/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0264 - acc: 0.9902 - recall: 0.3798 - fbeta_score: 0.3854 - val_loss: 0.1999 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 90/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0281 - acc: 0.9902 - recall: 0.3979 - fbeta_score: 0.4006 - val_loss: 0.1991 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 91/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0242 - acc: 0.9913 - recall: 0.3631 - fbeta_score: 0.3664 - val_loss: 0.1898 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 92/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0284 - acc: 0.9891 - recall: 0.3663 - fbeta_score: 0.3748 - val_loss: 0.1644 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 93/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0256 - acc: 0.9924 - recall: 0.4074 - fbeta_score: 0.4118 - val_loss: 0.1795 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 94/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0220 - acc: 0.9913 - recall: 0.3880 - fbeta_score: 0.3907 - val_loss: 0.1611 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 95/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0293 - acc: 0.9886 - recall: 0.4015 - fbeta_score: 0.4033 - val_loss: 0.2098 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 96/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0264 - acc: 0.9891 - recall: 0.3518 - fbeta_score: 0.3577 - val_loss: 0.1845 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 97/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0272 - acc: 0.9924 - recall: 0.4015 - fbeta_score: 0.4015 - val_loss: 0.1755 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 98/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0221 - acc: 0.9913 - recall: 0.4210 - fbeta_score: 0.4209 - val_loss: 0.2036 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 99/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0258 - acc: 0.9886 - recall: 0.3462 - fbeta_score: 0.3489 - val_loss: 0.2303 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 100/1000\n",
      "1843/1843 [==============================] - 0s 176us/step - loss: 0.0249 - acc: 0.9940 - recall: 0.3816 - fbeta_score: 0.3849 - val_loss: 0.2050 - val_acc: 0.9463 - val_recall: 0.3659 - val_fbeta_score: 0.3740\n",
      "Epoch 101/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0308 - acc: 0.9870 - recall: 0.3880 - fbeta_score: 0.3871 - val_loss: 0.2032 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 102/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0271 - acc: 0.9886 - recall: 0.4142 - fbeta_score: 0.4205 - val_loss: 0.1674 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 103/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0250 - acc: 0.9908 - recall: 0.3925 - fbeta_score: 0.3952 - val_loss: 0.1910 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 104/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0292 - acc: 0.9908 - recall: 0.3789 - fbeta_score: 0.3860 - val_loss: 0.1710 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 105/1000\n",
      "1843/1843 [==============================] - 0s 176us/step - loss: 0.0274 - acc: 0.9897 - recall: 0.3861 - fbeta_score: 0.3889 - val_loss: 0.1926 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 106/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0237 - acc: 0.9935 - recall: 0.3871 - fbeta_score: 0.3885 - val_loss: 0.2059 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 107/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0205 - acc: 0.9924 - recall: 0.3887 - fbeta_score: 0.3937 - val_loss: 0.1948 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 108/1000\n",
      "1843/1843 [==============================] - 0s 172us/step - loss: 0.0267 - acc: 0.9902 - recall: 0.3590 - fbeta_score: 0.3643 - val_loss: 0.2031 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 109/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0283 - acc: 0.9875 - recall: 0.3473 - fbeta_score: 0.3476 - val_loss: 0.2174 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 110/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0222 - acc: 0.9940 - recall: 0.3789 - fbeta_score: 0.3825 - val_loss: 0.2104 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 111/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0164 - acc: 0.9940 - recall: 0.4106 - fbeta_score: 0.4147 - val_loss: 0.1943 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 112/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0333 - acc: 0.9859 - recall: 0.3549 - fbeta_score: 0.3612 - val_loss: 0.2138 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 113/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0168 - acc: 0.9940 - recall: 0.4151 - fbeta_score: 0.4178 - val_loss: 0.2117 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 114/1000\n",
      "1843/1843 [==============================] - 0s 176us/step - loss: 0.0338 - acc: 0.9881 - recall: 0.3785 - fbeta_score: 0.3823 - val_loss: 0.2360 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 115/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0224 - acc: 0.9935 - recall: 0.3834 - fbeta_score: 0.3860 - val_loss: 0.2162 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 116/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0266 - acc: 0.9908 - recall: 0.3852 - fbeta_score: 0.3923 - val_loss: 0.2505 - val_acc: 0.9317 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 117/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0246 - acc: 0.9913 - recall: 0.3880 - fbeta_score: 0.3889 - val_loss: 0.2457 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 118/1000\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.0226 - acc: 0.9913 - recall: 0.3807 - fbeta_score: 0.3823 - val_loss: 0.2284 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 119/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0230 - acc: 0.9929 - recall: 0.3889 - fbeta_score: 0.3878 - val_loss: 0.2258 - val_acc: 0.9317 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 120/1000\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.0152 - acc: 0.9957 - recall: 0.3943 - fbeta_score: 0.3986 - val_loss: 0.2117 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 121/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0220 - acc: 0.9924 - recall: 0.4106 - fbeta_score: 0.4131 - val_loss: 0.2560 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 122/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0178 - acc: 0.9946 - recall: 0.4033 - fbeta_score: 0.4066 - val_loss: 0.2450 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 123/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0199 - acc: 0.9935 - recall: 0.3893 - fbeta_score: 0.3917 - val_loss: 0.2064 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 124/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0172 - acc: 0.9951 - recall: 0.3834 - fbeta_score: 0.3878 - val_loss: 0.1860 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 125/1000\n",
      "1843/1843 [==============================] - 0s 176us/step - loss: 0.0234 - acc: 0.9908 - recall: 0.3581 - fbeta_score: 0.3637 - val_loss: 0.2167 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 126/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0184 - acc: 0.9924 - recall: 0.3816 - fbeta_score: 0.3831 - val_loss: 0.2081 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 127/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0139 - acc: 0.9967 - recall: 0.4078 - fbeta_score: 0.4095 - val_loss: 0.1859 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 128/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0129 - acc: 0.9951 - recall: 0.4124 - fbeta_score: 0.4140 - val_loss: 0.2515 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 129/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0206 - acc: 0.9929 - recall: 0.4024 - fbeta_score: 0.4069 - val_loss: 0.2335 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 130/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0233 - acc: 0.9913 - recall: 0.3880 - fbeta_score: 0.3928 - val_loss: 0.2184 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 131/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0175 - acc: 0.9951 - recall: 0.4015 - fbeta_score: 0.4051 - val_loss: 0.1979 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 132/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0252 - acc: 0.9924 - recall: 0.3694 - fbeta_score: 0.3733 - val_loss: 0.2088 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 133/1000\n",
      "1843/1843 [==============================] - 0s 181us/step - loss: 0.0152 - acc: 0.9951 - recall: 0.4241 - fbeta_score: 0.4258 - val_loss: 0.2233 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 134/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0241 - acc: 0.9913 - recall: 0.3934 - fbeta_score: 0.3995 - val_loss: 0.2173 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 135/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0179 - acc: 0.9946 - recall: 0.3889 - fbeta_score: 0.3932 - val_loss: 0.2020 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 136/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0150 - acc: 0.9967 - recall: 0.4078 - fbeta_score: 0.4113 - val_loss: 0.2042 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 137/1000\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.0197 - acc: 0.9913 - recall: 0.3771 - fbeta_score: 0.3802 - val_loss: 0.2351 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 138/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0185 - acc: 0.9951 - recall: 0.3780 - fbeta_score: 0.3787 - val_loss: 0.1701 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 139/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0165 - acc: 0.9967 - recall: 0.3952 - fbeta_score: 0.3957 - val_loss: 0.2169 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 140/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0109 - acc: 0.9973 - recall: 0.4232 - fbeta_score: 0.4232 - val_loss: 0.2345 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 141/1000\n",
      "1843/1843 [==============================] - 0s 168us/step - loss: 0.0143 - acc: 0.9967 - recall: 0.4115 - fbeta_score: 0.4156 - val_loss: 0.2067 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 142/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0171 - acc: 0.9940 - recall: 0.4073 - fbeta_score: 0.4087 - val_loss: 0.2040 - val_acc: 0.9268 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 143/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0375 - acc: 0.9870 - recall: 0.3816 - fbeta_score: 0.3885 - val_loss: 0.2122 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 144/1000\n",
      "1843/1843 [==============================] - 0s 196us/step - loss: 0.0226 - acc: 0.9919 - recall: 0.3961 - fbeta_score: 0.3997 - val_loss: 0.2155 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0180 - acc: 0.9951 - recall: 0.4088 - fbeta_score: 0.4120 - val_loss: 0.2071 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 146/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0232 - acc: 0.9919 - recall: 0.3916 - fbeta_score: 0.3950 - val_loss: 0.2051 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 147/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0230 - acc: 0.9891 - recall: 0.3708 - fbeta_score: 0.3733 - val_loss: 0.2119 - val_acc: 0.9317 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 148/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0191 - acc: 0.9919 - recall: 0.4113 - fbeta_score: 0.4122 - val_loss: 0.1930 - val_acc: 0.9317 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 149/1000\n",
      "1843/1843 [==============================] - 0s 181us/step - loss: 0.0285 - acc: 0.9886 - recall: 0.3726 - fbeta_score: 0.3729 - val_loss: 0.2009 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 150/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0212 - acc: 0.9902 - recall: 0.3554 - fbeta_score: 0.3581 - val_loss: 0.2634 - val_acc: 0.9268 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 151/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0240 - acc: 0.9908 - recall: 0.3925 - fbeta_score: 0.3952 - val_loss: 0.2310 - val_acc: 0.9317 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 152/1000\n",
      "1843/1843 [==============================] - 0s 176us/step - loss: 0.0232 - acc: 0.9919 - recall: 0.3898 - fbeta_score: 0.3934 - val_loss: 0.2368 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 153/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0198 - acc: 0.9919 - recall: 0.4088 - fbeta_score: 0.4120 - val_loss: 0.1937 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 154/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0286 - acc: 0.9881 - recall: 0.3721 - fbeta_score: 0.3781 - val_loss: 0.2147 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 155/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0200 - acc: 0.9940 - recall: 0.4078 - fbeta_score: 0.4113 - val_loss: 0.2739 - val_acc: 0.9317 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 156/1000\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.0126 - acc: 0.9946 - recall: 0.4187 - fbeta_score: 0.4221 - val_loss: 0.2190 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 157/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0192 - acc: 0.9935 - recall: 0.4069 - fbeta_score: 0.4127 - val_loss: 0.2403 - val_acc: 0.9317 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 158/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0183 - acc: 0.9940 - recall: 0.4140 - fbeta_score: 0.4140 - val_loss: 0.2375 - val_acc: 0.9366 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 159/1000\n",
      "1843/1843 [==============================] - 0s 173us/step - loss: 0.0174 - acc: 0.9935 - recall: 0.4178 - fbeta_score: 0.4167 - val_loss: 0.2930 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 160/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0159 - acc: 0.9962 - recall: 0.4015 - fbeta_score: 0.4051 - val_loss: 0.2502 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 161/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0210 - acc: 0.9946 - recall: 0.3599 - fbeta_score: 0.3650 - val_loss: 0.2732 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 162/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0135 - acc: 0.9940 - recall: 0.3997 - fbeta_score: 0.4044 - val_loss: 0.2444 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 163/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0202 - acc: 0.9929 - recall: 0.3997 - fbeta_score: 0.4041 - val_loss: 0.2476 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 164/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0196 - acc: 0.9913 - recall: 0.4024 - fbeta_score: 0.4051 - val_loss: 0.2520 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 165/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0188 - acc: 0.9940 - recall: 0.4241 - fbeta_score: 0.4239 - val_loss: 0.2606 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 166/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0171 - acc: 0.9946 - recall: 0.3730 - fbeta_score: 0.3763 - val_loss: 0.2143 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 167/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0152 - acc: 0.9946 - recall: 0.4124 - fbeta_score: 0.4145 - val_loss: 0.2366 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 168/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0153 - acc: 0.9940 - recall: 0.3934 - fbeta_score: 0.3943 - val_loss: 0.2547 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 169/1000\n",
      "1843/1843 [==============================] - 0s 176us/step - loss: 0.0198 - acc: 0.9935 - recall: 0.3798 - fbeta_score: 0.3798 - val_loss: 0.2164 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 170/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0146 - acc: 0.9951 - recall: 0.4504 - fbeta_score: 0.4522 - val_loss: 0.2451 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 171/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0203 - acc: 0.9935 - recall: 0.3843 - fbeta_score: 0.3885 - val_loss: 0.2373 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 172/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0213 - acc: 0.9957 - recall: 0.4069 - fbeta_score: 0.4088 - val_loss: 0.2836 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 173/1000\n",
      "1843/1843 [==============================] - 0s 169us/step - loss: 0.0367 - acc: 0.9897 - recall: 0.3943 - fbeta_score: 0.3986 - val_loss: 0.2612 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 174/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0161 - acc: 0.9946 - recall: 0.3771 - fbeta_score: 0.3798 - val_loss: 0.1982 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 175/1000\n",
      "1843/1843 [==============================] - 0s 181us/step - loss: 0.0287 - acc: 0.9902 - recall: 0.3798 - fbeta_score: 0.3825 - val_loss: 0.1974 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 176/1000\n",
      "1843/1843 [==============================] - 0s 172us/step - loss: 0.0154 - acc: 0.9951 - recall: 0.3997 - fbeta_score: 0.4022 - val_loss: 0.2228 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 177/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0280 - acc: 0.9924 - recall: 0.4069 - fbeta_score: 0.4069 - val_loss: 0.2325 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 178/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0310 - acc: 0.9908 - recall: 0.3735 - fbeta_score: 0.3789 - val_loss: 0.1972 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2195\n",
      "Epoch 179/1000\n",
      "1843/1843 [==============================] - 0s 176us/step - loss: 0.0235 - acc: 0.9919 - recall: 0.4024 - fbeta_score: 0.4041 - val_loss: 0.2197 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 180/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0177 - acc: 0.9940 - recall: 0.3970 - fbeta_score: 0.3986 - val_loss: 0.1897 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0209 - acc: 0.9935 - recall: 0.4051 - fbeta_score: 0.4095 - val_loss: 0.2009 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 182/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0175 - acc: 0.9946 - recall: 0.4160 - fbeta_score: 0.4203 - val_loss: 0.2261 - val_acc: 0.9366 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 183/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0284 - acc: 0.9902 - recall: 0.4074 - fbeta_score: 0.4089 - val_loss: 0.2029 - val_acc: 0.9366 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 184/1000\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.0194 - acc: 0.9951 - recall: 0.4097 - fbeta_score: 0.4106 - val_loss: 0.2169 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 185/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0143 - acc: 0.9946 - recall: 0.4097 - fbeta_score: 0.4124 - val_loss: 0.2564 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 186/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0225 - acc: 0.9919 - recall: 0.3816 - fbeta_score: 0.3849 - val_loss: 0.2628 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 187/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0195 - acc: 0.9946 - recall: 0.3934 - fbeta_score: 0.3934 - val_loss: 0.2717 - val_acc: 0.9220 - val_recall: 0.2439 - val_fbeta_score: 0.2358\n",
      "Epoch 188/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0183 - acc: 0.9929 - recall: 0.4086 - fbeta_score: 0.4111 - val_loss: 0.2571 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 189/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0253 - acc: 0.9940 - recall: 0.4024 - fbeta_score: 0.4041 - val_loss: 0.2423 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 190/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0157 - acc: 0.9935 - recall: 0.3586 - fbeta_score: 0.3637 - val_loss: 0.2321 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 191/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0189 - acc: 0.9924 - recall: 0.3780 - fbeta_score: 0.3842 - val_loss: 0.2556 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 192/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0166 - acc: 0.9957 - recall: 0.3889 - fbeta_score: 0.3896 - val_loss: 0.2300 - val_acc: 0.9366 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 193/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0160 - acc: 0.9946 - recall: 0.3825 - fbeta_score: 0.3852 - val_loss: 0.2923 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 194/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0209 - acc: 0.9935 - recall: 0.3880 - fbeta_score: 0.3907 - val_loss: 0.2497 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 195/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0200 - acc: 0.9935 - recall: 0.3952 - fbeta_score: 0.3975 - val_loss: 0.2339 - val_acc: 0.9366 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 196/1000\n",
      "1843/1843 [==============================] - 0s 172us/step - loss: 0.0160 - acc: 0.9951 - recall: 0.3889 - fbeta_score: 0.3914 - val_loss: 0.2830 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 197/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0225 - acc: 0.9913 - recall: 0.3608 - fbeta_score: 0.3634 - val_loss: 0.2388 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 198/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0188 - acc: 0.9935 - recall: 0.4133 - fbeta_score: 0.4149 - val_loss: 0.2409 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 199/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0253 - acc: 0.9908 - recall: 0.3970 - fbeta_score: 0.4004 - val_loss: 0.2875 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 200/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0149 - acc: 0.9951 - recall: 0.3970 - fbeta_score: 0.4004 - val_loss: 0.2555 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 201/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0126 - acc: 0.9962 - recall: 0.4178 - fbeta_score: 0.4196 - val_loss: 0.2263 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 202/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0131 - acc: 0.9962 - recall: 0.4196 - fbeta_score: 0.4187 - val_loss: 0.2603 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 203/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0225 - acc: 0.9919 - recall: 0.3825 - fbeta_score: 0.3871 - val_loss: 0.2735 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 204/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0147 - acc: 0.9946 - recall: 0.4133 - fbeta_score: 0.4149 - val_loss: 0.2711 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 205/1000\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.0097 - acc: 0.9962 - recall: 0.4122 - fbeta_score: 0.4129 - val_loss: 0.2780 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 206/1000\n",
      "1843/1843 [==============================] - 0s 181us/step - loss: 0.0146 - acc: 0.9962 - recall: 0.4241 - fbeta_score: 0.4258 - val_loss: 0.2560 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 207/1000\n",
      "1843/1843 [==============================] - 0s 169us/step - loss: 0.0136 - acc: 0.9962 - recall: 0.4124 - fbeta_score: 0.4142 - val_loss: 0.2546 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 208/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0181 - acc: 0.9919 - recall: 0.3934 - fbeta_score: 0.3965 - val_loss: 0.2895 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 209/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0143 - acc: 0.9978 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2483 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 210/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0116 - acc: 0.9973 - recall: 0.4124 - fbeta_score: 0.4142 - val_loss: 0.2577 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 211/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0114 - acc: 0.9946 - recall: 0.4042 - fbeta_score: 0.4069 - val_loss: 0.2862 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 212/1000\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.0110 - acc: 0.9946 - recall: 0.4042 - fbeta_score: 0.4069 - val_loss: 0.2252 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 213/1000\n",
      "1843/1843 [==============================] - 0s 176us/step - loss: 0.0149 - acc: 0.9929 - recall: 0.3762 - fbeta_score: 0.3789 - val_loss: 0.2437 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 214/1000\n",
      "1843/1843 [==============================] - 0s 172us/step - loss: 0.0209 - acc: 0.9913 - recall: 0.4015 - fbeta_score: 0.4060 - val_loss: 0.2604 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 215/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0126 - acc: 0.9957 - recall: 0.4341 - fbeta_score: 0.4359 - val_loss: 0.2068 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 216/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0166 - acc: 0.9940 - recall: 0.4110 - fbeta_score: 0.4127 - val_loss: 0.2508 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0154 - acc: 0.9929 - recall: 0.3997 - fbeta_score: 0.4022 - val_loss: 0.2292 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 218/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0151 - acc: 0.9946 - recall: 0.3836 - fbeta_score: 0.3852 - val_loss: 0.2420 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 219/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0137 - acc: 0.9957 - recall: 0.3943 - fbeta_score: 0.3986 - val_loss: 0.2279 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 220/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0106 - acc: 0.9957 - recall: 0.3744 - fbeta_score: 0.3744 - val_loss: 0.2380 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 221/1000\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.0147 - acc: 0.9957 - recall: 0.4160 - fbeta_score: 0.4185 - val_loss: 0.1931 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 222/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0144 - acc: 0.9957 - recall: 0.3961 - fbeta_score: 0.3997 - val_loss: 0.2396 - val_acc: 0.9415 - val_recall: 0.2195 - val_fbeta_score: 0.2179\n",
      "Epoch 223/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0153 - acc: 0.9946 - recall: 0.4051 - fbeta_score: 0.4077 - val_loss: 0.2475 - val_acc: 0.9317 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 224/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0292 - acc: 0.9891 - recall: 0.3699 - fbeta_score: 0.3715 - val_loss: 0.1892 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 225/1000\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.0171 - acc: 0.9946 - recall: 0.4250 - fbeta_score: 0.4283 - val_loss: 0.2942 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 226/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0123 - acc: 0.9967 - recall: 0.4341 - fbeta_score: 0.4359 - val_loss: 0.2140 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 227/1000\n",
      "1843/1843 [==============================] - 0s 181us/step - loss: 0.0203 - acc: 0.9935 - recall: 0.3762 - fbeta_score: 0.3776 - val_loss: 0.2809 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 228/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0095 - acc: 0.9973 - recall: 0.4458 - fbeta_score: 0.4493 - val_loss: 0.2619 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 229/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0234 - acc: 0.9908 - recall: 0.3916 - fbeta_score: 0.3950 - val_loss: 0.2247 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 230/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0121 - acc: 0.9962 - recall: 0.4077 - fbeta_score: 0.4100 - val_loss: 0.2180 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 231/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0160 - acc: 0.9935 - recall: 0.3988 - fbeta_score: 0.3997 - val_loss: 0.2454 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 232/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0162 - acc: 0.9951 - recall: 0.4015 - fbeta_score: 0.4050 - val_loss: 0.2388 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 233/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0108 - acc: 0.9957 - recall: 0.4259 - fbeta_score: 0.4268 - val_loss: 0.2660 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 234/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0149 - acc: 0.9967 - recall: 0.4124 - fbeta_score: 0.4142 - val_loss: 0.1936 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 235/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0119 - acc: 0.9951 - recall: 0.3950 - fbeta_score: 0.3941 - val_loss: 0.2527 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 236/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0234 - acc: 0.9946 - recall: 0.3752 - fbeta_score: 0.3779 - val_loss: 0.2274 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 237/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0163 - acc: 0.9957 - recall: 0.4154 - fbeta_score: 0.4186 - val_loss: 0.2530 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 238/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0067 - acc: 0.9978 - recall: 0.4377 - fbeta_score: 0.4402 - val_loss: 0.2384 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 239/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0123 - acc: 0.9957 - recall: 0.4296 - fbeta_score: 0.4301 - val_loss: 0.3041 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 240/1000\n",
      "1843/1843 [==============================] - 0s 177us/step - loss: 0.0098 - acc: 0.9973 - recall: 0.3943 - fbeta_score: 0.3968 - val_loss: 0.2694 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 241/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0092 - acc: 0.9967 - recall: 0.4059 - fbeta_score: 0.4089 - val_loss: 0.2424 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 242/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0099 - acc: 0.9967 - recall: 0.4042 - fbeta_score: 0.4051 - val_loss: 0.2793 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 243/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0082 - acc: 0.9967 - recall: 0.4124 - fbeta_score: 0.4142 - val_loss: 0.2403 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 244/1000\n",
      "1843/1843 [==============================] - 0s 172us/step - loss: 0.0212 - acc: 0.9940 - recall: 0.3644 - fbeta_score: 0.3700 - val_loss: 0.2442 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 245/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0146 - acc: 0.9940 - recall: 0.3812 - fbeta_score: 0.3863 - val_loss: 0.2332 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 246/1000\n",
      "1843/1843 [==============================] - 0s 182us/step - loss: 0.0145 - acc: 0.9962 - recall: 0.3961 - fbeta_score: 0.3977 - val_loss: 0.2292 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 247/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0089 - acc: 0.9978 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2531 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 248/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0079 - acc: 0.9984 - recall: 0.4015 - fbeta_score: 0.4015 - val_loss: 0.2417 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 249/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0082 - acc: 0.9973 - recall: 0.4187 - fbeta_score: 0.4185 - val_loss: 0.2721 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 250/1000\n",
      "1843/1843 [==============================] - 0s 168us/step - loss: 0.0120 - acc: 0.9962 - recall: 0.4069 - fbeta_score: 0.4088 - val_loss: 0.2721 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 251/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0092 - acc: 0.9967 - recall: 0.4341 - fbeta_score: 0.4359 - val_loss: 0.3996 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 252/1000\n",
      "1843/1843 [==============================] - 0s 174us/step - loss: 0.0196 - acc: 0.9951 - recall: 0.4051 - fbeta_score: 0.4077 - val_loss: 0.2526 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 253/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 173us/step - loss: 0.0107 - acc: 0.9962 - recall: 0.4042 - fbeta_score: 0.4051 - val_loss: 0.2670 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 254/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0115 - acc: 0.9967 - recall: 0.4303 - fbeta_score: 0.4321 - val_loss: 0.2887 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 255/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0121 - acc: 0.9962 - recall: 0.3880 - fbeta_score: 0.3889 - val_loss: 0.2613 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 256/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0141 - acc: 0.9962 - recall: 0.3852 - fbeta_score: 0.3889 - val_loss: 0.3034 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 257/1000\n",
      "1843/1843 [==============================] - 0s 172us/step - loss: 0.0153 - acc: 0.9957 - recall: 0.4024 - fbeta_score: 0.4041 - val_loss: 0.2873 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 258/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0113 - acc: 0.9946 - recall: 0.3787 - fbeta_score: 0.3836 - val_loss: 0.2563 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 259/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0094 - acc: 0.9967 - recall: 0.4323 - fbeta_score: 0.4330 - val_loss: 0.3003 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 260/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0082 - acc: 0.9978 - recall: 0.4124 - fbeta_score: 0.4142 - val_loss: 0.2786 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 261/1000\n",
      "1843/1843 [==============================] - 0s 170us/step - loss: 0.0114 - acc: 0.9957 - recall: 0.3997 - fbeta_score: 0.4041 - val_loss: 0.2818 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 262/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0101 - acc: 0.9973 - recall: 0.4476 - fbeta_score: 0.4485 - val_loss: 0.2661 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 263/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0118 - acc: 0.9962 - recall: 0.4101 - fbeta_score: 0.4094 - val_loss: 0.2873 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 264/1000\n",
      "1843/1843 [==============================] - 0s 171us/step - loss: 0.0180 - acc: 0.9935 - recall: 0.3871 - fbeta_score: 0.3885 - val_loss: 0.2782 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 265/1000\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.0119 - acc: 0.9962 - recall: 0.3742 - fbeta_score: 0.3766 - val_loss: 0.2834 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 266/1000\n",
      "1843/1843 [==============================] - 0s 178us/step - loss: 0.0114 - acc: 0.9973 - recall: 0.4187 - fbeta_score: 0.4203 - val_loss: 0.3181 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 267/1000\n",
      "1843/1843 [==============================] - 0s 175us/step - loss: 0.0180 - acc: 0.9935 - recall: 0.3979 - fbeta_score: 0.4006 - val_loss: 0.3036 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 268/1000\n",
      "1843/1843 [==============================] - 0s 177us/step - loss: 0.0138 - acc: 0.9935 - recall: 0.4024 - fbeta_score: 0.4059 - val_loss: 0.3236 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 269/1000\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.0150 - acc: 0.9946 - recall: 0.4042 - fbeta_score: 0.4055 - val_loss: 0.3154 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 270/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0182 - acc: 0.9929 - recall: 0.3663 - fbeta_score: 0.3679 - val_loss: 0.3190 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 271/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0213 - acc: 0.9946 - recall: 0.3916 - fbeta_score: 0.3932 - val_loss: 0.3125 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 272/1000\n",
      "1843/1843 [==============================] - 0s 173us/step - loss: 0.0159 - acc: 0.9946 - recall: 0.3875 - fbeta_score: 0.3899 - val_loss: 0.2956 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 273/1000\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.0143 - acc: 0.9957 - recall: 0.3880 - fbeta_score: 0.3910 - val_loss: 0.2482 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 274/1000\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.0138 - acc: 0.9967 - recall: 0.3934 - fbeta_score: 0.3943 - val_loss: 0.3160 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 275/1000\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.0224 - acc: 0.9924 - recall: 0.3852 - fbeta_score: 0.3887 - val_loss: 0.3395 - val_acc: 0.9366 - val_recall: 0.2195 - val_fbeta_score: 0.2179\n",
      "Epoch 276/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0178 - acc: 0.9946 - recall: 0.4024 - fbeta_score: 0.4041 - val_loss: 0.3037 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 277/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0091 - acc: 0.9978 - recall: 0.4296 - fbeta_score: 0.4312 - val_loss: 0.3041 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 278/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0145 - acc: 0.9940 - recall: 0.3780 - fbeta_score: 0.3796 - val_loss: 0.2699 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 279/1000\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.0140 - acc: 0.9957 - recall: 0.4173 - fbeta_score: 0.4177 - val_loss: 0.2896 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 280/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0153 - acc: 0.9935 - recall: 0.3802 - fbeta_score: 0.3836 - val_loss: 0.2428 - val_acc: 0.9463 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 281/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0133 - acc: 0.9962 - recall: 0.4205 - fbeta_score: 0.4178 - val_loss: 0.3024 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 282/1000\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.0160 - acc: 0.9957 - recall: 0.3907 - fbeta_score: 0.3941 - val_loss: 0.2731 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 283/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0090 - acc: 0.9978 - recall: 0.4187 - fbeta_score: 0.4203 - val_loss: 0.3034 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 284/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0138 - acc: 0.9951 - recall: 0.3961 - fbeta_score: 0.3979 - val_loss: 0.2955 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 285/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0050 - acc: 0.9989 - recall: 0.4314 - fbeta_score: 0.4323 - val_loss: 0.2740 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 286/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0126 - acc: 0.9962 - recall: 0.3907 - fbeta_score: 0.3907 - val_loss: 0.2675 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 287/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0121 - acc: 0.9951 - recall: 0.4065 - fbeta_score: 0.4087 - val_loss: 0.2612 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 288/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0137 - acc: 0.9946 - recall: 0.4106 - fbeta_score: 0.4113 - val_loss: 0.2759 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 289/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0092 - acc: 0.9978 - recall: 0.4088 - fbeta_score: 0.4102 - val_loss: 0.2297 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 290/1000\n",
      "1843/1843 [==============================] - 0s 201us/step - loss: 0.0083 - acc: 0.9978 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2744 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 291/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0116 - acc: 0.9973 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2867 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 292/1000\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.0082 - acc: 0.9957 - recall: 0.4241 - fbeta_score: 0.4239 - val_loss: 0.3114 - val_acc: 0.9268 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 293/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0069 - acc: 0.9973 - recall: 0.4286 - fbeta_score: 0.4305 - val_loss: 0.2944 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 294/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0063 - acc: 0.9989 - recall: 0.4151 - fbeta_score: 0.4160 - val_loss: 0.2588 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 295/1000\n",
      "1843/1843 [==============================] - 0s 202us/step - loss: 0.0102 - acc: 0.9973 - recall: 0.4106 - fbeta_score: 0.4113 - val_loss: 0.2727 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 296/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0139 - acc: 0.9962 - recall: 0.4187 - fbeta_score: 0.4221 - val_loss: 0.2647 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 297/1000\n",
      "1843/1843 [==============================] - 0s 202us/step - loss: 0.0042 - acc: 0.9984 - recall: 0.4314 - fbeta_score: 0.4323 - val_loss: 0.2832 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 298/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0104 - acc: 0.9951 - recall: 0.3861 - fbeta_score: 0.3914 - val_loss: 0.2519 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 299/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0088 - acc: 0.9978 - recall: 0.4341 - fbeta_score: 0.4323 - val_loss: 0.2691 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1057\n",
      "Epoch 300/1000\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.0099 - acc: 0.9967 - recall: 0.4160 - fbeta_score: 0.4167 - val_loss: 0.2352 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 301/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0115 - acc: 0.9967 - recall: 0.4124 - fbeta_score: 0.4140 - val_loss: 0.2766 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 302/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0072 - acc: 0.9978 - recall: 0.4187 - fbeta_score: 0.4221 - val_loss: 0.2205 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 303/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0136 - acc: 0.9957 - recall: 0.4060 - fbeta_score: 0.4084 - val_loss: 0.2343 - val_acc: 0.9561 - val_recall: 0.4146 - val_fbeta_score: 0.4065\n",
      "Epoch 304/1000\n",
      "1843/1843 [==============================] - 0s 202us/step - loss: 0.0093 - acc: 0.9967 - recall: 0.4395 - fbeta_score: 0.4377 - val_loss: 0.2457 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 305/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0166 - acc: 0.9940 - recall: 0.3509 - fbeta_score: 0.3552 - val_loss: 0.2747 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 306/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0123 - acc: 0.9978 - recall: 0.4124 - fbeta_score: 0.4142 - val_loss: 0.2359 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 307/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0127 - acc: 0.9957 - recall: 0.4133 - fbeta_score: 0.4167 - val_loss: 0.2724 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 308/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0121 - acc: 0.9957 - recall: 0.4160 - fbeta_score: 0.4203 - val_loss: 0.2963 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 309/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0070 - acc: 0.9978 - recall: 0.3834 - fbeta_score: 0.3860 - val_loss: 0.2909 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 310/1000\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.0098 - acc: 0.9973 - recall: 0.4214 - fbeta_score: 0.4239 - val_loss: 0.2865 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 311/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0190 - acc: 0.9957 - recall: 0.3680 - fbeta_score: 0.3708 - val_loss: 0.2605 - val_acc: 0.9317 - val_recall: 0.2195 - val_fbeta_score: 0.1951\n",
      "Epoch 312/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0199 - acc: 0.9913 - recall: 0.4024 - fbeta_score: 0.4041 - val_loss: 0.2458 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 313/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0162 - acc: 0.9940 - recall: 0.3744 - fbeta_score: 0.3760 - val_loss: 0.2460 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1545\n",
      "Epoch 314/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0217 - acc: 0.9940 - recall: 0.3676 - fbeta_score: 0.3728 - val_loss: 0.2941 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 315/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0199 - acc: 0.9973 - recall: 0.4227 - fbeta_score: 0.4235 - val_loss: 0.2788 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 316/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0126 - acc: 0.9962 - recall: 0.4069 - fbeta_score: 0.4106 - val_loss: 0.2278 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 317/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0089 - acc: 0.9978 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2810 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 318/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0076 - acc: 0.9973 - recall: 0.4214 - fbeta_score: 0.4221 - val_loss: 0.2495 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 319/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0114 - acc: 0.9962 - recall: 0.4341 - fbeta_score: 0.4359 - val_loss: 0.2771 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 320/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0090 - acc: 0.9962 - recall: 0.3961 - fbeta_score: 0.3997 - val_loss: 0.2770 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 321/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0118 - acc: 0.9962 - recall: 0.4095 - fbeta_score: 0.4093 - val_loss: 0.2735 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 322/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0111 - acc: 0.9951 - recall: 0.3997 - fbeta_score: 0.4041 - val_loss: 0.2651 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 323/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0124 - acc: 0.9957 - recall: 0.4151 - fbeta_score: 0.4158 - val_loss: 0.2524 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 324/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0099 - acc: 0.9951 - recall: 0.4167 - fbeta_score: 0.4194 - val_loss: 0.2438 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 325/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0120 - acc: 0.9973 - recall: 0.4214 - fbeta_score: 0.4221 - val_loss: 0.2303 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2033\n",
      "Epoch 326/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0131 - acc: 0.9973 - recall: 0.3843 - fbeta_score: 0.3867 - val_loss: 0.2602 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 327/1000\n",
      "1843/1843 [==============================] - 0s 200us/step - loss: 0.0090 - acc: 0.9962 - recall: 0.4160 - fbeta_score: 0.4149 - val_loss: 0.2980 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 328/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0100 - acc: 0.9957 - recall: 0.4250 - fbeta_score: 0.4283 - val_loss: 0.2735 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 329/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0072 - acc: 0.9978 - recall: 0.4151 - fbeta_score: 0.4160 - val_loss: 0.2646 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 330/1000\n",
      "1843/1843 [==============================] - 0s 200us/step - loss: 0.0107 - acc: 0.9973 - recall: 0.3934 - fbeta_score: 0.3961 - val_loss: 0.2694 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 331/1000\n",
      "1843/1843 [==============================] - 0s 200us/step - loss: 0.0100 - acc: 0.9973 - recall: 0.4078 - fbeta_score: 0.4095 - val_loss: 0.2646 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 332/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0090 - acc: 0.9967 - recall: 0.4160 - fbeta_score: 0.4185 - val_loss: 0.2829 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 333/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0074 - acc: 0.9978 - recall: 0.4065 - fbeta_score: 0.4087 - val_loss: 0.2762 - val_acc: 0.9366 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 334/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0087 - acc: 0.9984 - recall: 0.4151 - fbeta_score: 0.4160 - val_loss: 0.2577 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 335/1000\n",
      "1843/1843 [==============================] - 0s 265us/step - loss: 0.0132 - acc: 0.9962 - recall: 0.4395 - fbeta_score: 0.4413 - val_loss: 0.3403 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 336/1000\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.0192 - acc: 0.9929 - recall: 0.3848 - fbeta_score: 0.3881 - val_loss: 0.2603 - val_acc: 0.9463 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 337/1000\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.0124 - acc: 0.9967 - recall: 0.4133 - fbeta_score: 0.4149 - val_loss: 0.2435 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 338/1000\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.0163 - acc: 0.9924 - recall: 0.4140 - fbeta_score: 0.4176 - val_loss: 0.2668 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 339/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0078 - acc: 0.9978 - recall: 0.4133 - fbeta_score: 0.4149 - val_loss: 0.2421 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 340/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0101 - acc: 0.9973 - recall: 0.4110 - fbeta_score: 0.4116 - val_loss: 0.2721 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 341/1000\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.0098 - acc: 0.9962 - recall: 0.3970 - fbeta_score: 0.4004 - val_loss: 0.2839 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 342/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0122 - acc: 0.9973 - recall: 0.4151 - fbeta_score: 0.4160 - val_loss: 0.2918 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 343/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0099 - acc: 0.9951 - recall: 0.4004 - fbeta_score: 0.4031 - val_loss: 0.2919 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 344/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0074 - acc: 0.9973 - recall: 0.4154 - fbeta_score: 0.4168 - val_loss: 0.3080 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 345/1000\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.0040 - acc: 0.9995 - recall: 0.4485 - fbeta_score: 0.4493 - val_loss: 0.2921 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 346/1000\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.0070 - acc: 0.9973 - recall: 0.4232 - fbeta_score: 0.4232 - val_loss: 0.3162 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 347/1000\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.0105 - acc: 0.9962 - recall: 0.4239 - fbeta_score: 0.4245 - val_loss: 0.2509 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 348/1000\n",
      "1843/1843 [==============================] - 1s 283us/step - loss: 0.0089 - acc: 0.9973 - recall: 0.3771 - fbeta_score: 0.3798 - val_loss: 0.2719 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 349/1000\n",
      "1843/1843 [==============================] - 0s 267us/step - loss: 0.0144 - acc: 0.9962 - recall: 0.3907 - fbeta_score: 0.3943 - val_loss: 0.2736 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 350/1000\n",
      "1843/1843 [==============================] - 1s 286us/step - loss: 0.0253 - acc: 0.9951 - recall: 0.3915 - fbeta_score: 0.3918 - val_loss: 0.2421 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 351/1000\n",
      "1843/1843 [==============================] - 1s 300us/step - loss: 0.0120 - acc: 0.9957 - recall: 0.4106 - fbeta_score: 0.4095 - val_loss: 0.2458 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 352/1000\n",
      "1843/1843 [==============================] - 0s 270us/step - loss: 0.0087 - acc: 0.9973 - recall: 0.4187 - fbeta_score: 0.4203 - val_loss: 0.2318 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 353/1000\n",
      "1843/1843 [==============================] - 0s 261us/step - loss: 0.0121 - acc: 0.9957 - recall: 0.4314 - fbeta_score: 0.4341 - val_loss: 0.2698 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 354/1000\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.0164 - acc: 0.9946 - recall: 0.4024 - fbeta_score: 0.4022 - val_loss: 0.2837 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 355/1000\n",
      "1843/1843 [==============================] - 1s 298us/step - loss: 0.0132 - acc: 0.9940 - recall: 0.3916 - fbeta_score: 0.3950 - val_loss: 0.3051 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 356/1000\n",
      "1843/1843 [==============================] - 0s 258us/step - loss: 0.0085 - acc: 0.9989 - recall: 0.4069 - fbeta_score: 0.4069 - val_loss: 0.3039 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 357/1000\n",
      "1843/1843 [==============================] - 0s 264us/step - loss: 0.0058 - acc: 0.9984 - recall: 0.4314 - fbeta_score: 0.4305 - val_loss: 0.2672 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 358/1000\n",
      "1843/1843 [==============================] - 1s 276us/step - loss: 0.0079 - acc: 0.9962 - recall: 0.4042 - fbeta_score: 0.4069 - val_loss: 0.2992 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 359/1000\n",
      "1843/1843 [==============================] - 0s 265us/step - loss: 0.0132 - acc: 0.9951 - recall: 0.4097 - fbeta_score: 0.4088 - val_loss: 0.2992 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 360/1000\n",
      "1843/1843 [==============================] - 0s 258us/step - loss: 0.0091 - acc: 0.9967 - recall: 0.3997 - fbeta_score: 0.4022 - val_loss: 0.2575 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.0112 - acc: 0.9962 - recall: 0.4232 - fbeta_score: 0.4267 - val_loss: 0.2475 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 362/1000\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.0084 - acc: 0.9989 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2807 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 363/1000\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.0144 - acc: 0.9962 - recall: 0.4078 - fbeta_score: 0.4095 - val_loss: 0.2279 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 364/1000\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.0166 - acc: 0.9946 - recall: 0.3861 - fbeta_score: 0.3878 - val_loss: 0.2276 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 365/1000\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.0105 - acc: 0.9951 - recall: 0.3970 - fbeta_score: 0.4004 - val_loss: 0.2733 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 366/1000\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.0107 - acc: 0.9973 - recall: 0.4151 - fbeta_score: 0.4182 - val_loss: 0.2787 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 367/1000\n",
      "1843/1843 [==============================] - 0s 255us/step - loss: 0.0084 - acc: 0.9962 - recall: 0.3889 - fbeta_score: 0.3914 - val_loss: 0.2464 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 368/1000\n",
      "1843/1843 [==============================] - 1s 298us/step - loss: 0.0100 - acc: 0.9962 - recall: 0.4431 - fbeta_score: 0.4457 - val_loss: 0.2514 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 369/1000\n",
      "1843/1843 [==============================] - 1s 420us/step - loss: 0.0070 - acc: 0.9984 - recall: 0.4259 - fbeta_score: 0.4268 - val_loss: 0.2595 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 370/1000\n",
      "1843/1843 [==============================] - 0s 265us/step - loss: 0.0100 - acc: 0.9973 - recall: 0.4214 - fbeta_score: 0.4221 - val_loss: 0.2674 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 371/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0130 - acc: 0.9957 - recall: 0.3934 - fbeta_score: 0.3959 - val_loss: 0.3123 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 372/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0055 - acc: 0.9989 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2702 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 373/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0073 - acc: 0.9973 - recall: 0.3961 - fbeta_score: 0.3961 - val_loss: 0.2689 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 374/1000\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.0059 - acc: 0.9978 - recall: 0.4151 - fbeta_score: 0.4142 - val_loss: 0.2676 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 375/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0074 - acc: 0.9978 - recall: 0.3825 - fbeta_score: 0.3834 - val_loss: 0.2673 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 376/1000\n",
      "1843/1843 [==============================] - 1s 339us/step - loss: 0.0104 - acc: 0.9962 - recall: 0.4160 - fbeta_score: 0.4149 - val_loss: 0.2826 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 377/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0047 - acc: 0.9995 - recall: 0.4286 - fbeta_score: 0.4286 - val_loss: 0.2990 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 378/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0152 - acc: 0.9962 - recall: 0.4097 - fbeta_score: 0.4106 - val_loss: 0.3073 - val_acc: 0.9415 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 379/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0158 - acc: 0.9946 - recall: 0.4323 - fbeta_score: 0.4276 - val_loss: 0.2754 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 380/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0072 - acc: 0.9989 - recall: 0.4377 - fbeta_score: 0.4384 - val_loss: 0.2729 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 381/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0074 - acc: 0.9978 - recall: 0.4323 - fbeta_score: 0.4330 - val_loss: 0.2459 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 382/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0074 - acc: 0.9978 - recall: 0.4458 - fbeta_score: 0.4475 - val_loss: 0.2526 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 383/1000\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.0118 - acc: 0.9967 - recall: 0.4060 - fbeta_score: 0.4084 - val_loss: 0.2974 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 384/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0071 - acc: 0.9973 - recall: 0.4241 - fbeta_score: 0.4258 - val_loss: 0.3086 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 385/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0091 - acc: 0.9973 - recall: 0.4377 - fbeta_score: 0.4384 - val_loss: 0.2613 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 386/1000\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.0089 - acc: 0.9967 - recall: 0.4088 - fbeta_score: 0.4115 - val_loss: 0.2612 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 387/1000\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.0114 - acc: 0.9967 - recall: 0.4151 - fbeta_score: 0.4142 - val_loss: 0.2982 - val_acc: 0.9317 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 388/1000\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.0053 - acc: 0.9989 - recall: 0.4449 - fbeta_score: 0.4449 - val_loss: 0.2622 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 389/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0100 - acc: 0.9973 - recall: 0.3925 - fbeta_score: 0.3921 - val_loss: 0.2738 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 390/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0095 - acc: 0.9957 - recall: 0.4106 - fbeta_score: 0.4131 - val_loss: 0.2966 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 391/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0149 - acc: 0.9951 - recall: 0.4088 - fbeta_score: 0.4138 - val_loss: 0.3128 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 392/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0094 - acc: 0.9967 - recall: 0.3889 - fbeta_score: 0.3914 - val_loss: 0.2801 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 393/1000\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.0100 - acc: 0.9973 - recall: 0.4146 - fbeta_score: 0.4159 - val_loss: 0.2906 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 394/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0087 - acc: 0.9957 - recall: 0.4449 - fbeta_score: 0.4449 - val_loss: 0.2881 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 395/1000\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.0065 - acc: 0.9978 - recall: 0.4305 - fbeta_score: 0.4319 - val_loss: 0.2928 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 396/1000\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.0098 - acc: 0.9973 - recall: 0.4384 - fbeta_score: 0.4393 - val_loss: 0.2813 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 397/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0066 - acc: 0.9978 - recall: 0.4368 - fbeta_score: 0.4395 - val_loss: 0.2730 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 398/1000\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.0121 - acc: 0.9957 - recall: 0.4133 - fbeta_score: 0.4149 - val_loss: 0.3195 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 399/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0032 - acc: 0.9995 - recall: 0.4449 - fbeta_score: 0.4449 - val_loss: 0.3012 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 400/1000\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0210 - acc: 0.9940 - recall: 0.3885 - fbeta_score: 0.3929 - val_loss: 0.3247 - val_acc: 0.9415 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 401/1000\n",
      "1843/1843 [==============================] - 0s 202us/step - loss: 0.0188 - acc: 0.9951 - recall: 0.3712 - fbeta_score: 0.3755 - val_loss: 0.2743 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 402/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0098 - acc: 0.9962 - recall: 0.3961 - fbeta_score: 0.3997 - val_loss: 0.2936 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 403/1000\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0129 - acc: 0.9967 - recall: 0.4097 - fbeta_score: 0.4106 - val_loss: 0.2927 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 404/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0080 - acc: 0.9967 - recall: 0.4502 - fbeta_score: 0.4473 - val_loss: 0.3447 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 405/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0081 - acc: 0.9967 - recall: 0.4268 - fbeta_score: 0.4258 - val_loss: 0.2561 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 406/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0047 - acc: 0.9984 - recall: 0.4078 - fbeta_score: 0.4095 - val_loss: 0.2633 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 407/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0073 - acc: 0.9984 - recall: 0.4323 - fbeta_score: 0.4330 - val_loss: 0.2761 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 408/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0116 - acc: 0.9967 - recall: 0.4078 - fbeta_score: 0.4077 - val_loss: 0.4130 - val_acc: 0.9268 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 409/1000\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0175 - acc: 0.9940 - recall: 0.4160 - fbeta_score: 0.4203 - val_loss: 0.3204 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 410/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0230 - acc: 0.9929 - recall: 0.4015 - fbeta_score: 0.4033 - val_loss: 0.3289 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 411/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0152 - acc: 0.9946 - recall: 0.4047 - fbeta_score: 0.4088 - val_loss: 0.3332 - val_acc: 0.9366 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 412/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0094 - acc: 0.9962 - recall: 0.4250 - fbeta_score: 0.4265 - val_loss: 0.2824 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 413/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0088 - acc: 0.9962 - recall: 0.4133 - fbeta_score: 0.4113 - val_loss: 0.2934 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 414/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0202 - acc: 0.9940 - recall: 0.3880 - fbeta_score: 0.3923 - val_loss: 0.2614 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 415/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0095 - acc: 0.9957 - recall: 0.3952 - fbeta_score: 0.3957 - val_loss: 0.3025 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 416/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0124 - acc: 0.9967 - recall: 0.4002 - fbeta_score: 0.4026 - val_loss: 0.2868 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 417/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0075 - acc: 0.9967 - recall: 0.4069 - fbeta_score: 0.4088 - val_loss: 0.2797 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 418/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0077 - acc: 0.9957 - recall: 0.4194 - fbeta_score: 0.4194 - val_loss: 0.2998 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 419/1000\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.0128 - acc: 0.9957 - recall: 0.3871 - fbeta_score: 0.3914 - val_loss: 0.2993 - val_acc: 0.9415 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 420/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0081 - acc: 0.9967 - recall: 0.4042 - fbeta_score: 0.4051 - val_loss: 0.3539 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 421/1000\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.0099 - acc: 0.9967 - recall: 0.4196 - fbeta_score: 0.4223 - val_loss: 0.2988 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 422/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0122 - acc: 0.9957 - recall: 0.4011 - fbeta_score: 0.4033 - val_loss: 0.2666 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 423/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0087 - acc: 0.9962 - recall: 0.4314 - fbeta_score: 0.4341 - val_loss: 0.3200 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 424/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0107 - acc: 0.9973 - recall: 0.4241 - fbeta_score: 0.4258 - val_loss: 0.3041 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 425/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0113 - acc: 0.9978 - recall: 0.4393 - fbeta_score: 0.4414 - val_loss: 0.3269 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 426/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0091 - acc: 0.9957 - recall: 0.4300 - fbeta_score: 0.4326 - val_loss: 0.2994 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 427/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0075 - acc: 0.9962 - recall: 0.3871 - fbeta_score: 0.3921 - val_loss: 0.2757 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 428/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0108 - acc: 0.9957 - recall: 0.3974 - fbeta_score: 0.3989 - val_loss: 0.2535 - val_acc: 0.9561 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 429/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0108 - acc: 0.9951 - recall: 0.4006 - fbeta_score: 0.4048 - val_loss: 0.2696 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 430/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0091 - acc: 0.9973 - recall: 0.4232 - fbeta_score: 0.4232 - val_loss: 0.3468 - val_acc: 0.9220 - val_recall: 0.2195 - val_fbeta_score: 0.2114\n",
      "Epoch 431/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0243 - acc: 0.9913 - recall: 0.4069 - fbeta_score: 0.4088 - val_loss: 0.2787 - val_acc: 0.9317 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 432/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0105 - acc: 0.9973 - recall: 0.4088 - fbeta_score: 0.4102 - val_loss: 0.3000 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 433/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0108 - acc: 0.9967 - recall: 0.4047 - fbeta_score: 0.4076 - val_loss: 0.2516 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 434/1000\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.0115 - acc: 0.9951 - recall: 0.3735 - fbeta_score: 0.3776 - val_loss: 0.2580 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 435/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0105 - acc: 0.9973 - recall: 0.4078 - fbeta_score: 0.4077 - val_loss: 0.2857 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 436/1000\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.0075 - acc: 0.9978 - recall: 0.4133 - fbeta_score: 0.4149 - val_loss: 0.3152 - val_acc: 0.9366 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 437/1000\n",
      "1843/1843 [==============================] - 0s 254us/step - loss: 0.0115 - acc: 0.9973 - recall: 0.4097 - fbeta_score: 0.4106 - val_loss: 0.3214 - val_acc: 0.9366 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 438/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0132 - acc: 0.9946 - recall: 0.3861 - fbeta_score: 0.3878 - val_loss: 0.3338 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 439/1000\n",
      "1843/1843 [==============================] - ETA: 0s - loss: 0.0055 - acc: 0.9983 - recall: 0.4331 - fbeta_score: 0.43 - 0s 219us/step - loss: 0.0052 - acc: 0.9984 - recall: 0.4314 - fbeta_score: 0.4323 - val_loss: 0.3063 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 440/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0090 - acc: 0.9967 - recall: 0.4097 - fbeta_score: 0.4106 - val_loss: 0.2801 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 441/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0047 - acc: 0.9984 - recall: 0.4422 - fbeta_score: 0.4431 - val_loss: 0.2431 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 442/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0085 - acc: 0.9967 - recall: 0.4133 - fbeta_score: 0.4131 - val_loss: 0.3107 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 443/1000\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.0101 - acc: 0.9957 - recall: 0.3943 - fbeta_score: 0.3950 - val_loss: 0.3172 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 444/1000\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.0074 - acc: 0.9978 - recall: 0.4015 - fbeta_score: 0.4033 - val_loss: 0.2812 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 445/1000\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.0129 - acc: 0.9962 - recall: 0.3943 - fbeta_score: 0.3950 - val_loss: 0.2822 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 446/1000\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.0232 - acc: 0.9978 - recall: 0.4341 - fbeta_score: 0.4341 - val_loss: 0.2736 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 447/1000\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.0144 - acc: 0.9946 - recall: 0.3703 - fbeta_score: 0.3752 - val_loss: 0.3101 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 448/1000\n",
      "1843/1843 [==============================] - 1s 272us/step - loss: 0.0085 - acc: 0.9973 - recall: 0.4192 - fbeta_score: 0.4182 - val_loss: 0.2546 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 449/1000\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.0128 - acc: 0.9962 - recall: 0.3961 - fbeta_score: 0.3979 - val_loss: 0.2791 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 450/1000\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.0060 - acc: 0.9973 - recall: 0.4042 - fbeta_score: 0.4051 - val_loss: 0.2871 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 451/1000\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.0065 - acc: 0.9989 - recall: 0.4259 - fbeta_score: 0.4268 - val_loss: 0.2897 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 452/1000\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.0093 - acc: 0.9962 - recall: 0.3988 - fbeta_score: 0.4013 - val_loss: 0.2539 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 453/1000\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.0041 - acc: 0.9989 - recall: 0.3961 - fbeta_score: 0.3943 - val_loss: 0.2898 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 454/1000\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 0.0067 - acc: 0.9978 - recall: 0.4097 - fbeta_score: 0.4106 - val_loss: 0.2789 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 455/1000\n",
      "1843/1843 [==============================] - 0s 258us/step - loss: 0.0117 - acc: 0.9962 - recall: 0.4169 - fbeta_score: 0.4192 - val_loss: 0.2897 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 456/1000\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.0035 - acc: 0.9995 - recall: 0.4151 - fbeta_score: 0.4160 - val_loss: 0.2552 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 457/1000\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.0071 - acc: 0.9973 - recall: 0.4097 - fbeta_score: 0.4106 - val_loss: 0.2930 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 458/1000\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.0083 - acc: 0.9978 - recall: 0.3943 - fbeta_score: 0.3950 - val_loss: 0.2759 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 459/1000\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.0084 - acc: 0.9967 - recall: 0.3977 - fbeta_score: 0.3999 - val_loss: 0.2520 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 460/1000\n",
      "1843/1843 [==============================] - 1s 274us/step - loss: 0.0092 - acc: 0.9973 - recall: 0.4160 - fbeta_score: 0.4185 - val_loss: 0.2550 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 461/1000\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.0052 - acc: 0.9984 - recall: 0.4106 - fbeta_score: 0.4113 - val_loss: 0.2875 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 462/1000\n",
      "1843/1843 [==============================] - 1s 272us/step - loss: 0.0133 - acc: 0.9957 - recall: 0.4142 - fbeta_score: 0.4174 - val_loss: 0.2626 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 463/1000\n",
      "1843/1843 [==============================] - 1s 274us/step - loss: 0.0091 - acc: 0.9978 - recall: 0.4354 - fbeta_score: 0.4369 - val_loss: 0.2934 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 464/1000\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.0105 - acc: 0.9962 - recall: 0.4024 - fbeta_score: 0.4059 - val_loss: 0.2283 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 465/1000\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.0102 - acc: 0.9951 - recall: 0.4332 - fbeta_score: 0.4319 - val_loss: 0.2755 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 466/1000\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.0063 - acc: 0.9973 - recall: 0.4286 - fbeta_score: 0.4305 - val_loss: 0.2668 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 467/1000\n",
      "1843/1843 [==============================] - 0s 258us/step - loss: 0.0122 - acc: 0.9973 - recall: 0.3907 - fbeta_score: 0.3925 - val_loss: 0.3710 - val_acc: 0.9220 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 468/1000\n",
      "1843/1843 [==============================] - 0s 261us/step - loss: 0.0137 - acc: 0.9951 - recall: 0.4051 - fbeta_score: 0.4077 - val_loss: 0.2652 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/1000\n",
      "1843/1843 [==============================] - 1s 347us/step - loss: 0.0056 - acc: 0.9995 - recall: 0.4069 - fbeta_score: 0.4069 - val_loss: 0.2714 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 470/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0076 - acc: 0.9984 - recall: 0.4476 - fbeta_score: 0.4485 - val_loss: 0.2334 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 471/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0080 - acc: 0.9978 - recall: 0.4214 - fbeta_score: 0.4203 - val_loss: 0.2530 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 472/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0060 - acc: 0.9978 - recall: 0.4422 - fbeta_score: 0.4395 - val_loss: 0.2503 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 473/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0137 - acc: 0.9957 - recall: 0.3889 - fbeta_score: 0.3914 - val_loss: 0.2594 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 474/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0064 - acc: 0.9984 - recall: 0.4142 - fbeta_score: 0.4151 - val_loss: 0.2449 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 475/1000\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.0169 - acc: 0.9946 - recall: 0.3952 - fbeta_score: 0.3993 - val_loss: 0.2671 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 476/1000\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.0087 - acc: 0.9967 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.3051 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 477/1000\n",
      "1843/1843 [==============================] - 0s 250us/step - loss: 0.0116 - acc: 0.9962 - recall: 0.4106 - fbeta_score: 0.4095 - val_loss: 0.3166 - val_acc: 0.9415 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 478/1000\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 0.0078 - acc: 0.9978 - recall: 0.4086 - fbeta_score: 0.4068 - val_loss: 0.2876 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 479/1000\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.0076 - acc: 0.9973 - recall: 0.3916 - fbeta_score: 0.3932 - val_loss: 0.2368 - val_acc: 0.9463 - val_recall: 0.3659 - val_fbeta_score: 0.3642\n",
      "Epoch 480/1000\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.0137 - acc: 0.9962 - recall: 0.4205 - fbeta_score: 0.4196 - val_loss: 0.2815 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 481/1000\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.0167 - acc: 0.9962 - recall: 0.3711 - fbeta_score: 0.3729 - val_loss: 0.2734 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 482/1000\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.0080 - acc: 0.9984 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2697 - val_acc: 0.9463 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 483/1000\n",
      "1843/1843 [==============================] - 0s 252us/step - loss: 0.0142 - acc: 0.9967 - recall: 0.3916 - fbeta_score: 0.3932 - val_loss: 0.2841 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 484/1000\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 0.0148 - acc: 0.9946 - recall: 0.4106 - fbeta_score: 0.4131 - val_loss: 0.2659 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 485/1000\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 0.0130 - acc: 0.9973 - recall: 0.4033 - fbeta_score: 0.4048 - val_loss: 0.2936 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 486/1000\n",
      "1843/1843 [==============================] - 0s 250us/step - loss: 0.0084 - acc: 0.9978 - recall: 0.4314 - fbeta_score: 0.4323 - val_loss: 0.2758 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 487/1000\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.0181 - acc: 0.9929 - recall: 0.4033 - fbeta_score: 0.4066 - val_loss: 0.2267 - val_acc: 0.9512 - val_recall: 0.2683 - val_fbeta_score: 0.2683\n",
      "Epoch 488/1000\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.0247 - acc: 0.9897 - recall: 0.3762 - fbeta_score: 0.3776 - val_loss: 0.2537 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 489/1000\n",
      "1843/1843 [==============================] - 0s 250us/step - loss: 0.0164 - acc: 0.9946 - recall: 0.4060 - fbeta_score: 0.4066 - val_loss: 0.2580 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 490/1000\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.0105 - acc: 0.9967 - recall: 0.3961 - fbeta_score: 0.3979 - val_loss: 0.2467 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 491/1000\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.0147 - acc: 0.9946 - recall: 0.3843 - fbeta_score: 0.3885 - val_loss: 0.2956 - val_acc: 0.9415 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 492/1000\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.0071 - acc: 0.9984 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2639 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 493/1000\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.0080 - acc: 0.9973 - recall: 0.4088 - fbeta_score: 0.4102 - val_loss: 0.2749 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 494/1000\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.0092 - acc: 0.9973 - recall: 0.4104 - fbeta_score: 0.4100 - val_loss: 0.2805 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 495/1000\n",
      "1843/1843 [==============================] - 0s 250us/step - loss: 0.0094 - acc: 0.9978 - recall: 0.3934 - fbeta_score: 0.3925 - val_loss: 0.2742 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 496/1000\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.0185 - acc: 0.9929 - recall: 0.3708 - fbeta_score: 0.3758 - val_loss: 0.2425 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 497/1000\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.0110 - acc: 0.9957 - recall: 0.4151 - fbeta_score: 0.4178 - val_loss: 0.2499 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 498/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0131 - acc: 0.9967 - recall: 0.4169 - fbeta_score: 0.4192 - val_loss: 0.3043 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 499/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0098 - acc: 0.9962 - recall: 0.4142 - fbeta_score: 0.4133 - val_loss: 0.2422 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 500/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0097 - acc: 0.9973 - recall: 0.4006 - fbeta_score: 0.4030 - val_loss: 0.2384 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 501/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0072 - acc: 0.9973 - recall: 0.4083 - fbeta_score: 0.4080 - val_loss: 0.2368 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 502/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0075 - acc: 0.9973 - recall: 0.4422 - fbeta_score: 0.4413 - val_loss: 0.2430 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 503/1000\n",
      "1843/1843 [==============================] - 1s 344us/step - loss: 0.0113 - acc: 0.9962 - recall: 0.3916 - fbeta_score: 0.3932 - val_loss: 0.2275 - val_acc: 0.9561 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 504/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0069 - acc: 0.9984 - recall: 0.4286 - fbeta_score: 0.4286 - val_loss: 0.2574 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0164 - acc: 0.9940 - recall: 0.3952 - fbeta_score: 0.3970 - val_loss: 0.2756 - val_acc: 0.9366 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 506/1000\n",
      "1843/1843 [==============================] - 0s 201us/step - loss: 0.0153 - acc: 0.9951 - recall: 0.3825 - fbeta_score: 0.3851 - val_loss: 0.2553 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 507/1000\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.0078 - acc: 0.9978 - recall: 0.4051 - fbeta_score: 0.4041 - val_loss: 0.2722 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 508/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0096 - acc: 0.9973 - recall: 0.4350 - fbeta_score: 0.4384 - val_loss: 0.2581 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 509/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0052 - acc: 0.9989 - recall: 0.4286 - fbeta_score: 0.4305 - val_loss: 0.2710 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 510/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 0.9984 - recall: 0.4341 - fbeta_score: 0.4359 - val_loss: 0.2506 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 511/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0061 - acc: 0.9989 - recall: 0.4140 - fbeta_score: 0.4140 - val_loss: 0.2515 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 512/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0118 - acc: 0.9967 - recall: 0.4142 - fbeta_score: 0.4138 - val_loss: 0.2393 - val_acc: 0.9610 - val_recall: 0.3415 - val_fbeta_score: 0.3577\n",
      "Epoch 513/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0247 - acc: 0.9940 - recall: 0.4051 - fbeta_score: 0.4077 - val_loss: 0.2994 - val_acc: 0.9463 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 514/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0110 - acc: 0.9962 - recall: 0.4178 - fbeta_score: 0.4178 - val_loss: 0.3461 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 515/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0134 - acc: 0.9967 - recall: 0.4368 - fbeta_score: 0.4395 - val_loss: 0.3157 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 516/1000\n",
      "1843/1843 [==============================] - 0s 200us/step - loss: 0.0101 - acc: 0.9967 - recall: 0.3947 - fbeta_score: 0.3953 - val_loss: 0.3150 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 517/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0092 - acc: 0.9957 - recall: 0.4106 - fbeta_score: 0.4131 - val_loss: 0.3095 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 518/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0107 - acc: 0.9967 - recall: 0.4124 - fbeta_score: 0.4106 - val_loss: 0.2877 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 519/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0096 - acc: 0.9962 - recall: 0.4137 - fbeta_score: 0.4150 - val_loss: 0.2899 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 520/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0090 - acc: 0.9967 - recall: 0.4354 - fbeta_score: 0.4369 - val_loss: 0.2615 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 521/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0083 - acc: 0.9973 - recall: 0.4051 - fbeta_score: 0.4041 - val_loss: 0.4082 - val_acc: 0.9317 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 522/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0097 - acc: 0.9957 - recall: 0.4133 - fbeta_score: 0.4149 - val_loss: 0.2999 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 523/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0087 - acc: 0.9978 - recall: 0.4440 - fbeta_score: 0.4458 - val_loss: 0.3019 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 524/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0069 - acc: 0.9978 - recall: 0.4420 - fbeta_score: 0.4419 - val_loss: 0.3121 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 525/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0117 - acc: 0.9957 - recall: 0.4187 - fbeta_score: 0.4221 - val_loss: 0.3013 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 526/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0090 - acc: 0.9962 - recall: 0.3934 - fbeta_score: 0.3952 - val_loss: 0.2881 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 527/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0047 - acc: 0.9989 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2825 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 528/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0175 - acc: 0.9951 - recall: 0.3911 - fbeta_score: 0.3931 - val_loss: 0.2584 - val_acc: 0.9610 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 529/1000\n",
      "1843/1843 [==============================] - 0s 242us/step - loss: 0.0151 - acc: 0.9940 - recall: 0.3947 - fbeta_score: 0.3953 - val_loss: 0.2843 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 530/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0199 - acc: 0.9919 - recall: 0.3676 - fbeta_score: 0.3716 - val_loss: 0.2799 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 531/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0129 - acc: 0.9951 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2400 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 532/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0051 - acc: 0.9989 - recall: 0.4178 - fbeta_score: 0.4160 - val_loss: 0.2831 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 533/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0047 - acc: 0.9984 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2666 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 534/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0055 - acc: 0.9978 - recall: 0.3880 - fbeta_score: 0.3889 - val_loss: 0.2872 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 535/1000\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.0096 - acc: 0.9962 - recall: 0.3970 - fbeta_score: 0.3986 - val_loss: 0.2957 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 536/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0094 - acc: 0.9957 - recall: 0.4504 - fbeta_score: 0.4522 - val_loss: 0.3408 - val_acc: 0.9268 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 537/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0256 - acc: 0.9924 - recall: 0.3924 - fbeta_score: 0.3943 - val_loss: 0.3247 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 538/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0133 - acc: 0.9946 - recall: 0.3907 - fbeta_score: 0.3925 - val_loss: 0.3345 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 539/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0096 - acc: 0.9962 - recall: 0.4467 - fbeta_score: 0.4482 - val_loss: 0.2907 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 540/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0098 - acc: 0.9967 - recall: 0.4149 - fbeta_score: 0.4165 - val_loss: 0.2810 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0188 - acc: 0.9940 - recall: 0.4142 - fbeta_score: 0.4169 - val_loss: 0.2645 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 542/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0132 - acc: 0.9946 - recall: 0.3762 - fbeta_score: 0.3796 - val_loss: 0.2709 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 543/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0108 - acc: 0.9951 - recall: 0.4113 - fbeta_score: 0.4140 - val_loss: 0.3037 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 544/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0087 - acc: 0.9978 - recall: 0.4124 - fbeta_score: 0.4142 - val_loss: 0.2236 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 545/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0124 - acc: 0.9962 - recall: 0.4015 - fbeta_score: 0.4015 - val_loss: 0.2645 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 546/1000\n",
      "1843/1843 [==============================] - 0s 202us/step - loss: 0.0116 - acc: 0.9957 - recall: 0.4069 - fbeta_score: 0.4086 - val_loss: 0.3303 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 547/1000\n",
      "1843/1843 [==============================] - 0s 197us/step - loss: 0.0108 - acc: 0.9957 - recall: 0.4115 - fbeta_score: 0.4138 - val_loss: 0.3073 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 548/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0088 - acc: 0.9962 - recall: 0.4137 - fbeta_score: 0.4145 - val_loss: 0.2554 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 549/1000\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0082 - acc: 0.9978 - recall: 0.4314 - fbeta_score: 0.4323 - val_loss: 0.2981 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 550/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0061 - acc: 0.9978 - recall: 0.4259 - fbeta_score: 0.4268 - val_loss: 0.2763 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 551/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0074 - acc: 0.9978 - recall: 0.4033 - fbeta_score: 0.4048 - val_loss: 0.2582 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 552/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0072 - acc: 0.9973 - recall: 0.4268 - fbeta_score: 0.4276 - val_loss: 0.3600 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 553/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0090 - acc: 0.9962 - recall: 0.4051 - fbeta_score: 0.4077 - val_loss: 0.2744 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 554/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0092 - acc: 0.9967 - recall: 0.3905 - fbeta_score: 0.3930 - val_loss: 0.2617 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 555/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0077 - acc: 0.9967 - recall: 0.4314 - fbeta_score: 0.4323 - val_loss: 0.2727 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 556/1000\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.0087 - acc: 0.9984 - recall: 0.4069 - fbeta_score: 0.4088 - val_loss: 0.2695 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 557/1000\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.0083 - acc: 0.9962 - recall: 0.4124 - fbeta_score: 0.4142 - val_loss: 0.2448 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 558/1000\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.0098 - acc: 0.9967 - recall: 0.4024 - fbeta_score: 0.4022 - val_loss: 0.2783 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 559/1000\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.0068 - acc: 0.9973 - recall: 0.3880 - fbeta_score: 0.3889 - val_loss: 0.2574 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 560/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0076 - acc: 0.9978 - recall: 0.3898 - fbeta_score: 0.3921 - val_loss: 0.2812 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 561/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0065 - acc: 0.9973 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2710 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 562/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0066 - acc: 0.9973 - recall: 0.4078 - fbeta_score: 0.4095 - val_loss: 0.2803 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 563/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0070 - acc: 0.9984 - recall: 0.3893 - fbeta_score: 0.3899 - val_loss: 0.2450 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 564/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0071 - acc: 0.9978 - recall: 0.4282 - fbeta_score: 0.4304 - val_loss: 0.3043 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 565/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0066 - acc: 0.9989 - recall: 0.4241 - fbeta_score: 0.4258 - val_loss: 0.2582 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 566/1000\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.0118 - acc: 0.9957 - recall: 0.4268 - fbeta_score: 0.4276 - val_loss: 0.2611 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 567/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0026 - acc: 1.0000 - recall: 0.4178 - fbeta_score: 0.4178 - val_loss: 0.2636 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 568/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0082 - acc: 0.9962 - recall: 0.3898 - fbeta_score: 0.3921 - val_loss: 0.2238 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 569/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0075 - acc: 0.9978 - recall: 0.4124 - fbeta_score: 0.4142 - val_loss: 0.2382 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 570/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0072 - acc: 0.9967 - recall: 0.4314 - fbeta_score: 0.4341 - val_loss: 0.3074 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 571/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0125 - acc: 0.9951 - recall: 0.4024 - fbeta_score: 0.4059 - val_loss: 0.2457 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 572/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0068 - acc: 0.9978 - recall: 0.3961 - fbeta_score: 0.3979 - val_loss: 0.2562 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 573/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0151 - acc: 0.9940 - recall: 0.3956 - fbeta_score: 0.3977 - val_loss: 0.2486 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 574/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0101 - acc: 0.9973 - recall: 0.4078 - fbeta_score: 0.4095 - val_loss: 0.2586 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 575/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0084 - acc: 0.9967 - recall: 0.4033 - fbeta_score: 0.4048 - val_loss: 0.2768 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 576/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0128 - acc: 0.9957 - recall: 0.3843 - fbeta_score: 0.3885 - val_loss: 0.2139 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0157 - acc: 0.9951 - recall: 0.3684 - fbeta_score: 0.3684 - val_loss: 0.2393 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 578/1000\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.0064 - acc: 0.9984 - recall: 0.4323 - fbeta_score: 0.4312 - val_loss: 0.2634 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 579/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0026 - acc: 1.0000 - recall: 0.4178 - fbeta_score: 0.4178 - val_loss: 0.2534 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 580/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 0.9989 - recall: 0.4232 - fbeta_score: 0.4232 - val_loss: 0.2840 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 581/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0062 - acc: 0.9978 - recall: 0.4033 - fbeta_score: 0.4042 - val_loss: 0.2849 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 582/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0095 - acc: 0.9962 - recall: 0.4068 - fbeta_score: 0.4075 - val_loss: 0.2746 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 583/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0060 - acc: 0.9967 - recall: 0.4078 - fbeta_score: 0.4116 - val_loss: 0.2136 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 584/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0095 - acc: 0.9973 - recall: 0.4395 - fbeta_score: 0.4395 - val_loss: 0.2346 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 585/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0073 - acc: 0.9978 - recall: 0.4178 - fbeta_score: 0.4167 - val_loss: 0.2184 - val_acc: 0.9366 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 586/1000\n",
      "1843/1843 [==============================] - 0s 200us/step - loss: 0.0144 - acc: 0.9957 - recall: 0.3988 - fbeta_score: 0.4013 - val_loss: 0.2212 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 587/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0104 - acc: 0.9962 - recall: 0.4015 - fbeta_score: 0.4037 - val_loss: 0.2083 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 588/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0147 - acc: 0.9929 - recall: 0.4011 - fbeta_score: 0.4062 - val_loss: 0.2172 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 589/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0070 - acc: 0.9984 - recall: 0.4015 - fbeta_score: 0.4033 - val_loss: 0.2084 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 590/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0073 - acc: 0.9973 - recall: 0.4069 - fbeta_score: 0.4069 - val_loss: 0.2496 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 591/1000\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.0134 - acc: 0.9957 - recall: 0.3875 - fbeta_score: 0.3895 - val_loss: 0.2269 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 592/1000\n",
      "1843/1843 [==============================] - 1s 276us/step - loss: 0.0109 - acc: 0.9962 - recall: 0.3889 - fbeta_score: 0.3896 - val_loss: 0.2645 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 593/1000\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.0064 - acc: 0.9984 - recall: 0.4431 - fbeta_score: 0.4438 - val_loss: 0.2325 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 594/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0142 - acc: 0.9978 - recall: 0.4314 - fbeta_score: 0.4323 - val_loss: 0.2820 - val_acc: 0.9463 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 595/1000\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.0137 - acc: 0.9940 - recall: 0.4151 - fbeta_score: 0.4178 - val_loss: 0.3455 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 596/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0113 - acc: 0.9967 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2821 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 597/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0085 - acc: 0.9957 - recall: 0.4106 - fbeta_score: 0.4131 - val_loss: 0.2627 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 598/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0174 - acc: 0.9929 - recall: 0.3884 - fbeta_score: 0.3919 - val_loss: 0.2550 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 599/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0103 - acc: 0.9957 - recall: 0.3943 - fbeta_score: 0.3986 - val_loss: 0.2852 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 600/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0122 - acc: 0.9967 - recall: 0.3880 - fbeta_score: 0.3907 - val_loss: 0.2844 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 601/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0120 - acc: 0.9946 - recall: 0.3898 - fbeta_score: 0.3916 - val_loss: 0.3128 - val_acc: 0.9317 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 602/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0155 - acc: 0.9951 - recall: 0.4110 - fbeta_score: 0.4109 - val_loss: 0.2843 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 603/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0056 - acc: 0.9973 - recall: 0.4115 - fbeta_score: 0.4138 - val_loss: 0.2417 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 604/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0060 - acc: 0.9978 - recall: 0.4368 - fbeta_score: 0.4377 - val_loss: 0.2837 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 605/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0064 - acc: 0.9978 - recall: 0.4006 - fbeta_score: 0.4024 - val_loss: 0.2941 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 606/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0145 - acc: 0.9940 - recall: 0.3803 - fbeta_score: 0.3841 - val_loss: 0.2962 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 607/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0050 - acc: 0.9995 - recall: 0.4520 - fbeta_score: 0.4520 - val_loss: 0.2830 - val_acc: 0.9366 - val_recall: 0.2927 - val_fbeta_score: 0.2683\n",
      "Epoch 608/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0143 - acc: 0.9940 - recall: 0.3816 - fbeta_score: 0.3849 - val_loss: 0.2835 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 609/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0121 - acc: 0.9957 - recall: 0.3690 - fbeta_score: 0.3726 - val_loss: 0.3131 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 610/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0132 - acc: 0.9967 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.3104 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 611/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0109 - acc: 0.9962 - recall: 0.3706 - fbeta_score: 0.3740 - val_loss: 0.2605 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 612/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0173 - acc: 0.9924 - recall: 0.4042 - fbeta_score: 0.4068 - val_loss: 0.2340 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 613/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0157 - acc: 0.9940 - recall: 0.3812 - fbeta_score: 0.3872 - val_loss: 0.2298 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 614/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0048 - acc: 0.9989 - recall: 0.4666 - fbeta_score: 0.4666 - val_loss: 0.2659 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 615/1000\n",
      "1843/1843 [==============================] - 0s 201us/step - loss: 0.0045 - acc: 0.9984 - recall: 0.4051 - fbeta_score: 0.4059 - val_loss: 0.2719 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 616/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 0.9984 - recall: 0.4431 - fbeta_score: 0.4438 - val_loss: 0.2648 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 617/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0038 - acc: 0.9984 - recall: 0.4286 - fbeta_score: 0.4305 - val_loss: 0.2553 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 618/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0070 - acc: 0.9978 - recall: 0.4178 - fbeta_score: 0.4196 - val_loss: 0.2604 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 619/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0058 - acc: 0.9978 - recall: 0.4368 - fbeta_score: 0.4377 - val_loss: 0.2623 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 620/1000\n",
      "1843/1843 [==============================] - 0s 200us/step - loss: 0.0079 - acc: 0.9978 - recall: 0.3798 - fbeta_score: 0.3816 - val_loss: 0.2871 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 621/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0063 - acc: 0.9978 - recall: 0.4258 - fbeta_score: 0.4274 - val_loss: 0.2731 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 622/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0123 - acc: 0.9946 - recall: 0.4033 - fbeta_score: 0.4084 - val_loss: 0.2804 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 623/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0092 - acc: 0.9957 - recall: 0.4069 - fbeta_score: 0.4069 - val_loss: 0.2506 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 624/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0046 - acc: 0.9989 - recall: 0.3984 - fbeta_score: 0.3997 - val_loss: 0.2563 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 625/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0091 - acc: 0.9984 - recall: 0.4124 - fbeta_score: 0.4124 - val_loss: 0.2527 - val_acc: 0.9463 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 626/1000\n",
      "1843/1843 [==============================] - 0s 200us/step - loss: 0.0137 - acc: 0.9967 - recall: 0.3878 - fbeta_score: 0.3894 - val_loss: 0.2706 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 627/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0090 - acc: 0.9973 - recall: 0.3839 - fbeta_score: 0.3845 - val_loss: 0.2677 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 628/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0148 - acc: 0.9951 - recall: 0.3943 - fbeta_score: 0.3950 - val_loss: 0.2610 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 629/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0056 - acc: 0.9978 - recall: 0.4113 - fbeta_score: 0.4122 - val_loss: 0.2944 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 630/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0071 - acc: 0.9962 - recall: 0.3871 - fbeta_score: 0.3903 - val_loss: 0.2716 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 631/1000\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.0044 - acc: 0.9989 - recall: 0.4268 - fbeta_score: 0.4276 - val_loss: 0.2771 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 632/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0071 - acc: 0.9978 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2882 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 633/1000\n",
      "1843/1843 [==============================] - 0s 252us/step - loss: 0.0168 - acc: 0.9962 - recall: 0.4159 - fbeta_score: 0.4153 - val_loss: 0.2533 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 634/1000\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.0078 - acc: 0.9967 - recall: 0.4323 - fbeta_score: 0.4330 - val_loss: 0.2742 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 635/1000\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.0065 - acc: 0.9973 - recall: 0.3880 - fbeta_score: 0.3905 - val_loss: 0.2419 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 636/1000\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.0056 - acc: 0.9984 - recall: 0.4312 - fbeta_score: 0.4328 - val_loss: 0.2606 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 637/1000\n",
      "1843/1843 [==============================] - 0s 256us/step - loss: 0.0089 - acc: 0.9984 - recall: 0.4011 - fbeta_score: 0.4033 - val_loss: 0.2870 - val_acc: 0.9366 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 638/1000\n",
      "1843/1843 [==============================] - 0s 254us/step - loss: 0.0091 - acc: 0.9984 - recall: 0.4002 - fbeta_score: 0.4026 - val_loss: 0.2472 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 639/1000\n",
      "1843/1843 [==============================] - 0s 252us/step - loss: 0.0069 - acc: 0.9973 - recall: 0.4106 - fbeta_score: 0.4113 - val_loss: 0.3256 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 640/1000\n",
      "1843/1843 [==============================] - 0s 255us/step - loss: 0.0179 - acc: 0.9946 - recall: 0.3902 - fbeta_score: 0.3936 - val_loss: 0.2300 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 641/1000\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.0063 - acc: 0.9984 - recall: 0.4124 - fbeta_score: 0.4124 - val_loss: 0.2357 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 642/1000\n",
      "1843/1843 [==============================] - 0s 258us/step - loss: 0.0159 - acc: 0.9957 - recall: 0.3866 - fbeta_score: 0.3881 - val_loss: 0.2920 - val_acc: 0.9268 - val_recall: 0.1220 - val_fbeta_score: 0.1220\n",
      "Epoch 643/1000\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.0107 - acc: 0.9962 - recall: 0.4088 - fbeta_score: 0.4084 - val_loss: 0.2728 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 644/1000\n",
      "1843/1843 [==============================] - 0s 266us/step - loss: 0.0152 - acc: 0.9967 - recall: 0.4033 - fbeta_score: 0.4030 - val_loss: 0.2627 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 645/1000\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.0098 - acc: 0.9973 - recall: 0.3979 - fbeta_score: 0.3988 - val_loss: 0.2139 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 646/1000\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.0072 - acc: 0.9978 - recall: 0.4241 - fbeta_score: 0.4258 - val_loss: 0.2896 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 647/1000\n",
      "1843/1843 [==============================] - 0s 261us/step - loss: 0.0124 - acc: 0.9957 - recall: 0.4142 - fbeta_score: 0.4156 - val_loss: 0.2260 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 648/1000\n",
      "1843/1843 [==============================] - 0s 258us/step - loss: 0.0051 - acc: 0.9978 - recall: 0.4113 - fbeta_score: 0.4122 - val_loss: 0.2635 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 649/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.0053 - acc: 0.9978 - recall: 0.4176 - fbeta_score: 0.4183 - val_loss: 0.2707 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 650/1000\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.0083 - acc: 0.9973 - recall: 0.3825 - fbeta_score: 0.3855 - val_loss: 0.2548 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 651/1000\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.0106 - acc: 0.9967 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.3040 - val_acc: 0.9415 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 652/1000\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.0075 - acc: 0.9984 - recall: 0.4133 - fbeta_score: 0.4131 - val_loss: 0.2701 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 653/1000\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.0076 - acc: 0.9973 - recall: 0.4223 - fbeta_score: 0.4241 - val_loss: 0.2882 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 654/1000\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.0100 - acc: 0.9962 - recall: 0.3796 - fbeta_score: 0.3822 - val_loss: 0.2896 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 655/1000\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.0105 - acc: 0.9967 - recall: 0.4350 - fbeta_score: 0.4366 - val_loss: 0.3199 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 656/1000\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.0109 - acc: 0.9957 - recall: 0.4051 - fbeta_score: 0.4059 - val_loss: 0.2875 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 657/1000\n",
      "1843/1843 [==============================] - 1s 349us/step - loss: 0.0039 - acc: 0.9984 - recall: 0.4493 - fbeta_score: 0.4502 - val_loss: 0.3041 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 658/1000\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.0084 - acc: 0.9989 - recall: 0.4341 - fbeta_score: 0.4323 - val_loss: 0.3165 - val_acc: 0.9317 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 659/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0230 - acc: 0.9951 - recall: 0.4002 - fbeta_score: 0.4044 - val_loss: 0.2818 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 660/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0104 - acc: 0.9962 - recall: 0.3861 - fbeta_score: 0.3878 - val_loss: 0.2541 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 661/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0083 - acc: 0.9973 - recall: 0.4167 - fbeta_score: 0.4158 - val_loss: 0.2770 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 662/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0110 - acc: 0.9967 - recall: 0.4088 - fbeta_score: 0.4113 - val_loss: 0.2596 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 663/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0075 - acc: 0.9967 - recall: 0.3907 - fbeta_score: 0.3925 - val_loss: 0.2681 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 664/1000\n",
      "1843/1843 [==============================] - 1s 341us/step - loss: 0.0060 - acc: 0.9978 - recall: 0.4422 - fbeta_score: 0.4413 - val_loss: 0.2794 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 665/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0083 - acc: 0.9984 - recall: 0.4106 - fbeta_score: 0.4095 - val_loss: 0.2853 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 666/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0065 - acc: 0.9984 - recall: 0.4368 - fbeta_score: 0.4359 - val_loss: 0.2809 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 667/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0061 - acc: 0.9973 - recall: 0.4214 - fbeta_score: 0.4221 - val_loss: 0.2754 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 668/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0066 - acc: 0.9973 - recall: 0.4232 - fbeta_score: 0.4232 - val_loss: 0.3042 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 669/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0060 - acc: 0.9989 - recall: 0.4078 - fbeta_score: 0.4095 - val_loss: 0.2857 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 670/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0055 - acc: 0.9984 - recall: 0.4015 - fbeta_score: 0.4031 - val_loss: 0.2964 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 671/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0043 - acc: 0.9989 - recall: 0.3961 - fbeta_score: 0.3961 - val_loss: 0.2848 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 672/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0075 - acc: 0.9962 - recall: 0.3889 - fbeta_score: 0.3914 - val_loss: 0.2550 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 673/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0070 - acc: 0.9962 - recall: 0.4078 - fbeta_score: 0.4095 - val_loss: 0.3223 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 674/1000\n",
      "1843/1843 [==============================] - ETA: 0s - loss: 0.0038 - acc: 1.0000 - recall: 0.3933 - fbeta_score: 0.39 - 0s 216us/step - loss: 0.0039 - acc: 1.0000 - recall: 0.3961 - fbeta_score: 0.3961 - val_loss: 0.3009 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 675/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0050 - acc: 0.9984 - recall: 0.4268 - fbeta_score: 0.4258 - val_loss: 0.2932 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 676/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0043 - acc: 0.9989 - recall: 0.3934 - fbeta_score: 0.3943 - val_loss: 0.3406 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 677/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0104 - acc: 0.9957 - recall: 0.3843 - fbeta_score: 0.3883 - val_loss: 0.3239 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 678/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0063 - acc: 0.9989 - recall: 0.4051 - fbeta_score: 0.4059 - val_loss: 0.2976 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 679/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0083 - acc: 0.9967 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2816 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 680/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0047 - acc: 0.9984 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.3011 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 681/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0108 - acc: 0.9967 - recall: 0.4296 - fbeta_score: 0.4294 - val_loss: 0.3422 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 682/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0093 - acc: 0.9957 - recall: 0.4494 - fbeta_score: 0.4482 - val_loss: 0.3732 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 683/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0041 - acc: 0.9995 - recall: 0.4178 - fbeta_score: 0.4178 - val_loss: 0.3169 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 684/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0036 - acc: 0.9989 - recall: 0.4232 - fbeta_score: 0.4232 - val_loss: 0.3444 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0038 - acc: 0.9984 - recall: 0.4051 - fbeta_score: 0.4059 - val_loss: 0.3267 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 686/1000\n",
      "1843/1843 [==============================] - 0s 200us/step - loss: 0.0079 - acc: 0.9973 - recall: 0.4083 - fbeta_score: 0.4098 - val_loss: 0.3382 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 687/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0038 - acc: 0.9984 - recall: 0.4151 - fbeta_score: 0.4160 - val_loss: 0.3140 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 688/1000\n",
      "1843/1843 [==============================] - 0s 201us/step - loss: 0.0037 - acc: 0.9995 - recall: 0.3825 - fbeta_score: 0.3834 - val_loss: 0.3174 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 689/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0049 - acc: 0.9978 - recall: 0.4115 - fbeta_score: 0.4138 - val_loss: 0.2990 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 690/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0128 - acc: 0.9951 - recall: 0.4169 - fbeta_score: 0.4205 - val_loss: 0.3097 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 691/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 0.9989 - recall: 0.4268 - fbeta_score: 0.4276 - val_loss: 0.3491 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 692/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0110 - acc: 0.9962 - recall: 0.3871 - fbeta_score: 0.3880 - val_loss: 0.3487 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 693/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0133 - acc: 0.9967 - recall: 0.4350 - fbeta_score: 0.4348 - val_loss: 0.3136 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 694/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0092 - acc: 0.9978 - recall: 0.4124 - fbeta_score: 0.4124 - val_loss: 0.2929 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 695/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0083 - acc: 0.9967 - recall: 0.3961 - fbeta_score: 0.3961 - val_loss: 0.2953 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 696/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0242 - acc: 0.9924 - recall: 0.4053 - fbeta_score: 0.4088 - val_loss: 0.4937 - val_acc: 0.9220 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 697/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0154 - acc: 0.9946 - recall: 0.3907 - fbeta_score: 0.3946 - val_loss: 0.2579 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 698/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0138 - acc: 0.9946 - recall: 0.3905 - fbeta_score: 0.3930 - val_loss: 0.2633 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 699/1000\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.0112 - acc: 0.9957 - recall: 0.4110 - fbeta_score: 0.4134 - val_loss: 0.3285 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 700/1000\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.0073 - acc: 0.9973 - recall: 0.4259 - fbeta_score: 0.4268 - val_loss: 0.3135 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 701/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0140 - acc: 0.9951 - recall: 0.4232 - fbeta_score: 0.4268 - val_loss: 0.3180 - val_acc: 0.9366 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 702/1000\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.0117 - acc: 0.9962 - recall: 0.4187 - fbeta_score: 0.4203 - val_loss: 0.2748 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 703/1000\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.0076 - acc: 0.9973 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.4027 - val_acc: 0.9317 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 704/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0090 - acc: 0.9957 - recall: 0.4069 - fbeta_score: 0.4069 - val_loss: 0.3198 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 705/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0063 - acc: 0.9984 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2775 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 706/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0061 - acc: 0.9978 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2844 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 707/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0099 - acc: 0.9957 - recall: 0.3943 - fbeta_score: 0.3968 - val_loss: 0.2741 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 708/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0097 - acc: 0.9962 - recall: 0.3898 - fbeta_score: 0.3916 - val_loss: 0.2984 - val_acc: 0.9317 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 709/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0056 - acc: 0.9973 - recall: 0.4078 - fbeta_score: 0.4095 - val_loss: 0.2872 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 710/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0147 - acc: 0.9962 - recall: 0.4033 - fbeta_score: 0.4060 - val_loss: 0.2697 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 711/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0085 - acc: 0.9978 - recall: 0.4323 - fbeta_score: 0.4330 - val_loss: 0.3194 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 712/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0065 - acc: 0.9973 - recall: 0.4187 - fbeta_score: 0.4185 - val_loss: 0.3116 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 713/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0070 - acc: 0.9978 - recall: 0.4078 - fbeta_score: 0.4095 - val_loss: 0.3107 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 714/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0101 - acc: 0.9962 - recall: 0.4223 - fbeta_score: 0.4247 - val_loss: 0.3568 - val_acc: 0.9317 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 715/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0034 - acc: 0.9995 - recall: 0.4086 - fbeta_score: 0.4086 - val_loss: 0.3388 - val_acc: 0.9366 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 716/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0080 - acc: 0.9984 - recall: 0.4395 - fbeta_score: 0.4413 - val_loss: 0.4128 - val_acc: 0.9317 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 717/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0085 - acc: 0.9973 - recall: 0.3898 - fbeta_score: 0.3934 - val_loss: 0.2754 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 718/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0090 - acc: 0.9978 - recall: 0.4268 - fbeta_score: 0.4294 - val_loss: 0.3138 - val_acc: 0.9268 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 719/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0063 - acc: 0.9973 - recall: 0.3807 - fbeta_score: 0.3823 - val_loss: 0.2826 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 720/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0096 - acc: 0.9957 - recall: 0.3997 - fbeta_score: 0.4022 - val_loss: 0.2865 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0088 - acc: 0.9973 - recall: 0.4205 - fbeta_score: 0.4232 - val_loss: 0.2543 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 722/1000\n",
      "1843/1843 [==============================] - 0s 200us/step - loss: 0.0078 - acc: 0.9984 - recall: 0.4232 - fbeta_score: 0.4232 - val_loss: 0.2938 - val_acc: 0.9366 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 723/1000\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.0090 - acc: 0.9967 - recall: 0.4205 - fbeta_score: 0.4178 - val_loss: 0.2490 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 724/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0086 - acc: 0.9973 - recall: 0.4259 - fbeta_score: 0.4286 - val_loss: 0.2736 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 725/1000\n",
      "1843/1843 [==============================] - 0s 202us/step - loss: 0.0065 - acc: 0.9984 - recall: 0.3834 - fbeta_score: 0.3842 - val_loss: 0.2911 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 726/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0069 - acc: 0.9967 - recall: 0.4178 - fbeta_score: 0.4196 - val_loss: 0.2753 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 727/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0080 - acc: 0.9978 - recall: 0.4042 - fbeta_score: 0.4051 - val_loss: 0.2767 - val_acc: 0.9366 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 728/1000\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0180 - acc: 0.9946 - recall: 0.3955 - fbeta_score: 0.3984 - val_loss: 0.2417 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 729/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0070 - acc: 0.9978 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2778 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 730/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0071 - acc: 0.9973 - recall: 0.4042 - fbeta_score: 0.4051 - val_loss: 0.2663 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 731/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0094 - acc: 0.9967 - recall: 0.4422 - fbeta_score: 0.4449 - val_loss: 0.2602 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 732/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0128 - acc: 0.9962 - recall: 0.3947 - fbeta_score: 0.3946 - val_loss: 0.3123 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 733/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0108 - acc: 0.9962 - recall: 0.4332 - fbeta_score: 0.4355 - val_loss: 0.3490 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 734/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0155 - acc: 0.9951 - recall: 0.4006 - fbeta_score: 0.4048 - val_loss: 0.2884 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 735/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0080 - acc: 0.9962 - recall: 0.4268 - fbeta_score: 0.4294 - val_loss: 0.2945 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 736/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0126 - acc: 0.9978 - recall: 0.4133 - fbeta_score: 0.4152 - val_loss: 0.2575 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 737/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0066 - acc: 0.9973 - recall: 0.3597 - fbeta_score: 0.3601 - val_loss: 0.2538 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 738/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0058 - acc: 0.9978 - recall: 0.4314 - fbeta_score: 0.4305 - val_loss: 0.2707 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 739/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0075 - acc: 0.9957 - recall: 0.4194 - fbeta_score: 0.4194 - val_loss: 0.2341 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 740/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0065 - acc: 0.9978 - recall: 0.4024 - fbeta_score: 0.4041 - val_loss: 0.2240 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 741/1000\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.0078 - acc: 0.9973 - recall: 0.3653 - fbeta_score: 0.3668 - val_loss: 0.2672 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 742/1000\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 0.0214 - acc: 0.9935 - recall: 0.3780 - fbeta_score: 0.3785 - val_loss: 0.3180 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 743/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0070 - acc: 0.9978 - recall: 0.4286 - fbeta_score: 0.4305 - val_loss: 0.6191 - val_acc: 0.9171 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 744/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0591 - acc: 0.9783 - recall: 0.3450 - fbeta_score: 0.3476 - val_loss: 0.2883 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 745/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0309 - acc: 0.9864 - recall: 0.3599 - fbeta_score: 0.3603 - val_loss: 0.2544 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 746/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0281 - acc: 0.9913 - recall: 0.3916 - fbeta_score: 0.3961 - val_loss: 0.3013 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 747/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0168 - acc: 0.9940 - recall: 0.3925 - fbeta_score: 0.3921 - val_loss: 0.2952 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 748/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0284 - acc: 0.9891 - recall: 0.3630 - fbeta_score: 0.3672 - val_loss: 0.2727 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 749/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0176 - acc: 0.9951 - recall: 0.3993 - fbeta_score: 0.4016 - val_loss: 0.3041 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 750/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0248 - acc: 0.9924 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2598 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 751/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0208 - acc: 0.9913 - recall: 0.3997 - fbeta_score: 0.4022 - val_loss: 0.2622 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 752/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0140 - acc: 0.9951 - recall: 0.4246 - fbeta_score: 0.4243 - val_loss: 0.4415 - val_acc: 0.9122 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 753/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0452 - acc: 0.9864 - recall: 0.3420 - fbeta_score: 0.3464 - val_loss: 0.2553 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 754/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0183 - acc: 0.9935 - recall: 0.3644 - fbeta_score: 0.3695 - val_loss: 0.2447 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 755/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0210 - acc: 0.9935 - recall: 0.4015 - fbeta_score: 0.4051 - val_loss: 0.2704 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 756/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0229 - acc: 0.9902 - recall: 0.3814 - fbeta_score: 0.3890 - val_loss: 0.2378 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 757/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0168 - acc: 0.9946 - recall: 0.4124 - fbeta_score: 0.4124 - val_loss: 0.2809 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 758/1000\n",
      "1843/1843 [==============================] - 0s 200us/step - loss: 0.0145 - acc: 0.9962 - recall: 0.4097 - fbeta_score: 0.4106 - val_loss: 0.2621 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 759/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0133 - acc: 0.9951 - recall: 0.4314 - fbeta_score: 0.4359 - val_loss: 0.3029 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 760/1000\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.0214 - acc: 0.9929 - recall: 0.3898 - fbeta_score: 0.3939 - val_loss: 0.2403 - val_acc: 0.9659 - val_recall: 0.3659 - val_fbeta_score: 0.3577\n",
      "Epoch 761/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0155 - acc: 0.9924 - recall: 0.4151 - fbeta_score: 0.4160 - val_loss: 0.2802 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 762/1000\n",
      "1843/1843 [==============================] - 0s 202us/step - loss: 0.0203 - acc: 0.9902 - recall: 0.3889 - fbeta_score: 0.3885 - val_loss: 0.2813 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 763/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0167 - acc: 0.9929 - recall: 0.4115 - fbeta_score: 0.4138 - val_loss: 0.2789 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 764/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0184 - acc: 0.9935 - recall: 0.3852 - fbeta_score: 0.3871 - val_loss: 0.2677 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 765/1000\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.0151 - acc: 0.9929 - recall: 0.3789 - fbeta_score: 0.3847 - val_loss: 0.2387 - val_acc: 0.9610 - val_recall: 0.2927 - val_fbeta_score: 0.2927\n",
      "Epoch 766/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0163 - acc: 0.9940 - recall: 0.4250 - fbeta_score: 0.4265 - val_loss: 0.2764 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 767/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0138 - acc: 0.9935 - recall: 0.3970 - fbeta_score: 0.3968 - val_loss: 0.2278 - val_acc: 0.9610 - val_recall: 0.2927 - val_fbeta_score: 0.2927\n",
      "Epoch 768/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0135 - acc: 0.9951 - recall: 0.4060 - fbeta_score: 0.4084 - val_loss: 0.2501 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 769/1000\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.0230 - acc: 0.9935 - recall: 0.4018 - fbeta_score: 0.4042 - val_loss: 0.2460 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 770/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0075 - acc: 0.9973 - recall: 0.4187 - fbeta_score: 0.4185 - val_loss: 0.2438 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 771/1000\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0186 - acc: 0.9929 - recall: 0.4042 - fbeta_score: 0.4104 - val_loss: 0.2157 - val_acc: 0.9610 - val_recall: 0.2927 - val_fbeta_score: 0.2927\n",
      "Epoch 772/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0105 - acc: 0.9946 - recall: 0.4323 - fbeta_score: 0.4348 - val_loss: 0.2323 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 773/1000\n",
      "1843/1843 [==============================] - 0s 201us/step - loss: 0.0134 - acc: 0.9973 - recall: 0.4133 - fbeta_score: 0.4131 - val_loss: 0.2432 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 774/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0137 - acc: 0.9967 - recall: 0.4113 - fbeta_score: 0.4140 - val_loss: 0.2410 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 775/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0121 - acc: 0.9946 - recall: 0.4050 - fbeta_score: 0.4064 - val_loss: 0.2355 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 776/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0108 - acc: 0.9978 - recall: 0.4201 - fbeta_score: 0.4232 - val_loss: 0.2497 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 777/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0065 - acc: 0.9973 - recall: 0.3997 - fbeta_score: 0.4022 - val_loss: 0.2506 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 778/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0145 - acc: 0.9951 - recall: 0.4173 - fbeta_score: 0.4177 - val_loss: 0.2573 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 779/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0130 - acc: 0.9951 - recall: 0.3572 - fbeta_score: 0.3614 - val_loss: 0.2632 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 780/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0085 - acc: 0.9973 - recall: 0.4106 - fbeta_score: 0.4131 - val_loss: 0.2550 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 781/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0112 - acc: 0.9962 - recall: 0.4169 - fbeta_score: 0.4187 - val_loss: 0.2291 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 782/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0098 - acc: 0.9967 - recall: 0.4095 - fbeta_score: 0.4111 - val_loss: 0.2569 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 783/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0130 - acc: 0.9946 - recall: 0.4214 - fbeta_score: 0.4232 - val_loss: 0.2881 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 784/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0081 - acc: 0.9984 - recall: 0.3934 - fbeta_score: 0.3943 - val_loss: 0.2373 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 785/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0092 - acc: 0.9957 - recall: 0.4475 - fbeta_score: 0.4491 - val_loss: 0.2653 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 786/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0059 - acc: 0.9984 - recall: 0.4178 - fbeta_score: 0.4178 - val_loss: 0.2546 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 787/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0061 - acc: 0.9989 - recall: 0.4268 - fbeta_score: 0.4276 - val_loss: 0.2532 - val_acc: 0.9659 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 788/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0054 - acc: 0.9989 - recall: 0.4377 - fbeta_score: 0.4384 - val_loss: 0.2574 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 789/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0096 - acc: 0.9973 - recall: 0.4097 - fbeta_score: 0.4124 - val_loss: 0.2391 - val_acc: 0.9659 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 790/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0052 - acc: 0.9984 - recall: 0.4124 - fbeta_score: 0.4124 - val_loss: 0.2675 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 791/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0080 - acc: 0.9973 - recall: 0.3974 - fbeta_score: 0.3989 - val_loss: 0.2761 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 792/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0052 - acc: 0.9984 - recall: 0.4106 - fbeta_score: 0.4095 - val_loss: 0.2498 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 793/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0116 - acc: 0.9957 - recall: 0.3923 - fbeta_score: 0.3959 - val_loss: 0.2433 - val_acc: 0.9659 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 794/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0080 - acc: 0.9973 - recall: 0.4422 - fbeta_score: 0.4431 - val_loss: 0.2606 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 795/1000\n",
      "1843/1843 [==============================] - 0s 202us/step - loss: 0.0120 - acc: 0.9957 - recall: 0.4088 - fbeta_score: 0.4102 - val_loss: 0.2895 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 796/1000\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0070 - acc: 0.9967 - recall: 0.4142 - fbeta_score: 0.4156 - val_loss: 0.2848 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 797/1000\n",
      "1843/1843 [==============================] - 0s 198us/step - loss: 0.0062 - acc: 0.9989 - recall: 0.4133 - fbeta_score: 0.4149 - val_loss: 0.2705 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 798/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0092 - acc: 0.9984 - recall: 0.4178 - fbeta_score: 0.4178 - val_loss: 0.3201 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 799/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0156 - acc: 0.9946 - recall: 0.4160 - fbeta_score: 0.4167 - val_loss: 0.2773 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 800/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0107 - acc: 0.9962 - recall: 0.3861 - fbeta_score: 0.3896 - val_loss: 0.2549 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 801/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0082 - acc: 0.9973 - recall: 0.4314 - fbeta_score: 0.4341 - val_loss: 0.2447 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 802/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0065 - acc: 0.9984 - recall: 0.4436 - fbeta_score: 0.4442 - val_loss: 0.2620 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 803/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0131 - acc: 0.9978 - recall: 0.4341 - fbeta_score: 0.4341 - val_loss: 0.2681 - val_acc: 0.9463 - val_recall: 0.3659 - val_fbeta_score: 0.3740\n",
      "Epoch 804/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0104 - acc: 0.9973 - recall: 0.4449 - fbeta_score: 0.4449 - val_loss: 0.3185 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 805/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0110 - acc: 0.9967 - recall: 0.4065 - fbeta_score: 0.4087 - val_loss: 0.2902 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 806/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0097 - acc: 0.9957 - recall: 0.3898 - fbeta_score: 0.3916 - val_loss: 0.3236 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 807/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0091 - acc: 0.9973 - recall: 0.4385 - fbeta_score: 0.4377 - val_loss: 0.2153 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 808/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0098 - acc: 0.9962 - recall: 0.4024 - fbeta_score: 0.4022 - val_loss: 0.2243 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 809/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0133 - acc: 0.9946 - recall: 0.4305 - fbeta_score: 0.4301 - val_loss: 0.2324 - val_acc: 0.9659 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 810/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0110 - acc: 0.9962 - recall: 0.4276 - fbeta_score: 0.4267 - val_loss: 0.2659 - val_acc: 0.9659 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 811/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0168 - acc: 0.9946 - recall: 0.4033 - fbeta_score: 0.4084 - val_loss: 0.2433 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 812/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0052 - acc: 0.9989 - recall: 0.4194 - fbeta_score: 0.4194 - val_loss: 0.2336 - val_acc: 0.9610 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 813/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0172 - acc: 0.9946 - recall: 0.3726 - fbeta_score: 0.3751 - val_loss: 0.2487 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 814/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0092 - acc: 0.9973 - recall: 0.4368 - fbeta_score: 0.4377 - val_loss: 0.2847 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 815/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0180 - acc: 0.9929 - recall: 0.4065 - fbeta_score: 0.4080 - val_loss: 0.3512 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 816/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0066 - acc: 0.9973 - recall: 0.4327 - fbeta_score: 0.4333 - val_loss: 0.2736 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 817/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0102 - acc: 0.9973 - recall: 0.4015 - fbeta_score: 0.4015 - val_loss: 0.3001 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 818/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0076 - acc: 0.9973 - recall: 0.4042 - fbeta_score: 0.4051 - val_loss: 0.2958 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 819/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0131 - acc: 0.9946 - recall: 0.3717 - fbeta_score: 0.3762 - val_loss: 0.3166 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 820/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0094 - acc: 0.9967 - recall: 0.4160 - fbeta_score: 0.4181 - val_loss: 0.2725 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 821/1000\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.0075 - acc: 0.9973 - recall: 0.3970 - fbeta_score: 0.3986 - val_loss: 0.2633 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 822/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0211 - acc: 0.9929 - recall: 0.3889 - fbeta_score: 0.3932 - val_loss: 0.2694 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 823/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0086 - acc: 0.9984 - recall: 0.4395 - fbeta_score: 0.4395 - val_loss: 0.4584 - val_acc: 0.9317 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 824/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0128 - acc: 0.9962 - recall: 0.3823 - fbeta_score: 0.3856 - val_loss: 0.3074 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 825/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0064 - acc: 0.9978 - recall: 0.3988 - fbeta_score: 0.3997 - val_loss: 0.2944 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 826/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0123 - acc: 0.9973 - recall: 0.3961 - fbeta_score: 0.3943 - val_loss: 0.2492 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 827/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0116 - acc: 0.9967 - recall: 0.3997 - fbeta_score: 0.4022 - val_loss: 0.2738 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 828/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0068 - acc: 0.9973 - recall: 0.4341 - fbeta_score: 0.4341 - val_loss: 0.2928 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 829/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0056 - acc: 0.9984 - recall: 0.4232 - fbeta_score: 0.4214 - val_loss: 0.2944 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 830/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0097 - acc: 0.9967 - recall: 0.4013 - fbeta_score: 0.4039 - val_loss: 0.2738 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 831/1000\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0058 - acc: 0.9984 - recall: 0.4285 - fbeta_score: 0.4292 - val_loss: 0.2879 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 832/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0097 - acc: 0.9973 - recall: 0.3925 - fbeta_score: 0.3939 - val_loss: 0.3083 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 833/1000\n",
      "1843/1843 [==============================] - 0s 201us/step - loss: 0.0110 - acc: 0.9962 - recall: 0.4187 - fbeta_score: 0.4203 - val_loss: 0.2408 - val_acc: 0.9610 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 834/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0050 - acc: 0.9989 - recall: 0.4140 - fbeta_score: 0.4140 - val_loss: 0.2991 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 835/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0123 - acc: 0.9967 - recall: 0.4110 - fbeta_score: 0.4127 - val_loss: 0.3086 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 836/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0097 - acc: 0.9967 - recall: 0.4194 - fbeta_score: 0.4158 - val_loss: 0.2598 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 837/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0102 - acc: 0.9962 - recall: 0.3861 - fbeta_score: 0.3878 - val_loss: 0.2418 - val_acc: 0.9512 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 838/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0078 - acc: 0.9962 - recall: 0.3920 - fbeta_score: 0.3935 - val_loss: 0.2740 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 839/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0050 - acc: 0.9984 - recall: 0.4214 - fbeta_score: 0.4221 - val_loss: 0.2970 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 840/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0110 - acc: 0.9957 - recall: 0.4201 - fbeta_score: 0.4196 - val_loss: 0.3086 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 841/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0093 - acc: 0.9984 - recall: 0.4133 - fbeta_score: 0.4149 - val_loss: 0.3029 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 842/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0109 - acc: 0.9973 - recall: 0.3816 - fbeta_score: 0.3849 - val_loss: 0.2831 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 843/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0058 - acc: 0.9978 - recall: 0.4232 - fbeta_score: 0.4232 - val_loss: 0.3220 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 844/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0069 - acc: 0.9967 - recall: 0.3825 - fbeta_score: 0.3856 - val_loss: 0.2746 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 845/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0063 - acc: 0.9978 - recall: 0.4060 - fbeta_score: 0.4084 - val_loss: 0.3054 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 846/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0176 - acc: 0.9940 - recall: 0.3767 - fbeta_score: 0.3816 - val_loss: 0.3045 - val_acc: 0.9561 - val_recall: 0.2927 - val_fbeta_score: 0.2927\n",
      "Epoch 847/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0107 - acc: 0.9946 - recall: 0.4268 - fbeta_score: 0.4294 - val_loss: 0.2641 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 848/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0139 - acc: 0.9946 - recall: 0.4164 - fbeta_score: 0.4188 - val_loss: 0.2712 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 849/1000\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.0128 - acc: 0.9967 - recall: 0.3858 - fbeta_score: 0.3857 - val_loss: 0.2189 - val_acc: 0.9512 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 850/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0121 - acc: 0.9946 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2964 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 851/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0175 - acc: 0.9946 - recall: 0.3760 - fbeta_score: 0.3796 - val_loss: 0.2949 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 852/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0079 - acc: 0.9978 - recall: 0.4431 - fbeta_score: 0.4438 - val_loss: 0.2812 - val_acc: 0.9415 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 853/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0133 - acc: 0.9951 - recall: 0.4060 - fbeta_score: 0.4084 - val_loss: 0.2820 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 854/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0079 - acc: 0.9989 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2652 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 855/1000\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.0055 - acc: 0.9978 - recall: 0.4314 - fbeta_score: 0.4323 - val_loss: 0.2700 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 856/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0146 - acc: 0.9962 - recall: 0.4097 - fbeta_score: 0.4122 - val_loss: 0.2920 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 857/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0117 - acc: 0.9962 - recall: 0.3907 - fbeta_score: 0.3928 - val_loss: 0.2772 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 858/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0100 - acc: 0.9984 - recall: 0.4106 - fbeta_score: 0.4113 - val_loss: 0.2564 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 859/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0108 - acc: 0.9962 - recall: 0.4377 - fbeta_score: 0.4402 - val_loss: 0.2990 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 860/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0101 - acc: 0.9978 - recall: 0.4069 - fbeta_score: 0.4088 - val_loss: 0.2987 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 861/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0125 - acc: 0.9946 - recall: 0.4214 - fbeta_score: 0.4239 - val_loss: 0.2670 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 862/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0144 - acc: 0.9957 - recall: 0.4273 - fbeta_score: 0.4300 - val_loss: 0.2641 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 863/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0058 - acc: 0.9984 - recall: 0.3843 - fbeta_score: 0.3867 - val_loss: 0.2768 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 864/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0151 - acc: 0.9951 - recall: 0.3979 - fbeta_score: 0.3993 - val_loss: 0.2747 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 865/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0070 - acc: 0.9973 - recall: 0.3889 - fbeta_score: 0.3914 - val_loss: 0.2720 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 866/1000\n",
      "1843/1843 [==============================] - 0s 197us/step - loss: 0.0096 - acc: 0.9967 - recall: 0.4133 - fbeta_score: 0.4131 - val_loss: 0.2876 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 867/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0098 - acc: 0.9967 - recall: 0.4069 - fbeta_score: 0.4104 - val_loss: 0.3048 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 868/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0079 - acc: 0.9967 - recall: 0.3789 - fbeta_score: 0.3831 - val_loss: 0.2234 - val_acc: 0.9659 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 869/1000\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0114 - acc: 0.9957 - recall: 0.4449 - fbeta_score: 0.4467 - val_loss: 0.2945 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 870/1000\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0058 - acc: 0.9984 - recall: 0.4124 - fbeta_score: 0.4124 - val_loss: 0.2995 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 871/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0131 - acc: 0.9957 - recall: 0.4106 - fbeta_score: 0.4149 - val_loss: 0.2564 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 872/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0063 - acc: 0.9984 - recall: 0.4024 - fbeta_score: 0.4041 - val_loss: 0.2941 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 873/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0071 - acc: 0.9984 - recall: 0.4368 - fbeta_score: 0.4359 - val_loss: 0.2874 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 874/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0143 - acc: 0.9957 - recall: 0.4192 - fbeta_score: 0.4206 - val_loss: 0.2518 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 875/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0042 - acc: 0.9989 - recall: 0.4051 - fbeta_score: 0.4059 - val_loss: 0.2623 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 876/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0098 - acc: 0.9957 - recall: 0.3871 - fbeta_score: 0.3903 - val_loss: 0.2465 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 877/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0128 - acc: 0.9946 - recall: 0.4296 - fbeta_score: 0.4294 - val_loss: 0.2063 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 878/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0118 - acc: 0.9951 - recall: 0.4051 - fbeta_score: 0.4059 - val_loss: 0.2514 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 879/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0038 - acc: 0.9989 - recall: 0.4384 - fbeta_score: 0.4393 - val_loss: 0.2658 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 880/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0081 - acc: 0.9973 - recall: 0.4015 - fbeta_score: 0.4033 - val_loss: 0.2399 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 881/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0175 - acc: 0.9951 - recall: 0.3861 - fbeta_score: 0.3860 - val_loss: 0.2413 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 882/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0084 - acc: 0.9967 - recall: 0.3916 - fbeta_score: 0.3914 - val_loss: 0.2457 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 883/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0062 - acc: 0.9973 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2848 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 884/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0043 - acc: 0.9989 - recall: 0.4042 - fbeta_score: 0.4051 - val_loss: 0.2293 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 885/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0047 - acc: 0.9989 - recall: 0.4232 - fbeta_score: 0.4232 - val_loss: 0.2315 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 886/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0053 - acc: 0.9984 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2914 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 887/1000\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.0048 - acc: 0.9984 - recall: 0.4558 - fbeta_score: 0.4576 - val_loss: 0.2850 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 888/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0061 - acc: 0.9984 - recall: 0.3798 - fbeta_score: 0.3816 - val_loss: 0.2809 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 889/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0066 - acc: 0.9973 - recall: 0.4232 - fbeta_score: 0.4236 - val_loss: 0.2407 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 890/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0048 - acc: 0.9978 - recall: 0.4395 - fbeta_score: 0.4377 - val_loss: 0.2925 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 891/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0107 - acc: 0.9962 - recall: 0.3950 - fbeta_score: 0.3977 - val_loss: 0.2498 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 892/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0029 - acc: 1.0000 - recall: 0.4341 - fbeta_score: 0.4341 - val_loss: 0.2395 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 893/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0106 - acc: 0.9962 - recall: 0.4140 - fbeta_score: 0.4162 - val_loss: 0.2669 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 894/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0136 - acc: 0.9967 - recall: 0.4429 - fbeta_score: 0.4438 - val_loss: 0.2080 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 895/1000\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.0142 - acc: 0.9951 - recall: 0.4124 - fbeta_score: 0.4106 - val_loss: 0.3520 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 896/1000\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.0278 - acc: 0.9913 - recall: 0.3676 - fbeta_score: 0.3700 - val_loss: 0.2381 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 897/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0080 - acc: 0.9973 - recall: 0.3907 - fbeta_score: 0.3907 - val_loss: 0.2381 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 898/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0184 - acc: 0.9935 - recall: 0.3685 - fbeta_score: 0.3717 - val_loss: 0.2197 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 899/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0131 - acc: 0.9951 - recall: 0.4160 - fbeta_score: 0.4167 - val_loss: 0.2813 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 900/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0105 - acc: 0.9962 - recall: 0.4015 - fbeta_score: 0.4033 - val_loss: 0.2927 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0129 - acc: 0.9957 - recall: 0.4259 - fbeta_score: 0.4250 - val_loss: 0.2468 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 902/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0097 - acc: 0.9962 - recall: 0.4024 - fbeta_score: 0.4041 - val_loss: 0.2321 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 903/1000\n",
      "1843/1843 [==============================] - 0s 200us/step - loss: 0.0091 - acc: 0.9973 - recall: 0.4178 - fbeta_score: 0.4178 - val_loss: 0.2720 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 904/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0124 - acc: 0.9962 - recall: 0.4042 - fbeta_score: 0.4033 - val_loss: 0.2360 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 905/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0180 - acc: 0.9929 - recall: 0.3925 - fbeta_score: 0.3939 - val_loss: 0.2890 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 906/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0161 - acc: 0.9935 - recall: 0.3961 - fbeta_score: 0.3997 - val_loss: 0.2788 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 907/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0186 - acc: 0.9946 - recall: 0.3870 - fbeta_score: 0.3907 - val_loss: 0.2620 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.1951\n",
      "Epoch 908/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0225 - acc: 0.9924 - recall: 0.3988 - fbeta_score: 0.4037 - val_loss: 0.2651 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 909/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0143 - acc: 0.9946 - recall: 0.4232 - fbeta_score: 0.4232 - val_loss: 0.2983 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 910/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0139 - acc: 0.9962 - recall: 0.4060 - fbeta_score: 0.4084 - val_loss: 0.2967 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 911/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0156 - acc: 0.9940 - recall: 0.3843 - fbeta_score: 0.3867 - val_loss: 0.2406 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 912/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0061 - acc: 0.9984 - recall: 0.3997 - fbeta_score: 0.4022 - val_loss: 0.2318 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 913/1000\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.0052 - acc: 0.9995 - recall: 0.4314 - fbeta_score: 0.4323 - val_loss: 0.2805 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 914/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0081 - acc: 0.9973 - recall: 0.4268 - fbeta_score: 0.4294 - val_loss: 0.2715 - val_acc: 0.9366 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 915/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0073 - acc: 0.9973 - recall: 0.4115 - fbeta_score: 0.4138 - val_loss: 0.2280 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 916/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0091 - acc: 0.9973 - recall: 0.4015 - fbeta_score: 0.4033 - val_loss: 0.2226 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 917/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0108 - acc: 0.9962 - recall: 0.3771 - fbeta_score: 0.3798 - val_loss: 0.3987 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 918/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0230 - acc: 0.9940 - recall: 0.3609 - fbeta_score: 0.3633 - val_loss: 0.2564 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 919/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0092 - acc: 0.9962 - recall: 0.4151 - fbeta_score: 0.4142 - val_loss: 0.2902 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 920/1000\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.0070 - acc: 0.9978 - recall: 0.4083 - fbeta_score: 0.4116 - val_loss: 0.2444 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 921/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0238 - acc: 0.9962 - recall: 0.3699 - fbeta_score: 0.3715 - val_loss: 0.3618 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 922/1000\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.0103 - acc: 0.9951 - recall: 0.4151 - fbeta_score: 0.4142 - val_loss: 0.2738 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 923/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0077 - acc: 0.9973 - recall: 0.4069 - fbeta_score: 0.4088 - val_loss: 0.2408 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 924/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0069 - acc: 0.9978 - recall: 0.4339 - fbeta_score: 0.4364 - val_loss: 0.2656 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 925/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0076 - acc: 0.9984 - recall: 0.3608 - fbeta_score: 0.3620 - val_loss: 0.2520 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 926/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0066 - acc: 0.9984 - recall: 0.3988 - fbeta_score: 0.4015 - val_loss: 0.2452 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 927/1000\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.0116 - acc: 0.9957 - recall: 0.4160 - fbeta_score: 0.4165 - val_loss: 0.3743 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 928/1000\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.0105 - acc: 0.9962 - recall: 0.4151 - fbeta_score: 0.4160 - val_loss: 0.3032 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 929/1000\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.0055 - acc: 0.9984 - recall: 0.4531 - fbeta_score: 0.4540 - val_loss: 0.2670 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 930/1000\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.0151 - acc: 0.9935 - recall: 0.3852 - fbeta_score: 0.3874 - val_loss: 0.3154 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 931/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0149 - acc: 0.9946 - recall: 0.3977 - fbeta_score: 0.4013 - val_loss: 0.2731 - val_acc: 0.9463 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 932/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0111 - acc: 0.9973 - recall: 0.4137 - fbeta_score: 0.4134 - val_loss: 0.2666 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 933/1000\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.0111 - acc: 0.9967 - recall: 0.3979 - fbeta_score: 0.3993 - val_loss: 0.2756 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 934/1000\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.0110 - acc: 0.9951 - recall: 0.4178 - fbeta_score: 0.4196 - val_loss: 0.2393 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 935/1000\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.0074 - acc: 0.9973 - recall: 0.4151 - fbeta_score: 0.4160 - val_loss: 0.2535 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 936/1000\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.0045 - acc: 0.9995 - recall: 0.4314 - fbeta_score: 0.4323 - val_loss: 0.2581 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.0109 - acc: 0.9967 - recall: 0.4133 - fbeta_score: 0.4149 - val_loss: 0.2816 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 938/1000\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.0115 - acc: 0.9957 - recall: 0.4104 - fbeta_score: 0.4118 - val_loss: 0.2265 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 939/1000\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.0119 - acc: 0.9940 - recall: 0.3934 - fbeta_score: 0.3959 - val_loss: 0.3029 - val_acc: 0.9268 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 940/1000\n",
      "1843/1843 [==============================] - 1s 323us/step - loss: 0.0126 - acc: 0.9940 - recall: 0.3861 - fbeta_score: 0.3878 - val_loss: 0.2323 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 941/1000\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.0130 - acc: 0.9962 - recall: 0.4178 - fbeta_score: 0.4196 - val_loss: 0.2488 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 942/1000\n",
      "1843/1843 [==============================] - 1s 272us/step - loss: 0.0134 - acc: 0.9957 - recall: 0.4133 - fbeta_score: 0.4149 - val_loss: 0.2557 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 943/1000\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.0070 - acc: 0.9973 - recall: 0.4246 - fbeta_score: 0.4261 - val_loss: 0.2687 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 944/1000\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.0059 - acc: 0.9984 - recall: 0.4069 - fbeta_score: 0.4088 - val_loss: 0.2642 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 945/1000\n",
      "1843/1843 [==============================] - 1s 287us/step - loss: 0.0065 - acc: 0.9978 - recall: 0.4187 - fbeta_score: 0.4185 - val_loss: 0.3011 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 946/1000\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.0121 - acc: 0.9946 - recall: 0.3843 - fbeta_score: 0.3885 - val_loss: 0.2546 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 947/1000\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.0032 - acc: 1.0000 - recall: 0.4124 - fbeta_score: 0.4124 - val_loss: 0.2531 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 948/1000\n",
      "1843/1843 [==============================] - 1s 302us/step - loss: 0.0093 - acc: 0.9967 - recall: 0.4404 - fbeta_score: 0.4384 - val_loss: 0.2923 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 949/1000\n",
      "1843/1843 [==============================] - 0s 262us/step - loss: 0.0057 - acc: 0.9984 - recall: 0.3812 - fbeta_score: 0.3827 - val_loss: 0.2897 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 950/1000\n",
      "1843/1843 [==============================] - 0s 268us/step - loss: 0.0063 - acc: 0.9978 - recall: 0.3889 - fbeta_score: 0.3914 - val_loss: 0.2944 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 951/1000\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.0065 - acc: 0.9967 - recall: 0.3871 - fbeta_score: 0.3903 - val_loss: 0.2430 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 952/1000\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.0081 - acc: 0.9973 - recall: 0.3889 - fbeta_score: 0.3914 - val_loss: 0.2521 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 953/1000\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.0050 - acc: 0.9978 - recall: 0.4341 - fbeta_score: 0.4359 - val_loss: 0.2844 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 954/1000\n",
      "1843/1843 [==============================] - 1s 274us/step - loss: 0.0035 - acc: 0.9995 - recall: 0.4504 - fbeta_score: 0.4504 - val_loss: 0.2542 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 955/1000\n",
      "1843/1843 [==============================] - 1s 300us/step - loss: 0.0118 - acc: 0.9957 - recall: 0.3916 - fbeta_score: 0.3950 - val_loss: 0.3547 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 956/1000\n",
      "1843/1843 [==============================] - 1s 368us/step - loss: 0.0077 - acc: 0.9978 - recall: 0.4323 - fbeta_score: 0.4330 - val_loss: 0.2586 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 957/1000\n",
      "1843/1843 [==============================] - 0s 252us/step - loss: 0.0119 - acc: 0.9973 - recall: 0.4404 - fbeta_score: 0.4420 - val_loss: 0.3134 - val_acc: 0.9317 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 958/1000\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.0125 - acc: 0.9957 - recall: 0.3974 - fbeta_score: 0.3989 - val_loss: 0.3096 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 959/1000\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.0075 - acc: 0.9984 - recall: 0.4368 - fbeta_score: 0.4377 - val_loss: 0.2598 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 960/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0086 - acc: 0.9978 - recall: 0.3997 - fbeta_score: 0.4022 - val_loss: 0.3240 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 961/1000\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.0105 - acc: 0.9962 - recall: 0.4133 - fbeta_score: 0.4131 - val_loss: 0.3426 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 962/1000\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0097 - acc: 0.9962 - recall: 0.4341 - fbeta_score: 0.4359 - val_loss: 0.3093 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 963/1000\n",
      "1843/1843 [==============================] - 1s 339us/step - loss: 0.0166 - acc: 0.9978 - recall: 0.4088 - fbeta_score: 0.4097 - val_loss: 0.3935 - val_acc: 0.9268 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 964/1000\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.0249 - acc: 0.9924 - recall: 0.4088 - fbeta_score: 0.4138 - val_loss: 0.3270 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 965/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0102 - acc: 0.9962 - recall: 0.4042 - fbeta_score: 0.4069 - val_loss: 0.2386 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 966/1000\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.0067 - acc: 0.9984 - recall: 0.4259 - fbeta_score: 0.4268 - val_loss: 0.2894 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 967/1000\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.0083 - acc: 0.9973 - recall: 0.4106 - fbeta_score: 0.4095 - val_loss: 0.2697 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 968/1000\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.0171 - acc: 0.9957 - recall: 0.3926 - fbeta_score: 0.3958 - val_loss: 0.2310 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 969/1000\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.0099 - acc: 0.9967 - recall: 0.4160 - fbeta_score: 0.4113 - val_loss: 0.2505 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 970/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0084 - acc: 0.9978 - recall: 0.4002 - fbeta_score: 0.4007 - val_loss: 0.2536 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 971/1000\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.0140 - acc: 0.9962 - recall: 0.4350 - fbeta_score: 0.4366 - val_loss: 0.1561 - val_acc: 0.9659 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 972/1000\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.0122 - acc: 0.9951 - recall: 0.3679 - fbeta_score: 0.3706 - val_loss: 0.2139 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 973/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0105 - acc: 0.9962 - recall: 0.4106 - fbeta_score: 0.4131 - val_loss: 0.2480 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 974/1000\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.0119 - acc: 0.9957 - recall: 0.4160 - fbeta_score: 0.4167 - val_loss: 0.2617 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 975/1000\n",
      "1843/1843 [==============================] - 0s 203us/step - loss: 0.0089 - acc: 0.9967 - recall: 0.4368 - fbeta_score: 0.4377 - val_loss: 0.3113 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 976/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0096 - acc: 0.9973 - recall: 0.4327 - fbeta_score: 0.4333 - val_loss: 0.3057 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 977/1000\n",
      "1843/1843 [==============================] - 0s 201us/step - loss: 0.0072 - acc: 0.9978 - recall: 0.4368 - fbeta_score: 0.4377 - val_loss: 0.2932 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 978/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0098 - acc: 0.9973 - recall: 0.4033 - fbeta_score: 0.4066 - val_loss: 0.2821 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 979/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0066 - acc: 0.9973 - recall: 0.4232 - fbeta_score: 0.4250 - val_loss: 0.2659 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 980/1000\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.0087 - acc: 0.9973 - recall: 0.4305 - fbeta_score: 0.4301 - val_loss: 0.2458 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 981/1000\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0027 - acc: 0.9995 - recall: 0.4069 - fbeta_score: 0.4069 - val_loss: 0.2947 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 982/1000\n",
      "1843/1843 [==============================] - 0s 261us/step - loss: 0.0061 - acc: 0.9978 - recall: 0.4178 - fbeta_score: 0.4196 - val_loss: 0.2918 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 983/1000\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.0064 - acc: 0.9973 - recall: 0.3946 - fbeta_score: 0.3977 - val_loss: 0.2618 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 984/1000\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.0085 - acc: 0.9967 - recall: 0.3979 - fbeta_score: 0.4012 - val_loss: 0.2744 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 985/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0070 - acc: 0.9984 - recall: 0.4205 - fbeta_score: 0.4214 - val_loss: 0.2392 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 986/1000\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.0085 - acc: 0.9973 - recall: 0.4368 - fbeta_score: 0.4359 - val_loss: 0.3423 - val_acc: 0.9317 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 987/1000\n",
      "1843/1843 [==============================] - 0s 202us/step - loss: 0.0075 - acc: 0.9967 - recall: 0.4106 - fbeta_score: 0.4131 - val_loss: 0.2700 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 988/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0058 - acc: 0.9984 - recall: 0.4504 - fbeta_score: 0.4504 - val_loss: 0.3131 - val_acc: 0.9463 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 989/1000\n",
      "1843/1843 [==============================] - 0s 196us/step - loss: 0.0046 - acc: 0.9984 - recall: 0.4024 - fbeta_score: 0.4041 - val_loss: 0.3065 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 990/1000\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.0091 - acc: 0.9978 - recall: 0.4137 - fbeta_score: 0.4152 - val_loss: 0.2832 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 991/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 0.9984 - recall: 0.3970 - fbeta_score: 0.3986 - val_loss: 0.2839 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 992/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0059 - acc: 0.9984 - recall: 0.4137 - fbeta_score: 0.4152 - val_loss: 0.2619 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 993/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0062 - acc: 0.9978 - recall: 0.4124 - fbeta_score: 0.4124 - val_loss: 0.2731 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 994/1000\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.0049 - acc: 0.9984 - recall: 0.4214 - fbeta_score: 0.4221 - val_loss: 0.2728 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 995/1000\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.0094 - acc: 0.9967 - recall: 0.4219 - fbeta_score: 0.4243 - val_loss: 0.2416 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 996/1000\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.0054 - acc: 0.9989 - recall: 0.4368 - fbeta_score: 0.4377 - val_loss: 0.2648 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 997/1000\n",
      "1843/1843 [==============================] - 0s 207us/step - loss: 0.0019 - acc: 1.0000 - recall: 0.4504 - fbeta_score: 0.4504 - val_loss: 0.2672 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 998/1000\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.0073 - acc: 0.9973 - recall: 0.4042 - fbeta_score: 0.4051 - val_loss: 0.2424 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 999/1000\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.0099 - acc: 0.9962 - recall: 0.3929 - fbeta_score: 0.3942 - val_loss: 0.2904 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 1000/1000\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.0072 - acc: 0.9984 - recall: 0.4205 - fbeta_score: 0.4178 - val_loss: 0.2740 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19164b6fb00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.fit(X_scale_train, y_train,\n",
    "                epochs=1000,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_split=0.1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               2400      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 34,401\n",
      "Trainable params: 33,601\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El hacer una red más compleja da unos resultados similares en Accuracy, y algo mejores en recall. El modelo sobre-entrena por el uso de varias capas internas\n",
    "\n",
    "Vamos a probar estas redes con regularización para ver si hay mejoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Capa Regularización l2 (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4))\n",
    "\n",
    "#l=0.007\n",
    "l=0.01\n",
    "\n",
    "x = Input(shape=(23,))\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(l))(x)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(l))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(l))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(l))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "y = Dense(1, activation='sigmoid',kernel_initializer='he_uniform')(layer)\n",
    "mlp3 = Model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp3.compile(optimizer='sgd',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', recall, fbeta_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1843 samples, validate on 205 samples\n",
      "Epoch 1/500\n",
      "1843/1843 [==============================] - 2s 920us/step - loss: 8.2841 - acc: 0.8020 - recall: 0.0733 - fbeta_score: 0.0517 - val_loss: 7.8274 - val_acc: 0.9220 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 7.4933 - acc: 0.9398 - recall: 0.0651 - fbeta_score: 0.0705 - val_loss: 7.2167 - val_acc: 0.9268 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 3/500\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 6.9144 - acc: 0.9485 - recall: 0.0778 - fbeta_score: 0.0841 - val_loss: 6.6807 - val_acc: 0.9317 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 6.4111 - acc: 0.9501 - recall: 0.0922 - fbeta_score: 0.0977 - val_loss: 6.1968 - val_acc: 0.9317 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 5/500\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 5.9507 - acc: 0.9517 - recall: 0.1167 - fbeta_score: 0.1167 - val_loss: 5.7806 - val_acc: 0.9268 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 6/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 5.5317 - acc: 0.9555 - recall: 0.1465 - fbeta_score: 0.1492 - val_loss: 5.3855 - val_acc: 0.9317 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 7/500\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 5.1378 - acc: 0.9598 - recall: 0.1524 - fbeta_score: 0.1604 - val_loss: 4.9998 - val_acc: 0.9366 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 8/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 4.7759 - acc: 0.9593 - recall: 0.1592 - fbeta_score: 0.1655 - val_loss: 4.6522 - val_acc: 0.9366 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 9/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 4.4333 - acc: 0.9615 - recall: 0.1745 - fbeta_score: 0.1809 - val_loss: 4.3322 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 10/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 4.1197 - acc: 0.9685 - recall: 0.2496 - fbeta_score: 0.2568 - val_loss: 4.0478 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 11/500\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 3.8458 - acc: 0.9642 - recall: 0.2198 - fbeta_score: 0.2243 - val_loss: 3.7764 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 12/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 3.5751 - acc: 0.9626 - recall: 0.2270 - fbeta_score: 0.2288 - val_loss: 3.5186 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 13/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 3.3233 - acc: 0.9631 - recall: 0.2089 - fbeta_score: 0.2116 - val_loss: 3.2970 - val_acc: 0.9366 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 14/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 3.0937 - acc: 0.9636 - recall: 0.2198 - fbeta_score: 0.2250 - val_loss: 3.0585 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 15/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 2.8815 - acc: 0.9658 - recall: 0.2415 - fbeta_score: 0.2494 - val_loss: 2.8581 - val_acc: 0.9415 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 16/500\n",
      "1843/1843 [==============================] - 0s 254us/step - loss: 2.6832 - acc: 0.9577 - recall: 0.1863 - fbeta_score: 0.1926 - val_loss: 2.6900 - val_acc: 0.9366 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 17/500\n",
      "1843/1843 [==============================] - 0s 266us/step - loss: 2.4922 - acc: 0.9702 - recall: 0.2604 - fbeta_score: 0.2641 - val_loss: 2.5129 - val_acc: 0.9317 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 18/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 2.3156 - acc: 0.9723 - recall: 0.2894 - fbeta_score: 0.2957 - val_loss: 2.3320 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 19/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 2.1624 - acc: 0.9669 - recall: 0.2387 - fbeta_score: 0.2415 - val_loss: 2.2295 - val_acc: 0.9317 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 20/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 2.0182 - acc: 0.9669 - recall: 0.2613 - fbeta_score: 0.2641 - val_loss: 2.0936 - val_acc: 0.9317 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 21/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 1.8916 - acc: 0.9664 - recall: 0.2523 - fbeta_score: 0.2586 - val_loss: 1.9720 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 22/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 1.7560 - acc: 0.9696 - recall: 0.2650 - fbeta_score: 0.2722 - val_loss: 1.7728 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 23/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 1.6502 - acc: 0.9626 - recall: 0.2297 - fbeta_score: 0.2351 - val_loss: 1.6999 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 24/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 1.5371 - acc: 0.9707 - recall: 0.2491 - fbeta_score: 0.2577 - val_loss: 1.6123 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 25/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 1.4386 - acc: 0.9653 - recall: 0.2161 - fbeta_score: 0.2243 - val_loss: 1.4877 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 26/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 1.3439 - acc: 0.9718 - recall: 0.2623 - fbeta_score: 0.2700 - val_loss: 1.3791 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 27/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 1.2642 - acc: 0.9615 - recall: 0.2080 - fbeta_score: 0.2149 - val_loss: 1.3075 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 28/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 1.1702 - acc: 0.9712 - recall: 0.2424 - fbeta_score: 0.2514 - val_loss: 1.2388 - val_acc: 0.9415 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 29/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 1.1031 - acc: 0.9669 - recall: 0.2623 - fbeta_score: 0.2630 - val_loss: 1.2127 - val_acc: 0.9220 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 30/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 1.0351 - acc: 0.9658 - recall: 0.2333 - fbeta_score: 0.2415 - val_loss: 1.1195 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 31/500\n",
      "1843/1843 [==============================] - 0s 255us/step - loss: 0.9686 - acc: 0.9658 - recall: 0.2378 - fbeta_score: 0.2478 - val_loss: 1.0149 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 32/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.9112 - acc: 0.9674 - recall: 0.2812 - fbeta_score: 0.2903 - val_loss: 0.9792 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 33/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.8606 - acc: 0.9631 - recall: 0.2315 - fbeta_score: 0.2378 - val_loss: 0.9628 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 34/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.8155 - acc: 0.9642 - recall: 0.2044 - fbeta_score: 0.2105 - val_loss: 0.8606 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 35/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.7661 - acc: 0.9626 - recall: 0.2234 - fbeta_score: 0.2322 - val_loss: 0.8492 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 36/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.7152 - acc: 0.9653 - recall: 0.2460 - fbeta_score: 0.2523 - val_loss: 0.7963 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.6691 - acc: 0.9664 - recall: 0.2351 - fbeta_score: 0.2451 - val_loss: 0.8144 - val_acc: 0.9220 - val_recall: 0.3902 - val_fbeta_score: 0.3659\n",
      "Epoch 38/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.6501 - acc: 0.9577 - recall: 0.2234 - fbeta_score: 0.2279 - val_loss: 0.8524 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 39/500\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.6370 - acc: 0.9550 - recall: 0.1506 - fbeta_score: 0.1602 - val_loss: 0.6906 - val_acc: 0.9415 - val_recall: 0.1707 - val_fbeta_score: 0.1626\n",
      "Epoch 40/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.5882 - acc: 0.9620 - recall: 0.2261 - fbeta_score: 0.2351 - val_loss: 0.6532 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 41/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.5559 - acc: 0.9615 - recall: 0.2297 - fbeta_score: 0.2351 - val_loss: 0.6153 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 42/500\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.5178 - acc: 0.9647 - recall: 0.2170 - fbeta_score: 0.2292 - val_loss: 0.5937 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 43/500\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.4932 - acc: 0.9647 - recall: 0.2387 - fbeta_score: 0.2460 - val_loss: 0.6910 - val_acc: 0.8976 - val_recall: 0.4390 - val_fbeta_score: 0.3431\n",
      "Epoch 44/500\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.4897 - acc: 0.9598 - recall: 0.2179 - fbeta_score: 0.2204 - val_loss: 0.5748 - val_acc: 0.9366 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 45/500\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.4600 - acc: 0.9631 - recall: 0.2428 - fbeta_score: 0.2481 - val_loss: 0.5733 - val_acc: 0.9463 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 46/500\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.4438 - acc: 0.9609 - recall: 0.2170 - fbeta_score: 0.2187 - val_loss: 0.4940 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 47/500\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.4273 - acc: 0.9533 - recall: 0.1876 - fbeta_score: 0.1984 - val_loss: 0.4524 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 48/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.3975 - acc: 0.9626 - recall: 0.2351 - fbeta_score: 0.2451 - val_loss: 0.4576 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 49/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.3786 - acc: 0.9696 - recall: 0.2568 - fbeta_score: 0.2632 - val_loss: 0.4462 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 50/500\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.3690 - acc: 0.9577 - recall: 0.1971 - fbeta_score: 0.2040 - val_loss: 0.7046 - val_acc: 0.9171 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 51/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.3673 - acc: 0.9593 - recall: 0.2178 - fbeta_score: 0.2183 - val_loss: 0.4014 - val_acc: 0.9610 - val_recall: 0.3659 - val_fbeta_score: 0.3740\n",
      "Epoch 52/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.3449 - acc: 0.9588 - recall: 0.2080 - fbeta_score: 0.2161 - val_loss: 0.4068 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 53/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.3286 - acc: 0.9593 - recall: 0.1881 - fbeta_score: 0.1890 - val_loss: 0.4433 - val_acc: 0.9122 - val_recall: 0.2683 - val_fbeta_score: 0.2228\n",
      "Epoch 54/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.3267 - acc: 0.9533 - recall: 0.1682 - fbeta_score: 0.1680 - val_loss: 0.3715 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 55/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.2981 - acc: 0.9620 - recall: 0.2044 - fbeta_score: 0.2098 - val_loss: 0.3818 - val_acc: 0.9366 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 56/500\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.2828 - acc: 0.9598 - recall: 0.2297 - fbeta_score: 0.2324 - val_loss: 0.3696 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 57/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.2750 - acc: 0.9680 - recall: 0.2559 - fbeta_score: 0.2630 - val_loss: 0.3201 - val_acc: 0.9561 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 58/500\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.2822 - acc: 0.9593 - recall: 0.2134 - fbeta_score: 0.2107 - val_loss: 0.3110 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 59/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.2659 - acc: 0.9598 - recall: 0.2053 - fbeta_score: 0.2044 - val_loss: 0.2908 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 60/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.2577 - acc: 0.9598 - recall: 0.1881 - fbeta_score: 0.1962 - val_loss: 0.3065 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 61/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.2403 - acc: 0.9664 - recall: 0.2295 - fbeta_score: 0.2366 - val_loss: 0.3358 - val_acc: 0.9317 - val_recall: 0.3659 - val_fbeta_score: 0.3496\n",
      "Epoch 62/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.2481 - acc: 0.9544 - recall: 0.1836 - fbeta_score: 0.1888 - val_loss: 0.2677 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 63/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.2334 - acc: 0.9604 - recall: 0.2109 - fbeta_score: 0.2196 - val_loss: 0.3741 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 64/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.2499 - acc: 0.9642 - recall: 0.2107 - fbeta_score: 0.2125 - val_loss: 0.3738 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 65/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.2228 - acc: 0.9582 - recall: 0.1999 - fbeta_score: 0.2087 - val_loss: 0.3163 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 66/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.2166 - acc: 0.9615 - recall: 0.2243 - fbeta_score: 0.2252 - val_loss: 0.2919 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 67/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.2312 - acc: 0.9544 - recall: 0.1447 - fbeta_score: 0.1501 - val_loss: 0.2953 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 68/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.2184 - acc: 0.9577 - recall: 0.2198 - fbeta_score: 0.2261 - val_loss: 0.2624 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 69/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1985 - acc: 0.9626 - recall: 0.2098 - fbeta_score: 0.2152 - val_loss: 0.2516 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 70/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.2043 - acc: 0.9620 - recall: 0.2107 - fbeta_score: 0.2179 - val_loss: 0.2392 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 71/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1909 - acc: 0.9615 - recall: 0.2143 - fbeta_score: 0.2223 - val_loss: 0.2793 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 72/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1960 - acc: 0.9615 - recall: 0.2062 - fbeta_score: 0.2098 - val_loss: 0.2384 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1915 - acc: 0.9593 - recall: 0.2225 - fbeta_score: 0.2225 - val_loss: 0.2297 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 74/500\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.1853 - acc: 0.9593 - recall: 0.2044 - fbeta_score: 0.2125 - val_loss: 0.2465 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 75/500\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.1902 - acc: 0.9560 - recall: 0.1908 - fbeta_score: 0.1953 - val_loss: 0.2223 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 76/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1718 - acc: 0.9604 - recall: 0.2270 - fbeta_score: 0.2342 - val_loss: 0.3041 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 77/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1860 - acc: 0.9550 - recall: 0.1673 - fbeta_score: 0.1745 - val_loss: 0.2098 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 78/500\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.1700 - acc: 0.9642 - recall: 0.2143 - fbeta_score: 0.2188 - val_loss: 0.2451 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 79/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.1869 - acc: 0.9539 - recall: 0.1637 - fbeta_score: 0.1680 - val_loss: 0.2247 - val_acc: 0.9366 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 80/500\n",
      "1843/1843 [==============================] - 0s 213us/step - loss: 0.1760 - acc: 0.9550 - recall: 0.1700 - fbeta_score: 0.1763 - val_loss: 0.2625 - val_acc: 0.9220 - val_recall: 0.3171 - val_fbeta_score: 0.2911\n",
      "Epoch 81/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.1786 - acc: 0.9566 - recall: 0.1863 - fbeta_score: 0.1908 - val_loss: 0.2383 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 82/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.1672 - acc: 0.9560 - recall: 0.1870 - fbeta_score: 0.1923 - val_loss: 0.2056 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 83/500\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.1634 - acc: 0.9571 - recall: 0.2044 - fbeta_score: 0.2069 - val_loss: 0.2416 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 84/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1578 - acc: 0.9604 - recall: 0.2170 - fbeta_score: 0.2223 - val_loss: 0.2426 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 85/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1628 - acc: 0.9588 - recall: 0.2044 - fbeta_score: 0.2116 - val_loss: 0.2364 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 86/500\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.1659 - acc: 0.9631 - recall: 0.2216 - fbeta_score: 0.2207 - val_loss: 0.1996 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 87/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1566 - acc: 0.9604 - recall: 0.2243 - fbeta_score: 0.2270 - val_loss: 0.2487 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 88/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1586 - acc: 0.9588 - recall: 0.1646 - fbeta_score: 0.1718 - val_loss: 0.2530 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 89/500\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.1734 - acc: 0.9555 - recall: 0.1791 - fbeta_score: 0.1845 - val_loss: 0.2110 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 90/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1634 - acc: 0.9604 - recall: 0.2080 - fbeta_score: 0.2141 - val_loss: 0.2142 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 91/500\n",
      "1843/1843 [==============================] - ETA: 0s - loss: 0.1528 - acc: 0.9599 - recall: 0.2051 - fbeta_score: 0.20 - 0s 216us/step - loss: 0.1519 - acc: 0.9604 - recall: 0.2080 - fbeta_score: 0.2107 - val_loss: 0.2243 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 92/500\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.1667 - acc: 0.9582 - recall: 0.1845 - fbeta_score: 0.1921 - val_loss: 0.2422 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 93/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1600 - acc: 0.9571 - recall: 0.1782 - fbeta_score: 0.1870 - val_loss: 0.2402 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 94/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1551 - acc: 0.9598 - recall: 0.2039 - fbeta_score: 0.2102 - val_loss: 0.2035 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 95/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1481 - acc: 0.9636 - recall: 0.2198 - fbeta_score: 0.2243 - val_loss: 0.2007 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 96/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1571 - acc: 0.9582 - recall: 0.1958 - fbeta_score: 0.2002 - val_loss: 0.2290 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 97/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1482 - acc: 0.9631 - recall: 0.1707 - fbeta_score: 0.1778 - val_loss: 0.1859 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 98/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1473 - acc: 0.9566 - recall: 0.1899 - fbeta_score: 0.1952 - val_loss: 0.1928 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 99/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1484 - acc: 0.9582 - recall: 0.1917 - fbeta_score: 0.1988 - val_loss: 0.1992 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 100/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1523 - acc: 0.9593 - recall: 0.1836 - fbeta_score: 0.1942 - val_loss: 0.2121 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 101/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1517 - acc: 0.9588 - recall: 0.1997 - fbeta_score: 0.2042 - val_loss: 0.2167 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 102/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1493 - acc: 0.9582 - recall: 0.2078 - fbeta_score: 0.2123 - val_loss: 0.1835 - val_acc: 0.9610 - val_recall: 0.3659 - val_fbeta_score: 0.3659\n",
      "Epoch 103/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1459 - acc: 0.9588 - recall: 0.2008 - fbeta_score: 0.2062 - val_loss: 0.1775 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 104/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1454 - acc: 0.9604 - recall: 0.2270 - fbeta_score: 0.2306 - val_loss: 0.2649 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 105/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1527 - acc: 0.9571 - recall: 0.1727 - fbeta_score: 0.1818 - val_loss: 0.2036 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 106/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1408 - acc: 0.9642 - recall: 0.2170 - fbeta_score: 0.2223 - val_loss: 0.1743 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 107/500\n",
      "1843/1843 [==============================] - 1s 280us/step - loss: 0.1489 - acc: 0.9577 - recall: 0.1705 - fbeta_score: 0.1812 - val_loss: 0.1997 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 108/500\n",
      "1843/1843 [==============================] - 1s 320us/step - loss: 0.1495 - acc: 0.9566 - recall: 0.1818 - fbeta_score: 0.1899 - val_loss: 0.2376 - val_acc: 0.9415 - val_recall: 0.2683 - val_fbeta_score: 0.2602\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 1s 280us/step - loss: 0.1745 - acc: 0.9528 - recall: 0.1610 - fbeta_score: 0.1700 - val_loss: 0.2334 - val_acc: 0.9366 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 110/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.1551 - acc: 0.9539 - recall: 0.1745 - fbeta_score: 0.1809 - val_loss: 0.1929 - val_acc: 0.9610 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 111/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1604 - acc: 0.9533 - recall: 0.1696 - fbeta_score: 0.1722 - val_loss: 0.2098 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 112/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1484 - acc: 0.9544 - recall: 0.1845 - fbeta_score: 0.1845 - val_loss: 0.1967 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 113/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1491 - acc: 0.9593 - recall: 0.2161 - fbeta_score: 0.2132 - val_loss: 0.2318 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 114/500\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.1493 - acc: 0.9544 - recall: 0.1682 - fbeta_score: 0.1718 - val_loss: 0.1802 - val_acc: 0.9610 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 115/500\n",
      "1843/1843 [==============================] - 0s 212us/step - loss: 0.1434 - acc: 0.9604 - recall: 0.2306 - fbeta_score: 0.2340 - val_loss: 0.2067 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 116/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1589 - acc: 0.9571 - recall: 0.1736 - fbeta_score: 0.1771 - val_loss: 0.2035 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 117/500\n",
      "1843/1843 [==============================] - 0s 206us/step - loss: 0.1444 - acc: 0.9604 - recall: 0.2134 - fbeta_score: 0.2161 - val_loss: 0.2060 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 118/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1377 - acc: 0.9593 - recall: 0.2143 - fbeta_score: 0.2179 - val_loss: 0.1956 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 119/500\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.1378 - acc: 0.9593 - recall: 0.1917 - fbeta_score: 0.1944 - val_loss: 0.1716 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 120/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1413 - acc: 0.9550 - recall: 0.1917 - fbeta_score: 0.1906 - val_loss: 0.1683 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 121/500\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.1416 - acc: 0.9604 - recall: 0.2080 - fbeta_score: 0.2107 - val_loss: 0.1868 - val_acc: 0.9512 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 122/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1397 - acc: 0.9582 - recall: 0.1926 - fbeta_score: 0.1990 - val_loss: 0.1843 - val_acc: 0.9463 - val_recall: 0.0488 - val_fbeta_score: 0.0650\n",
      "Epoch 123/500\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.1399 - acc: 0.9550 - recall: 0.2017 - fbeta_score: 0.1997 - val_loss: 0.1948 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 124/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1447 - acc: 0.9571 - recall: 0.1818 - fbeta_score: 0.1863 - val_loss: 0.2254 - val_acc: 0.9415 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 125/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1559 - acc: 0.9523 - recall: 0.1411 - fbeta_score: 0.1456 - val_loss: 0.1781 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 126/500\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.1419 - acc: 0.9566 - recall: 0.1736 - fbeta_score: 0.1763 - val_loss: 0.1799 - val_acc: 0.9463 - val_recall: 0.3171 - val_fbeta_score: 0.2927\n",
      "Epoch 127/500\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.1363 - acc: 0.9550 - recall: 0.1646 - fbeta_score: 0.1709 - val_loss: 0.1830 - val_acc: 0.9610 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 128/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1445 - acc: 0.9620 - recall: 0.1872 - fbeta_score: 0.1935 - val_loss: 0.1825 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 129/500\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.1390 - acc: 0.9588 - recall: 0.1971 - fbeta_score: 0.1962 - val_loss: 0.1846 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 130/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.1382 - acc: 0.9582 - recall: 0.1971 - fbeta_score: 0.2026 - val_loss: 0.1733 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 131/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.1377 - acc: 0.9598 - recall: 0.2179 - fbeta_score: 0.2188 - val_loss: 0.2201 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 132/500\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.1346 - acc: 0.9582 - recall: 0.1935 - fbeta_score: 0.2015 - val_loss: 0.2440 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 133/500\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.1344 - acc: 0.9615 - recall: 0.1917 - fbeta_score: 0.1971 - val_loss: 0.1879 - val_acc: 0.9610 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 134/500\n",
      "1843/1843 [==============================] - ETA: 0s - loss: 0.1493 - acc: 0.9575 - recall: 0.1741 - fbeta_score: 0.18 - 0s 241us/step - loss: 0.1478 - acc: 0.9577 - recall: 0.1691 - fbeta_score: 0.1772 - val_loss: 0.1864 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 135/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1456 - acc: 0.9560 - recall: 0.1637 - fbeta_score: 0.1669 - val_loss: 0.1607 - val_acc: 0.9610 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 136/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1393 - acc: 0.9593 - recall: 0.1763 - fbeta_score: 0.1827 - val_loss: 0.1987 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 137/500\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.1347 - acc: 0.9647 - recall: 0.2415 - fbeta_score: 0.2460 - val_loss: 0.2371 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 138/500\n",
      "1843/1843 [==============================] - 1s 352us/step - loss: 0.1433 - acc: 0.9571 - recall: 0.1763 - fbeta_score: 0.1845 - val_loss: 0.2882 - val_acc: 0.9268 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 139/500\n",
      "1843/1843 [==============================] - 1s 348us/step - loss: 0.1390 - acc: 0.9588 - recall: 0.2042 - fbeta_score: 0.2105 - val_loss: 0.1781 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 140/500\n",
      "1843/1843 [==============================] - 1s 280us/step - loss: 0.1421 - acc: 0.9577 - recall: 0.1944 - fbeta_score: 0.1980 - val_loss: 0.1976 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 141/500\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.1363 - acc: 0.9620 - recall: 0.2152 - fbeta_score: 0.2152 - val_loss: 0.1523 - val_acc: 0.9756 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 142/500\n",
      "1843/1843 [==============================] - 0s 209us/step - loss: 0.1376 - acc: 0.9544 - recall: 0.1709 - fbeta_score: 0.1789 - val_loss: 0.1739 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 143/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1346 - acc: 0.9577 - recall: 0.1958 - fbeta_score: 0.1991 - val_loss: 0.1701 - val_acc: 0.9610 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 144/500\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.1350 - acc: 0.9609 - recall: 0.1917 - fbeta_score: 0.1962 - val_loss: 0.2136 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1438 - acc: 0.9588 - recall: 0.1854 - fbeta_score: 0.1877 - val_loss: 0.1932 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 146/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1425 - acc: 0.9588 - recall: 0.1863 - fbeta_score: 0.1888 - val_loss: 0.1908 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 147/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1417 - acc: 0.9582 - recall: 0.1827 - fbeta_score: 0.1827 - val_loss: 0.1842 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 148/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1257 - acc: 0.9680 - recall: 0.2469 - fbeta_score: 0.2514 - val_loss: 0.1827 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 149/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1362 - acc: 0.9636 - recall: 0.2225 - fbeta_score: 0.2268 - val_loss: 0.1771 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 150/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1396 - acc: 0.9555 - recall: 0.1754 - fbeta_score: 0.1845 - val_loss: 0.1977 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 151/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1332 - acc: 0.9658 - recall: 0.2324 - fbeta_score: 0.2378 - val_loss: 0.1941 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 152/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1381 - acc: 0.9604 - recall: 0.1863 - fbeta_score: 0.1908 - val_loss: 0.1657 - val_acc: 0.9756 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 153/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1361 - acc: 0.9577 - recall: 0.1809 - fbeta_score: 0.1854 - val_loss: 0.2045 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 154/500\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.1323 - acc: 0.9604 - recall: 0.1979 - fbeta_score: 0.2024 - val_loss: 0.1472 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 155/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1403 - acc: 0.9598 - recall: 0.2116 - fbeta_score: 0.2152 - val_loss: 0.1768 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 156/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1305 - acc: 0.9626 - recall: 0.2125 - fbeta_score: 0.2196 - val_loss: 0.1951 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 157/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1267 - acc: 0.9631 - recall: 0.1872 - fbeta_score: 0.1944 - val_loss: 0.1705 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 158/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1337 - acc: 0.9615 - recall: 0.2107 - fbeta_score: 0.2161 - val_loss: 0.1675 - val_acc: 0.9610 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 159/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1362 - acc: 0.9566 - recall: 0.1926 - fbeta_score: 0.1917 - val_loss: 0.1625 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 160/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1394 - acc: 0.9582 - recall: 0.1926 - fbeta_score: 0.1971 - val_loss: 0.1984 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 161/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1366 - acc: 0.9571 - recall: 0.1691 - fbeta_score: 0.1834 - val_loss: 0.1807 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 162/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1362 - acc: 0.9604 - recall: 0.1836 - fbeta_score: 0.1890 - val_loss: 0.2073 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 163/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1329 - acc: 0.9642 - recall: 0.2008 - fbeta_score: 0.2053 - val_loss: 0.2018 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 164/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1437 - acc: 0.9582 - recall: 0.1888 - fbeta_score: 0.1952 - val_loss: 0.1971 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 165/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1418 - acc: 0.9571 - recall: 0.1962 - fbeta_score: 0.1990 - val_loss: 0.1975 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 166/500\n",
      "1843/1843 [==============================] - 0s 196us/step - loss: 0.1330 - acc: 0.9626 - recall: 0.2044 - fbeta_score: 0.2132 - val_loss: 0.1853 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 167/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1354 - acc: 0.9571 - recall: 0.1872 - fbeta_score: 0.1881 - val_loss: 0.2401 - val_acc: 0.9073 - val_recall: 0.4146 - val_fbeta_score: 0.3041\n",
      "Epoch 168/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1517 - acc: 0.9588 - recall: 0.1791 - fbeta_score: 0.1845 - val_loss: 0.2159 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 169/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1443 - acc: 0.9571 - recall: 0.1782 - fbeta_score: 0.1863 - val_loss: 0.1969 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 170/500\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.1421 - acc: 0.9582 - recall: 0.1619 - fbeta_score: 0.1669 - val_loss: 0.1945 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 171/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1225 - acc: 0.9620 - recall: 0.2062 - fbeta_score: 0.2116 - val_loss: 0.1719 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 172/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1285 - acc: 0.9636 - recall: 0.2161 - fbeta_score: 0.2205 - val_loss: 0.1948 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 173/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1367 - acc: 0.9588 - recall: 0.1836 - fbeta_score: 0.1888 - val_loss: 0.1820 - val_acc: 0.9512 - val_recall: 0.3171 - val_fbeta_score: 0.3089\n",
      "Epoch 174/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1369 - acc: 0.9571 - recall: 0.1700 - fbeta_score: 0.1791 - val_loss: 0.1989 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 175/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1363 - acc: 0.9577 - recall: 0.2098 - fbeta_score: 0.2160 - val_loss: 0.1892 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 176/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1289 - acc: 0.9626 - recall: 0.2152 - fbeta_score: 0.2243 - val_loss: 0.1805 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 177/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1293 - acc: 0.9577 - recall: 0.1890 - fbeta_score: 0.1908 - val_loss: 0.1736 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 178/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1267 - acc: 0.9615 - recall: 0.2196 - fbeta_score: 0.2241 - val_loss: 0.1688 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 179/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1367 - acc: 0.9620 - recall: 0.1926 - fbeta_score: 0.2035 - val_loss: 0.2064 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 180/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1321 - acc: 0.9609 - recall: 0.1935 - fbeta_score: 0.1990 - val_loss: 0.1641 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1271 - acc: 0.9588 - recall: 0.2035 - fbeta_score: 0.2042 - val_loss: 0.1743 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 182/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1321 - acc: 0.9544 - recall: 0.1917 - fbeta_score: 0.1980 - val_loss: 0.1988 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 183/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1340 - acc: 0.9604 - recall: 0.1718 - fbeta_score: 0.1798 - val_loss: 0.1805 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 184/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1364 - acc: 0.9550 - recall: 0.1763 - fbeta_score: 0.1800 - val_loss: 0.2126 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 185/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1290 - acc: 0.9609 - recall: 0.1727 - fbeta_score: 0.1782 - val_loss: 0.2006 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 186/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1276 - acc: 0.9615 - recall: 0.2433 - fbeta_score: 0.2487 - val_loss: 0.1726 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 187/500\n",
      "1843/1843 [==============================] - 0s 186us/step - loss: 0.1327 - acc: 0.9598 - recall: 0.1990 - fbeta_score: 0.2044 - val_loss: 0.1661 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 188/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1348 - acc: 0.9620 - recall: 0.1953 - fbeta_score: 0.2006 - val_loss: 0.3497 - val_acc: 0.8976 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 189/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1348 - acc: 0.9566 - recall: 0.1791 - fbeta_score: 0.1870 - val_loss: 0.1718 - val_acc: 0.9756 - val_recall: 0.4146 - val_fbeta_score: 0.4065\n",
      "Epoch 190/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1339 - acc: 0.9588 - recall: 0.1881 - fbeta_score: 0.1953 - val_loss: 0.1581 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 191/500\n",
      "1843/1843 [==============================] - 0s 186us/step - loss: 0.1385 - acc: 0.9550 - recall: 0.1619 - fbeta_score: 0.1691 - val_loss: 0.1735 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 192/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1310 - acc: 0.9615 - recall: 0.2179 - fbeta_score: 0.2252 - val_loss: 0.1885 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 193/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1309 - acc: 0.9604 - recall: 0.2026 - fbeta_score: 0.2125 - val_loss: 0.2062 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 194/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1277 - acc: 0.9560 - recall: 0.1682 - fbeta_score: 0.1700 - val_loss: 0.1502 - val_acc: 0.9756 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 195/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1256 - acc: 0.9658 - recall: 0.2442 - fbeta_score: 0.2523 - val_loss: 0.1861 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 196/500\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.1359 - acc: 0.9598 - recall: 0.1791 - fbeta_score: 0.1843 - val_loss: 0.1749 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 197/500\n",
      "1843/1843 [==============================] - 0s 193us/step - loss: 0.1239 - acc: 0.9647 - recall: 0.2368 - fbeta_score: 0.2413 - val_loss: 0.1757 - val_acc: 0.9463 - val_recall: 0.3171 - val_fbeta_score: 0.3089\n",
      "Epoch 198/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1436 - acc: 0.9582 - recall: 0.1804 - fbeta_score: 0.1857 - val_loss: 0.1765 - val_acc: 0.9561 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 199/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1343 - acc: 0.9604 - recall: 0.1980 - fbeta_score: 0.2053 - val_loss: 0.1949 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 200/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1243 - acc: 0.9609 - recall: 0.1944 - fbeta_score: 0.1999 - val_loss: 0.1686 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 201/500\n",
      "1843/1843 [==============================] - 0s 198us/step - loss: 0.1297 - acc: 0.9571 - recall: 0.2017 - fbeta_score: 0.2026 - val_loss: 0.2384 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 202/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1287 - acc: 0.9588 - recall: 0.1944 - fbeta_score: 0.2053 - val_loss: 0.1798 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 203/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1326 - acc: 0.9620 - recall: 0.2107 - fbeta_score: 0.2179 - val_loss: 0.1566 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 204/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1301 - acc: 0.9604 - recall: 0.2071 - fbeta_score: 0.2152 - val_loss: 0.1826 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 205/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1317 - acc: 0.9631 - recall: 0.1762 - fbeta_score: 0.1861 - val_loss: 0.1881 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 206/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1331 - acc: 0.9626 - recall: 0.2351 - fbeta_score: 0.2415 - val_loss: 0.1752 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 207/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1344 - acc: 0.9615 - recall: 0.1845 - fbeta_score: 0.1886 - val_loss: 0.1865 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 208/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1377 - acc: 0.9593 - recall: 0.1623 - fbeta_score: 0.1729 - val_loss: 0.2126 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 209/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1370 - acc: 0.9604 - recall: 0.1745 - fbeta_score: 0.1845 - val_loss: 0.1947 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 210/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1246 - acc: 0.9658 - recall: 0.2080 - fbeta_score: 0.2125 - val_loss: 0.1781 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 211/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1388 - acc: 0.9577 - recall: 0.1744 - fbeta_score: 0.1834 - val_loss: 0.1771 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 212/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1340 - acc: 0.9571 - recall: 0.1809 - fbeta_score: 0.1843 - val_loss: 0.2081 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 213/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1194 - acc: 0.9631 - recall: 0.2017 - fbeta_score: 0.2098 - val_loss: 0.2100 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 214/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1257 - acc: 0.9615 - recall: 0.2062 - fbeta_score: 0.2116 - val_loss: 0.1703 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 215/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1363 - acc: 0.9593 - recall: 0.1926 - fbeta_score: 0.2024 - val_loss: 0.2881 - val_acc: 0.9220 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 216/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1465 - acc: 0.9582 - recall: 0.1397 - fbeta_score: 0.1478 - val_loss: 0.1683 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 217/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1359 - acc: 0.9555 - recall: 0.1818 - fbeta_score: 0.1854 - val_loss: 0.1759 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 218/500\n",
      "1843/1843 [==============================] - 0s 196us/step - loss: 0.1256 - acc: 0.9620 - recall: 0.2225 - fbeta_score: 0.2225 - val_loss: 0.1707 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 219/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1264 - acc: 0.9588 - recall: 0.1854 - fbeta_score: 0.1971 - val_loss: 0.1717 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 220/500\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.1282 - acc: 0.9642 - recall: 0.2374 - fbeta_score: 0.2436 - val_loss: 0.1927 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 221/500\n",
      "1843/1843 [==============================] - 0s 211us/step - loss: 0.1311 - acc: 0.9598 - recall: 0.1772 - fbeta_score: 0.1816 - val_loss: 0.1557 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 222/500\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.1342 - acc: 0.9609 - recall: 0.1953 - fbeta_score: 0.1979 - val_loss: 0.1712 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 223/500\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.1236 - acc: 0.9620 - recall: 0.2053 - fbeta_score: 0.2125 - val_loss: 0.1785 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 224/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1195 - acc: 0.9647 - recall: 0.2311 - fbeta_score: 0.2400 - val_loss: 0.1788 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 225/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1326 - acc: 0.9626 - recall: 0.1926 - fbeta_score: 0.2013 - val_loss: 0.1952 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 226/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.1422 - acc: 0.9560 - recall: 0.1718 - fbeta_score: 0.1809 - val_loss: 0.2587 - val_acc: 0.9171 - val_recall: 0.2927 - val_fbeta_score: 0.2683\n",
      "Epoch 227/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1355 - acc: 0.9593 - recall: 0.1763 - fbeta_score: 0.1836 - val_loss: 0.2086 - val_acc: 0.9366 - val_recall: 0.3171 - val_fbeta_score: 0.3089\n",
      "Epoch 228/500\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.1295 - acc: 0.9626 - recall: 0.2216 - fbeta_score: 0.2234 - val_loss: 0.1538 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 229/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1360 - acc: 0.9609 - recall: 0.1745 - fbeta_score: 0.1827 - val_loss: 0.1760 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 230/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1340 - acc: 0.9582 - recall: 0.1854 - fbeta_score: 0.1952 - val_loss: 0.2039 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 231/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1405 - acc: 0.9615 - recall: 0.1971 - fbeta_score: 0.2017 - val_loss: 0.1648 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 232/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1321 - acc: 0.9604 - recall: 0.1990 - fbeta_score: 0.2008 - val_loss: 0.1973 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 233/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1229 - acc: 0.9615 - recall: 0.1944 - fbeta_score: 0.1962 - val_loss: 0.2260 - val_acc: 0.9317 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 234/500\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.1367 - acc: 0.9588 - recall: 0.1883 - fbeta_score: 0.1935 - val_loss: 0.1660 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 235/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1332 - acc: 0.9615 - recall: 0.1935 - fbeta_score: 0.2044 - val_loss: 0.2089 - val_acc: 0.9415 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 236/500\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.1269 - acc: 0.9577 - recall: 0.1854 - fbeta_score: 0.1899 - val_loss: 0.1958 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 237/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1428 - acc: 0.9550 - recall: 0.1510 - fbeta_score: 0.1628 - val_loss: 0.1600 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 238/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1276 - acc: 0.9593 - recall: 0.2107 - fbeta_score: 0.2143 - val_loss: 0.1924 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 239/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.1273 - acc: 0.9636 - recall: 0.2541 - fbeta_score: 0.2559 - val_loss: 0.1899 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 240/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1296 - acc: 0.9577 - recall: 0.1953 - fbeta_score: 0.1988 - val_loss: 0.1541 - val_acc: 0.9463 - val_recall: 0.2195 - val_fbeta_score: 0.2195\n",
      "Epoch 241/500\n",
      "1843/1843 [==============================] - 1s 319us/step - loss: 0.1340 - acc: 0.9593 - recall: 0.2075 - fbeta_score: 0.2102 - val_loss: 0.1812 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 242/500\n",
      "1843/1843 [==============================] - 0s 196us/step - loss: 0.1330 - acc: 0.9577 - recall: 0.1442 - fbeta_score: 0.1559 - val_loss: 0.1682 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 243/500\n",
      "1843/1843 [==============================] - 0s 197us/step - loss: 0.1340 - acc: 0.9598 - recall: 0.1709 - fbeta_score: 0.1776 - val_loss: 0.2117 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 244/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1324 - acc: 0.9582 - recall: 0.1537 - fbeta_score: 0.1646 - val_loss: 0.2034 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 245/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1240 - acc: 0.9609 - recall: 0.1980 - fbeta_score: 0.2044 - val_loss: 0.1553 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 246/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1266 - acc: 0.9680 - recall: 0.2279 - fbeta_score: 0.2396 - val_loss: 0.2057 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 247/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1212 - acc: 0.9685 - recall: 0.2600 - fbeta_score: 0.2680 - val_loss: 0.1851 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 248/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1246 - acc: 0.9620 - recall: 0.2198 - fbeta_score: 0.2297 - val_loss: 0.1716 - val_acc: 0.9659 - val_recall: 0.3659 - val_fbeta_score: 0.3496\n",
      "Epoch 249/500\n",
      "1843/1843 [==============================] - 1s 303us/step - loss: 0.1335 - acc: 0.9620 - recall: 0.2071 - fbeta_score: 0.2123 - val_loss: 0.1539 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 250/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1365 - acc: 0.9577 - recall: 0.1890 - fbeta_score: 0.1961 - val_loss: 0.2193 - val_acc: 0.9366 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 251/500\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.1277 - acc: 0.9598 - recall: 0.1831 - fbeta_score: 0.1876 - val_loss: 0.1907 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 252/500\n",
      "1843/1843 [==============================] - 0s 197us/step - loss: 0.1271 - acc: 0.9582 - recall: 0.1791 - fbeta_score: 0.1836 - val_loss: 0.1696 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 253/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 196us/step - loss: 0.1241 - acc: 0.9636 - recall: 0.2243 - fbeta_score: 0.2304 - val_loss: 0.1503 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 254/500\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.1172 - acc: 0.9712 - recall: 0.2496 - fbeta_score: 0.2536 - val_loss: 0.1522 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 255/500\n",
      "1843/1843 [==============================] - 0s 196us/step - loss: 0.1213 - acc: 0.9609 - recall: 0.2143 - fbeta_score: 0.2179 - val_loss: 0.1940 - val_acc: 0.9463 - val_recall: 0.3659 - val_fbeta_score: 0.3333\n",
      "Epoch 256/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1245 - acc: 0.9615 - recall: 0.2378 - fbeta_score: 0.2469 - val_loss: 0.1839 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 257/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1197 - acc: 0.9620 - recall: 0.2378 - fbeta_score: 0.2360 - val_loss: 0.2067 - val_acc: 0.9366 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 258/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1334 - acc: 0.9560 - recall: 0.1917 - fbeta_score: 0.1988 - val_loss: 0.1571 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 259/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1327 - acc: 0.9571 - recall: 0.1971 - fbeta_score: 0.2017 - val_loss: 0.1750 - val_acc: 0.9561 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 260/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1269 - acc: 0.9631 - recall: 0.2161 - fbeta_score: 0.2198 - val_loss: 0.1854 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 261/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1219 - acc: 0.9707 - recall: 0.2550 - fbeta_score: 0.2632 - val_loss: 0.1615 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 262/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1280 - acc: 0.9598 - recall: 0.1863 - fbeta_score: 0.1953 - val_loss: 0.2001 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 263/500\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.1352 - acc: 0.9582 - recall: 0.1886 - fbeta_score: 0.1939 - val_loss: 0.1657 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 264/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1304 - acc: 0.9609 - recall: 0.1985 - fbeta_score: 0.2029 - val_loss: 0.2066 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 265/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1252 - acc: 0.9631 - recall: 0.2080 - fbeta_score: 0.2198 - val_loss: 0.2117 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 266/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1238 - acc: 0.9691 - recall: 0.2360 - fbeta_score: 0.2422 - val_loss: 0.1646 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 267/500\n",
      "1843/1843 [==============================] - 0s 197us/step - loss: 0.1269 - acc: 0.9642 - recall: 0.2008 - fbeta_score: 0.2042 - val_loss: 0.1999 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 268/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1244 - acc: 0.9615 - recall: 0.2066 - fbeta_score: 0.2109 - val_loss: 0.2366 - val_acc: 0.9415 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 269/500\n",
      "1843/1843 [==============================] - 0s 186us/step - loss: 0.1183 - acc: 0.9631 - recall: 0.2288 - fbeta_score: 0.2322 - val_loss: 0.1704 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 270/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1307 - acc: 0.9609 - recall: 0.2211 - fbeta_score: 0.2210 - val_loss: 0.1932 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 271/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1307 - acc: 0.9615 - recall: 0.2080 - fbeta_score: 0.2094 - val_loss: 0.1836 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 272/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1397 - acc: 0.9566 - recall: 0.1727 - fbeta_score: 0.1818 - val_loss: 0.2406 - val_acc: 0.9415 - val_recall: 0.1707 - val_fbeta_score: 0.1545\n",
      "Epoch 273/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1376 - acc: 0.9615 - recall: 0.1691 - fbeta_score: 0.1753 - val_loss: 0.1955 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 274/500\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.1306 - acc: 0.9620 - recall: 0.1804 - fbeta_score: 0.1876 - val_loss: 0.1875 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 275/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1226 - acc: 0.9647 - recall: 0.2107 - fbeta_score: 0.2198 - val_loss: 0.1848 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 276/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1318 - acc: 0.9598 - recall: 0.1836 - fbeta_score: 0.1908 - val_loss: 0.1982 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 277/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1199 - acc: 0.9664 - recall: 0.2261 - fbeta_score: 0.2377 - val_loss: 0.1610 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 278/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1236 - acc: 0.9609 - recall: 0.2089 - fbeta_score: 0.2161 - val_loss: 0.1627 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 279/500\n",
      "1843/1843 [==============================] - 0s 182us/step - loss: 0.1352 - acc: 0.9620 - recall: 0.2030 - fbeta_score: 0.2138 - val_loss: 0.1721 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 280/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1168 - acc: 0.9680 - recall: 0.2482 - fbeta_score: 0.2518 - val_loss: 0.1942 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 281/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1235 - acc: 0.9626 - recall: 0.2170 - fbeta_score: 0.2225 - val_loss: 0.1676 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 282/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1288 - acc: 0.9615 - recall: 0.2080 - fbeta_score: 0.2161 - val_loss: 0.1884 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 283/500\n",
      "1843/1843 [==============================] - 0s 208us/step - loss: 0.1201 - acc: 0.9620 - recall: 0.2333 - fbeta_score: 0.2405 - val_loss: 0.2421 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 284/500\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 0.1322 - acc: 0.9615 - recall: 0.1822 - fbeta_score: 0.1921 - val_loss: 0.1991 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 285/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1226 - acc: 0.9658 - recall: 0.2455 - fbeta_score: 0.2518 - val_loss: 0.1860 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 286/500\n",
      "1843/1843 [==============================] - 0s 210us/step - loss: 0.1181 - acc: 0.9620 - recall: 0.2098 - fbeta_score: 0.2160 - val_loss: 0.1630 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 287/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.1410 - acc: 0.9582 - recall: 0.1709 - fbeta_score: 0.1791 - val_loss: 0.1623 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 288/500\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.1315 - acc: 0.9604 - recall: 0.2179 - fbeta_score: 0.2250 - val_loss: 0.1676 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1231 - acc: 0.9598 - recall: 0.2179 - fbeta_score: 0.2214 - val_loss: 0.2034 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 290/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.1299 - acc: 0.9604 - recall: 0.2161 - fbeta_score: 0.2214 - val_loss: 0.2004 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 291/500\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.1214 - acc: 0.9647 - recall: 0.2035 - fbeta_score: 0.2098 - val_loss: 0.1760 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 292/500\n",
      "1843/1843 [==============================] - 0s 193us/step - loss: 0.1338 - acc: 0.9593 - recall: 0.1908 - fbeta_score: 0.1997 - val_loss: 0.2150 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 293/500\n",
      "1843/1843 [==============================] - 0s 182us/step - loss: 0.1307 - acc: 0.9620 - recall: 0.1772 - fbeta_score: 0.1863 - val_loss: 0.1722 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 294/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1287 - acc: 0.9598 - recall: 0.1926 - fbeta_score: 0.1952 - val_loss: 0.1711 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 295/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1390 - acc: 0.9593 - recall: 0.1976 - fbeta_score: 0.2029 - val_loss: 0.1582 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 296/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1302 - acc: 0.9577 - recall: 0.1655 - fbeta_score: 0.1716 - val_loss: 0.1683 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 297/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1242 - acc: 0.9609 - recall: 0.1990 - fbeta_score: 0.2062 - val_loss: 0.1965 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 298/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1310 - acc: 0.9593 - recall: 0.1763 - fbeta_score: 0.1861 - val_loss: 0.1747 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 299/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1301 - acc: 0.9577 - recall: 0.1772 - fbeta_score: 0.1832 - val_loss: 0.2811 - val_acc: 0.9220 - val_recall: 0.2439 - val_fbeta_score: 0.2276\n",
      "Epoch 300/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1378 - acc: 0.9598 - recall: 0.2134 - fbeta_score: 0.2216 - val_loss: 0.1651 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 301/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1260 - acc: 0.9642 - recall: 0.2143 - fbeta_score: 0.2241 - val_loss: 0.1854 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 302/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1301 - acc: 0.9588 - recall: 0.1827 - fbeta_score: 0.1870 - val_loss: 0.1628 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 303/500\n",
      "1843/1843 [==============================] - 0s 194us/step - loss: 0.1321 - acc: 0.9566 - recall: 0.1709 - fbeta_score: 0.1763 - val_loss: 0.1822 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 304/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1211 - acc: 0.9631 - recall: 0.2324 - fbeta_score: 0.2378 - val_loss: 0.1828 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 305/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1249 - acc: 0.9615 - recall: 0.1700 - fbeta_score: 0.1800 - val_loss: 0.1621 - val_acc: 0.9707 - val_recall: 0.3659 - val_fbeta_score: 0.3659\n",
      "Epoch 306/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1254 - acc: 0.9685 - recall: 0.2550 - fbeta_score: 0.2586 - val_loss: 0.2160 - val_acc: 0.9122 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 307/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1444 - acc: 0.9528 - recall: 0.1492 - fbeta_score: 0.1592 - val_loss: 0.2116 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 308/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1187 - acc: 0.9658 - recall: 0.2243 - fbeta_score: 0.2342 - val_loss: 0.1681 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 309/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1307 - acc: 0.9620 - recall: 0.2279 - fbeta_score: 0.2277 - val_loss: 0.1927 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 310/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1292 - acc: 0.9593 - recall: 0.1836 - fbeta_score: 0.1872 - val_loss: 0.1934 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 311/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1284 - acc: 0.9582 - recall: 0.1628 - fbeta_score: 0.1698 - val_loss: 0.1863 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 312/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1209 - acc: 0.9626 - recall: 0.2071 - fbeta_score: 0.2134 - val_loss: 0.1888 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 313/500\n",
      "1843/1843 [==============================] - 0s 182us/step - loss: 0.1255 - acc: 0.9571 - recall: 0.1863 - fbeta_score: 0.1961 - val_loss: 0.1763 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 314/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1246 - acc: 0.9620 - recall: 0.2062 - fbeta_score: 0.2107 - val_loss: 0.1676 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 315/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1310 - acc: 0.9598 - recall: 0.2026 - fbeta_score: 0.2089 - val_loss: 0.1781 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 316/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1203 - acc: 0.9631 - recall: 0.1917 - fbeta_score: 0.1999 - val_loss: 0.2030 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 317/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1240 - acc: 0.9631 - recall: 0.2143 - fbeta_score: 0.2225 - val_loss: 0.1727 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 318/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1297 - acc: 0.9593 - recall: 0.2125 - fbeta_score: 0.2207 - val_loss: 0.1851 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 319/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1287 - acc: 0.9626 - recall: 0.1804 - fbeta_score: 0.1912 - val_loss: 0.2008 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 320/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1267 - acc: 0.9615 - recall: 0.1990 - fbeta_score: 0.2033 - val_loss: 0.2256 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 321/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1295 - acc: 0.9593 - recall: 0.1926 - fbeta_score: 0.1988 - val_loss: 0.1759 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 322/500\n",
      "1843/1843 [==============================] - 0s 186us/step - loss: 0.1334 - acc: 0.9604 - recall: 0.2044 - fbeta_score: 0.2116 - val_loss: 0.1828 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 323/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1370 - acc: 0.9566 - recall: 0.1583 - fbeta_score: 0.1680 - val_loss: 0.2004 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 324/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1356 - acc: 0.9604 - recall: 0.2152 - fbeta_score: 0.2196 - val_loss: 0.1594 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1182 - acc: 0.9669 - recall: 0.2342 - fbeta_score: 0.2424 - val_loss: 0.1670 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 326/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1222 - acc: 0.9626 - recall: 0.2297 - fbeta_score: 0.2340 - val_loss: 0.2092 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 327/500\n",
      "1843/1843 [==============================] - 0s 181us/step - loss: 0.1361 - acc: 0.9604 - recall: 0.1628 - fbeta_score: 0.1753 - val_loss: 0.1682 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 328/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1163 - acc: 0.9647 - recall: 0.2216 - fbeta_score: 0.2270 - val_loss: 0.2080 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 329/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1278 - acc: 0.9604 - recall: 0.1623 - fbeta_score: 0.1668 - val_loss: 0.2075 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 330/500\n",
      "1843/1843 [==============================] - 0s 202us/step - loss: 0.1357 - acc: 0.9528 - recall: 0.1908 - fbeta_score: 0.1961 - val_loss: 0.2235 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 331/500\n",
      "1843/1843 [==============================] - 0s 198us/step - loss: 0.1382 - acc: 0.9550 - recall: 0.1818 - fbeta_score: 0.1908 - val_loss: 0.1704 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 332/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1271 - acc: 0.9626 - recall: 0.1926 - fbeta_score: 0.2035 - val_loss: 0.1757 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 333/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1233 - acc: 0.9593 - recall: 0.1791 - fbeta_score: 0.1861 - val_loss: 0.1719 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 334/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1270 - acc: 0.9626 - recall: 0.1906 - fbeta_score: 0.1997 - val_loss: 0.1658 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 335/500\n",
      "1843/1843 [==============================] - 0s 196us/step - loss: 0.1218 - acc: 0.9642 - recall: 0.2514 - fbeta_score: 0.2559 - val_loss: 0.1586 - val_acc: 0.9756 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 336/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1220 - acc: 0.9615 - recall: 0.1854 - fbeta_score: 0.1933 - val_loss: 0.1862 - val_acc: 0.9610 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 337/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1143 - acc: 0.9653 - recall: 0.2306 - fbeta_score: 0.2369 - val_loss: 0.2138 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 338/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1258 - acc: 0.9609 - recall: 0.2179 - fbeta_score: 0.2207 - val_loss: 0.1662 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 339/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1290 - acc: 0.9582 - recall: 0.1890 - fbeta_score: 0.1971 - val_loss: 0.2012 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 340/500\n",
      "1843/1843 [==============================] - 0s 186us/step - loss: 0.1186 - acc: 0.9593 - recall: 0.2098 - fbeta_score: 0.2185 - val_loss: 0.2358 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 341/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1336 - acc: 0.9620 - recall: 0.2270 - fbeta_score: 0.2324 - val_loss: 0.2429 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 342/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1275 - acc: 0.9636 - recall: 0.2008 - fbeta_score: 0.2062 - val_loss: 0.1985 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 343/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1308 - acc: 0.9582 - recall: 0.1664 - fbeta_score: 0.1734 - val_loss: 0.2054 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 344/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1288 - acc: 0.9620 - recall: 0.1904 - fbeta_score: 0.2029 - val_loss: 0.2027 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 345/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1237 - acc: 0.9636 - recall: 0.1962 - fbeta_score: 0.2069 - val_loss: 0.1939 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 346/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1285 - acc: 0.9588 - recall: 0.2125 - fbeta_score: 0.2170 - val_loss: 0.2038 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 347/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1234 - acc: 0.9664 - recall: 0.2107 - fbeta_score: 0.2198 - val_loss: 0.2023 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 348/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1249 - acc: 0.9615 - recall: 0.2116 - fbeta_score: 0.2132 - val_loss: 0.1837 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 349/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1257 - acc: 0.9609 - recall: 0.2035 - fbeta_score: 0.2042 - val_loss: 0.1895 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 350/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1265 - acc: 0.9620 - recall: 0.2225 - fbeta_score: 0.2223 - val_loss: 0.2597 - val_acc: 0.9171 - val_recall: 0.3171 - val_fbeta_score: 0.2911\n",
      "Epoch 351/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1352 - acc: 0.9593 - recall: 0.1917 - fbeta_score: 0.1990 - val_loss: 0.1967 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 352/500\n",
      "1843/1843 [==============================] - 0s 182us/step - loss: 0.1251 - acc: 0.9664 - recall: 0.2130 - fbeta_score: 0.2210 - val_loss: 0.1848 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 353/500\n",
      "1843/1843 [==============================] - 0s 193us/step - loss: 0.1277 - acc: 0.9642 - recall: 0.2116 - fbeta_score: 0.2141 - val_loss: 0.1598 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 354/500\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 0.1230 - acc: 0.9620 - recall: 0.1971 - fbeta_score: 0.2053 - val_loss: 0.1654 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 355/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1173 - acc: 0.9691 - recall: 0.2369 - fbeta_score: 0.2415 - val_loss: 0.1599 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 356/500\n",
      "1843/1843 [==============================] - 0s 205us/step - loss: 0.1241 - acc: 0.9604 - recall: 0.2107 - fbeta_score: 0.2179 - val_loss: 0.1959 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 357/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1210 - acc: 0.9609 - recall: 0.2179 - fbeta_score: 0.2261 - val_loss: 0.1899 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 358/500\n",
      "1843/1843 [==============================] - 0s 186us/step - loss: 0.1249 - acc: 0.9636 - recall: 0.2089 - fbeta_score: 0.2116 - val_loss: 0.1887 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 359/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1202 - acc: 0.9658 - recall: 0.2042 - fbeta_score: 0.2123 - val_loss: 0.2278 - val_acc: 0.9366 - val_recall: 0.3659 - val_fbeta_score: 0.3333\n",
      "Epoch 360/500\n",
      "1843/1843 [==============================] - 0s 193us/step - loss: 0.1268 - acc: 0.9620 - recall: 0.2152 - fbeta_score: 0.2250 - val_loss: 0.1784 - val_acc: 0.9707 - val_recall: 0.2927 - val_fbeta_score: 0.2927\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1216 - acc: 0.9674 - recall: 0.2469 - fbeta_score: 0.2514 - val_loss: 0.1838 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 362/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1203 - acc: 0.9642 - recall: 0.2261 - fbeta_score: 0.2340 - val_loss: 0.1690 - val_acc: 0.9561 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 363/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1300 - acc: 0.9609 - recall: 0.1953 - fbeta_score: 0.2080 - val_loss: 0.1931 - val_acc: 0.9610 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 364/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1254 - acc: 0.9631 - recall: 0.2175 - fbeta_score: 0.2273 - val_loss: 0.1691 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 365/500\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.1219 - acc: 0.9680 - recall: 0.2415 - fbeta_score: 0.2476 - val_loss: 0.1686 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 366/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1282 - acc: 0.9582 - recall: 0.1926 - fbeta_score: 0.1990 - val_loss: 0.1953 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 367/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1279 - acc: 0.9555 - recall: 0.1836 - fbeta_score: 0.1854 - val_loss: 0.1709 - val_acc: 0.9512 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 368/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1253 - acc: 0.9664 - recall: 0.2324 - fbeta_score: 0.2378 - val_loss: 0.1871 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 369/500\n",
      "1843/1843 [==============================] - 0s 196us/step - loss: 0.1303 - acc: 0.9615 - recall: 0.2238 - fbeta_score: 0.2310 - val_loss: 0.2039 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 370/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1255 - acc: 0.9658 - recall: 0.2035 - fbeta_score: 0.2134 - val_loss: 0.1612 - val_acc: 0.9659 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 371/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1254 - acc: 0.9653 - recall: 0.2198 - fbeta_score: 0.2241 - val_loss: 0.1874 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 372/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1370 - acc: 0.9609 - recall: 0.1813 - fbeta_score: 0.1885 - val_loss: 0.1842 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 373/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1126 - acc: 0.9658 - recall: 0.2243 - fbeta_score: 0.2306 - val_loss: 0.2240 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 374/500\n",
      "1843/1843 [==============================] - 0s 182us/step - loss: 0.1320 - acc: 0.9642 - recall: 0.1766 - fbeta_score: 0.1856 - val_loss: 0.1700 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 375/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1221 - acc: 0.9636 - recall: 0.1899 - fbeta_score: 0.2008 - val_loss: 0.1980 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 376/500\n",
      "1843/1843 [==============================] - 0s 179us/step - loss: 0.1198 - acc: 0.9658 - recall: 0.2356 - fbeta_score: 0.2389 - val_loss: 0.1946 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 377/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1243 - acc: 0.9636 - recall: 0.2207 - fbeta_score: 0.2279 - val_loss: 0.1747 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 378/500\n",
      "1843/1843 [==============================] - 0s 197us/step - loss: 0.1180 - acc: 0.9658 - recall: 0.2424 - fbeta_score: 0.2442 - val_loss: 0.1867 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 379/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1231 - acc: 0.9664 - recall: 0.2333 - fbeta_score: 0.2377 - val_loss: 0.1794 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 380/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1269 - acc: 0.9577 - recall: 0.1917 - fbeta_score: 0.1961 - val_loss: 0.1818 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 381/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1358 - acc: 0.9588 - recall: 0.1745 - fbeta_score: 0.1863 - val_loss: 0.3990 - val_acc: 0.8780 - val_recall: 0.3171 - val_fbeta_score: 0.2764\n",
      "Epoch 382/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1525 - acc: 0.9566 - recall: 0.1772 - fbeta_score: 0.1816 - val_loss: 0.1790 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 383/500\n",
      "1843/1843 [==============================] - 0s 193us/step - loss: 0.1683 - acc: 0.9501 - recall: 0.1275 - fbeta_score: 0.1338 - val_loss: 0.1602 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 384/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1651 - acc: 0.9528 - recall: 0.1130 - fbeta_score: 0.1210 - val_loss: 0.1508 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 385/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1500 - acc: 0.9539 - recall: 0.1420 - fbeta_score: 0.1501 - val_loss: 0.1774 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 386/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1493 - acc: 0.9598 - recall: 0.1926 - fbeta_score: 0.1953 - val_loss: 0.3385 - val_acc: 0.8732 - val_recall: 0.3171 - val_fbeta_score: 0.2390\n",
      "Epoch 387/500\n",
      "1843/1843 [==============================] - 0s 186us/step - loss: 0.1809 - acc: 0.9485 - recall: 0.1112 - fbeta_score: 0.1121 - val_loss: 0.2046 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 388/500\n",
      "1843/1843 [==============================] - 0s 196us/step - loss: 0.1696 - acc: 0.9506 - recall: 0.1004 - fbeta_score: 0.1058 - val_loss: 0.1818 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 389/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1574 - acc: 0.9528 - recall: 0.1574 - fbeta_score: 0.1628 - val_loss: 0.2105 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 390/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1608 - acc: 0.9512 - recall: 0.1139 - fbeta_score: 0.1230 - val_loss: 0.1969 - val_acc: 0.9415 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 391/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1520 - acc: 0.9533 - recall: 0.1201 - fbeta_score: 0.1273 - val_loss: 0.1937 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 392/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1541 - acc: 0.9517 - recall: 0.1472 - fbeta_score: 0.1481 - val_loss: 0.1822 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 393/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1492 - acc: 0.9588 - recall: 0.1791 - fbeta_score: 0.1872 - val_loss: 0.2049 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 394/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1502 - acc: 0.9544 - recall: 0.1465 - fbeta_score: 0.1519 - val_loss: 0.1933 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 395/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1493 - acc: 0.9523 - recall: 0.1198 - fbeta_score: 0.1261 - val_loss: 0.1896 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 396/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1542 - acc: 0.9495 - recall: 0.1282 - fbeta_score: 0.1364 - val_loss: 0.1673 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1491 - acc: 0.9533 - recall: 0.1388 - fbeta_score: 0.1496 - val_loss: 0.1647 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 398/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1432 - acc: 0.9523 - recall: 0.1492 - fbeta_score: 0.1537 - val_loss: 0.1738 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 399/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1425 - acc: 0.9506 - recall: 0.1302 - fbeta_score: 0.1338 - val_loss: 0.1849 - val_acc: 0.9415 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 400/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1333 - acc: 0.9550 - recall: 0.1628 - fbeta_score: 0.1664 - val_loss: 0.2514 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 401/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1445 - acc: 0.9517 - recall: 0.1438 - fbeta_score: 0.1481 - val_loss: 0.1785 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 402/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1302 - acc: 0.9604 - recall: 0.1917 - fbeta_score: 0.1926 - val_loss: 0.1831 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 403/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1265 - acc: 0.9653 - recall: 0.2161 - fbeta_score: 0.2198 - val_loss: 0.1773 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 404/500\n",
      "1843/1843 [==============================] - 0s 181us/step - loss: 0.1323 - acc: 0.9588 - recall: 0.1913 - fbeta_score: 0.1975 - val_loss: 0.1774 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 405/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1289 - acc: 0.9560 - recall: 0.1782 - fbeta_score: 0.1854 - val_loss: 0.1965 - val_acc: 0.9659 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 406/500\n",
      "1843/1843 [==============================] - 0s 186us/step - loss: 0.1282 - acc: 0.9598 - recall: 0.2026 - fbeta_score: 0.2071 - val_loss: 0.1849 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 407/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1357 - acc: 0.9626 - recall: 0.2084 - fbeta_score: 0.2156 - val_loss: 0.1777 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 408/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1239 - acc: 0.9653 - recall: 0.2107 - fbeta_score: 0.2188 - val_loss: 0.1609 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 409/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1345 - acc: 0.9588 - recall: 0.1881 - fbeta_score: 0.1935 - val_loss: 0.1722 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 410/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1333 - acc: 0.9582 - recall: 0.1709 - fbeta_score: 0.1771 - val_loss: 0.1715 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 411/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1234 - acc: 0.9631 - recall: 0.1899 - fbeta_score: 0.1935 - val_loss: 0.1561 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 412/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1267 - acc: 0.9609 - recall: 0.1809 - fbeta_score: 0.1890 - val_loss: 0.1622 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 413/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1269 - acc: 0.9620 - recall: 0.1944 - fbeta_score: 0.1999 - val_loss: 0.1729 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 414/500\n",
      "1843/1843 [==============================] - 0s 186us/step - loss: 0.1326 - acc: 0.9571 - recall: 0.1555 - fbeta_score: 0.1655 - val_loss: 0.1609 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 415/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1358 - acc: 0.9566 - recall: 0.1705 - fbeta_score: 0.1722 - val_loss: 0.1971 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 416/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1356 - acc: 0.9609 - recall: 0.1962 - fbeta_score: 0.2044 - val_loss: 0.1845 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 417/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1146 - acc: 0.9664 - recall: 0.2060 - fbeta_score: 0.2132 - val_loss: 0.1757 - val_acc: 0.9659 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 418/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1277 - acc: 0.9626 - recall: 0.2281 - fbeta_score: 0.2342 - val_loss: 0.1519 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 419/500\n",
      "1843/1843 [==============================] - 0s 197us/step - loss: 0.1308 - acc: 0.9571 - recall: 0.1673 - fbeta_score: 0.1753 - val_loss: 0.1560 - val_acc: 0.9659 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 420/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1242 - acc: 0.9653 - recall: 0.2297 - fbeta_score: 0.2342 - val_loss: 0.1565 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 421/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1252 - acc: 0.9609 - recall: 0.1791 - fbeta_score: 0.1872 - val_loss: 0.1701 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 422/500\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.1339 - acc: 0.9571 - recall: 0.1678 - fbeta_score: 0.1722 - val_loss: 0.1495 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 423/500\n",
      "1843/1843 [==============================] - 0s 197us/step - loss: 0.1309 - acc: 0.9593 - recall: 0.1890 - fbeta_score: 0.1980 - val_loss: 0.2088 - val_acc: 0.9415 - val_recall: 0.2683 - val_fbeta_score: 0.2634\n",
      "Epoch 424/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1238 - acc: 0.9626 - recall: 0.2243 - fbeta_score: 0.2304 - val_loss: 0.1686 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 425/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1235 - acc: 0.9598 - recall: 0.1944 - fbeta_score: 0.1997 - val_loss: 0.1950 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 426/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1335 - acc: 0.9571 - recall: 0.1734 - fbeta_score: 0.1780 - val_loss: 0.1544 - val_acc: 0.9756 - val_recall: 0.3659 - val_fbeta_score: 0.3740\n",
      "Epoch 427/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1185 - acc: 0.9626 - recall: 0.2170 - fbeta_score: 0.2188 - val_loss: 0.1883 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 428/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1180 - acc: 0.9604 - recall: 0.2116 - fbeta_score: 0.2116 - val_loss: 0.1801 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 429/500\n",
      "1843/1843 [==============================] - 0s 186us/step - loss: 0.1454 - acc: 0.9582 - recall: 0.1646 - fbeta_score: 0.1727 - val_loss: 0.2146 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 430/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1323 - acc: 0.9588 - recall: 0.1845 - fbeta_score: 0.1908 - val_loss: 0.1710 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 431/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1221 - acc: 0.9615 - recall: 0.2347 - fbeta_score: 0.2373 - val_loss: 0.2161 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 432/500\n",
      "1843/1843 [==============================] - 0s 194us/step - loss: 0.1215 - acc: 0.9598 - recall: 0.1655 - fbeta_score: 0.1771 - val_loss: 0.1786 - val_acc: 0.9610 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 433/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1265 - acc: 0.9609 - recall: 0.2080 - fbeta_score: 0.2143 - val_loss: 0.1760 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 434/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1264 - acc: 0.9626 - recall: 0.1904 - fbeta_score: 0.1966 - val_loss: 0.1785 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 435/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1278 - acc: 0.9664 - recall: 0.2125 - fbeta_score: 0.2188 - val_loss: 0.2194 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 436/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1229 - acc: 0.9598 - recall: 0.1818 - fbeta_score: 0.1935 - val_loss: 0.2109 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 437/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1317 - acc: 0.9626 - recall: 0.2089 - fbeta_score: 0.2170 - val_loss: 0.2320 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 438/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1160 - acc: 0.9653 - recall: 0.2116 - fbeta_score: 0.2141 - val_loss: 0.1905 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 439/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1150 - acc: 0.9669 - recall: 0.2360 - fbeta_score: 0.2369 - val_loss: 0.1602 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 440/500\n",
      "1843/1843 [==============================] - 0s 194us/step - loss: 0.1358 - acc: 0.9604 - recall: 0.2069 - fbeta_score: 0.2069 - val_loss: 0.1582 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 441/500\n",
      "1843/1843 [==============================] - 0s 181us/step - loss: 0.1200 - acc: 0.9647 - recall: 0.2080 - fbeta_score: 0.2143 - val_loss: 0.1588 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 442/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1271 - acc: 0.9598 - recall: 0.1872 - fbeta_score: 0.1944 - val_loss: 0.1523 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 443/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1133 - acc: 0.9636 - recall: 0.2143 - fbeta_score: 0.2241 - val_loss: 0.1809 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 444/500\n",
      "1843/1843 [==============================] - 0s 193us/step - loss: 0.1184 - acc: 0.9669 - recall: 0.2342 - fbeta_score: 0.2375 - val_loss: 0.1721 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 445/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1220 - acc: 0.9626 - recall: 0.2098 - fbeta_score: 0.2225 - val_loss: 0.1932 - val_acc: 0.9610 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 446/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1391 - acc: 0.9615 - recall: 0.1845 - fbeta_score: 0.1908 - val_loss: 0.2359 - val_acc: 0.9415 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 447/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1206 - acc: 0.9647 - recall: 0.2288 - fbeta_score: 0.2340 - val_loss: 0.1784 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 448/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1241 - acc: 0.9653 - recall: 0.1997 - fbeta_score: 0.2103 - val_loss: 0.1865 - val_acc: 0.9561 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 449/500\n",
      "1843/1843 [==============================] - 0s 196us/step - loss: 0.1256 - acc: 0.9615 - recall: 0.2211 - fbeta_score: 0.2273 - val_loss: 0.1698 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 450/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1303 - acc: 0.9577 - recall: 0.1763 - fbeta_score: 0.1863 - val_loss: 0.2063 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 451/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1216 - acc: 0.9647 - recall: 0.2279 - fbeta_score: 0.2297 - val_loss: 0.1682 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 452/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1257 - acc: 0.9582 - recall: 0.1899 - fbeta_score: 0.1953 - val_loss: 0.1770 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 453/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1306 - acc: 0.9615 - recall: 0.1908 - fbeta_score: 0.1935 - val_loss: 0.1943 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 454/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1303 - acc: 0.9582 - recall: 0.1827 - fbeta_score: 0.1923 - val_loss: 0.1612 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 455/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1192 - acc: 0.9631 - recall: 0.2211 - fbeta_score: 0.2246 - val_loss: 0.1684 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 456/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1303 - acc: 0.9571 - recall: 0.1759 - fbeta_score: 0.1803 - val_loss: 0.1802 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 457/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1352 - acc: 0.9593 - recall: 0.1881 - fbeta_score: 0.1971 - val_loss: 0.1442 - val_acc: 0.9756 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 458/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1210 - acc: 0.9588 - recall: 0.1845 - fbeta_score: 0.1897 - val_loss: 0.1870 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 459/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1259 - acc: 0.9593 - recall: 0.2134 - fbeta_score: 0.2143 - val_loss: 0.1650 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 460/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1290 - acc: 0.9631 - recall: 0.1899 - fbeta_score: 0.1970 - val_loss: 0.1407 - val_acc: 0.9659 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 461/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1192 - acc: 0.9669 - recall: 0.2324 - fbeta_score: 0.2396 - val_loss: 0.1529 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 462/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1256 - acc: 0.9604 - recall: 0.2053 - fbeta_score: 0.2125 - val_loss: 0.1638 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 463/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1276 - acc: 0.9609 - recall: 0.1763 - fbeta_score: 0.1881 - val_loss: 0.1526 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 464/500\n",
      "1843/1843 [==============================] - 0s 180us/step - loss: 0.1393 - acc: 0.9588 - recall: 0.1913 - fbeta_score: 0.1975 - val_loss: 0.1866 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 465/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1346 - acc: 0.9615 - recall: 0.1537 - fbeta_score: 0.1610 - val_loss: 0.1664 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 466/500\n",
      "1843/1843 [==============================] - 0s 185us/step - loss: 0.1227 - acc: 0.9653 - recall: 0.2170 - fbeta_score: 0.2270 - val_loss: 0.1590 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 467/500\n",
      "1843/1843 [==============================] - 0s 186us/step - loss: 0.1218 - acc: 0.9620 - recall: 0.1718 - fbeta_score: 0.1772 - val_loss: 0.1378 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 468/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1274 - acc: 0.9577 - recall: 0.1709 - fbeta_score: 0.1744 - val_loss: 0.1393 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 469/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 202us/step - loss: 0.1278 - acc: 0.9620 - recall: 0.2143 - fbeta_score: 0.2214 - val_loss: 0.1652 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 470/500\n",
      "1843/1843 [==============================] - 0s 182us/step - loss: 0.1277 - acc: 0.9620 - recall: 0.1687 - fbeta_score: 0.1812 - val_loss: 0.1770 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 471/500\n",
      "1843/1843 [==============================] - 0s 199us/step - loss: 0.1233 - acc: 0.9620 - recall: 0.2143 - fbeta_score: 0.2170 - val_loss: 0.1958 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 472/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1199 - acc: 0.9658 - recall: 0.2134 - fbeta_score: 0.2198 - val_loss: 0.1641 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 473/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1223 - acc: 0.9658 - recall: 0.2351 - fbeta_score: 0.2415 - val_loss: 0.2847 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 474/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1289 - acc: 0.9598 - recall: 0.1926 - fbeta_score: 0.1953 - val_loss: 0.1900 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 475/500\n",
      "1843/1843 [==============================] - 0s 192us/step - loss: 0.1208 - acc: 0.9631 - recall: 0.2089 - fbeta_score: 0.2089 - val_loss: 0.1907 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 476/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1231 - acc: 0.9642 - recall: 0.2107 - fbeta_score: 0.2161 - val_loss: 0.1660 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 477/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1169 - acc: 0.9691 - recall: 0.2776 - fbeta_score: 0.2811 - val_loss: 0.1611 - val_acc: 0.9610 - val_recall: 0.3659 - val_fbeta_score: 0.3740\n",
      "Epoch 478/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1320 - acc: 0.9588 - recall: 0.1682 - fbeta_score: 0.1754 - val_loss: 0.1808 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 479/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1168 - acc: 0.9636 - recall: 0.1736 - fbeta_score: 0.1836 - val_loss: 0.1924 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 480/500\n",
      "1843/1843 [==============================] - 0s 181us/step - loss: 0.1248 - acc: 0.9631 - recall: 0.1953 - fbeta_score: 0.2035 - val_loss: 0.1697 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 481/500\n",
      "1843/1843 [==============================] - 0s 194us/step - loss: 0.1312 - acc: 0.9604 - recall: 0.1990 - fbeta_score: 0.2071 - val_loss: 0.1475 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 482/500\n",
      "1843/1843 [==============================] - 0s 189us/step - loss: 0.1284 - acc: 0.9571 - recall: 0.1727 - fbeta_score: 0.1782 - val_loss: 0.1826 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 483/500\n",
      "1843/1843 [==============================] - 0s 195us/step - loss: 0.1295 - acc: 0.9620 - recall: 0.1899 - fbeta_score: 0.1980 - val_loss: 0.1766 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 484/500\n",
      "1843/1843 [==============================] - 0s 193us/step - loss: 0.1252 - acc: 0.9636 - recall: 0.2161 - fbeta_score: 0.2252 - val_loss: 0.1702 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 485/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1254 - acc: 0.9636 - recall: 0.1908 - fbeta_score: 0.1986 - val_loss: 0.1883 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 486/500\n",
      "1843/1843 [==============================] - 0s 190us/step - loss: 0.1281 - acc: 0.9609 - recall: 0.2008 - fbeta_score: 0.2098 - val_loss: 0.1733 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 487/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1292 - acc: 0.9571 - recall: 0.1777 - fbeta_score: 0.1812 - val_loss: 0.1492 - val_acc: 0.9610 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 488/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1230 - acc: 0.9582 - recall: 0.1745 - fbeta_score: 0.1780 - val_loss: 0.2355 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 489/500\n",
      "1843/1843 [==============================] - 0s 194us/step - loss: 0.1353 - acc: 0.9571 - recall: 0.1872 - fbeta_score: 0.1971 - val_loss: 0.1524 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 490/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1287 - acc: 0.9604 - recall: 0.1795 - fbeta_score: 0.1894 - val_loss: 0.1604 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 491/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1180 - acc: 0.9636 - recall: 0.2008 - fbeta_score: 0.2069 - val_loss: 0.1981 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 492/500\n",
      "1843/1843 [==============================] - 0s 183us/step - loss: 0.1181 - acc: 0.9674 - recall: 0.2473 - fbeta_score: 0.2491 - val_loss: 0.1864 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 493/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1263 - acc: 0.9647 - recall: 0.1999 - fbeta_score: 0.2089 - val_loss: 0.1858 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 494/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1229 - acc: 0.9647 - recall: 0.2234 - fbeta_score: 0.2248 - val_loss: 0.1725 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 495/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1212 - acc: 0.9636 - recall: 0.2075 - fbeta_score: 0.2120 - val_loss: 0.1482 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 496/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1170 - acc: 0.9642 - recall: 0.2089 - fbeta_score: 0.2169 - val_loss: 0.1948 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 497/500\n",
      "1843/1843 [==============================] - 0s 188us/step - loss: 0.1313 - acc: 0.9566 - recall: 0.1664 - fbeta_score: 0.1734 - val_loss: 0.1880 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 498/500\n",
      "1843/1843 [==============================] - 0s 184us/step - loss: 0.1314 - acc: 0.9598 - recall: 0.1763 - fbeta_score: 0.1852 - val_loss: 0.1803 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 499/500\n",
      "1843/1843 [==============================] - 0s 191us/step - loss: 0.1245 - acc: 0.9642 - recall: 0.2125 - fbeta_score: 0.2194 - val_loss: 0.1936 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 500/500\n",
      "1843/1843 [==============================] - 0s 187us/step - loss: 0.1196 - acc: 0.9598 - recall: 0.1822 - fbeta_score: 0.1894 - val_loss: 0.1628 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19167642e48>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp3.fit(X_scale_train, y_train,\n",
    "                epochs=500,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_split=0.1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               2400      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 34,401\n",
      "Trainable params: 33,601\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El usar una regularización l2 tipo Ridge no mejora el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Capa (Lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4))\n",
    "\n",
    "#l=0.007\n",
    "l=0.001\n",
    "\n",
    "x = Input(shape=(23,))\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l1(l))(x)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l1(l))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l1(l))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l1(l))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "y = Dense(1, activation='sigmoid',kernel_initializer='he_uniform')(layer)\n",
    "mlp4 = Model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp4.compile(optimizer='sgd',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', recall, fbeta_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1843 samples, validate on 205 samples\n",
      "Epoch 1/500\n",
      "1843/1843 [==============================] - 2s 1ms/step - loss: 4.7103 - acc: 0.7889 - recall: 0.1763 - fbeta_score: 0.1320 - val_loss: 4.4934 - val_acc: 0.9317 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 2/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 4.3947 - acc: 0.9463 - recall: 0.1429 - fbeta_score: 0.1438 - val_loss: 4.3522 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 3/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 4.2759 - acc: 0.9533 - recall: 0.1266 - fbeta_score: 0.1293 - val_loss: 4.2615 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 4/500\n",
      "1843/1843 [==============================] - 1s 290us/step - loss: 4.1998 - acc: 0.9517 - recall: 0.1167 - fbeta_score: 0.1266 - val_loss: 4.2020 - val_acc: 0.9317 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 5/500\n",
      "1843/1843 [==============================] - 0s 271us/step - loss: 4.1252 - acc: 0.9550 - recall: 0.1230 - fbeta_score: 0.1284 - val_loss: 4.1393 - val_acc: 0.9268 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 6/500\n",
      "1843/1843 [==============================] - 1s 312us/step - loss: 4.0570 - acc: 0.9577 - recall: 0.1406 - fbeta_score: 0.1469 - val_loss: 4.0825 - val_acc: 0.9415 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 7/500\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 3.9982 - acc: 0.9560 - recall: 0.1763 - fbeta_score: 0.1782 - val_loss: 4.0154 - val_acc: 0.9317 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 8/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 3.9346 - acc: 0.9626 - recall: 0.1944 - fbeta_score: 0.1999 - val_loss: 3.9657 - val_acc: 0.9317 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 9/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 3.8760 - acc: 0.9642 - recall: 0.1791 - fbeta_score: 0.1834 - val_loss: 3.8904 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 10/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 3.8140 - acc: 0.9615 - recall: 0.1754 - fbeta_score: 0.1836 - val_loss: 3.8520 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 11/500\n",
      "1843/1843 [==============================] - 0s 271us/step - loss: 3.7633 - acc: 0.9604 - recall: 0.1693 - fbeta_score: 0.1736 - val_loss: 3.7968 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 12/500\n",
      "1843/1843 [==============================] - 0s 260us/step - loss: 3.6973 - acc: 0.9636 - recall: 0.2188 - fbeta_score: 0.2286 - val_loss: 3.7463 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 13/500\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 3.6386 - acc: 0.9631 - recall: 0.2098 - fbeta_score: 0.2170 - val_loss: 3.6938 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 14/500\n",
      "1843/1843 [==============================] - 1s 316us/step - loss: 3.5822 - acc: 0.9680 - recall: 0.2207 - fbeta_score: 0.2277 - val_loss: 3.6519 - val_acc: 0.9415 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 15/500\n",
      "1843/1843 [==============================] - 1s 312us/step - loss: 3.5384 - acc: 0.9674 - recall: 0.2392 - fbeta_score: 0.2491 - val_loss: 3.5986 - val_acc: 0.9317 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 16/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 3.4709 - acc: 0.9718 - recall: 0.2550 - fbeta_score: 0.2639 - val_loss: 3.5287 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.1138\n",
      "Epoch 17/500\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 3.4178 - acc: 0.9745 - recall: 0.2758 - fbeta_score: 0.2847 - val_loss: 3.4673 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 18/500\n",
      "1843/1843 [==============================] - 1s 285us/step - loss: 3.3633 - acc: 0.9702 - recall: 0.2561 - fbeta_score: 0.2623 - val_loss: 3.4312 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 19/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 3.3091 - acc: 0.9712 - recall: 0.2415 - fbeta_score: 0.2492 - val_loss: 3.3963 - val_acc: 0.9268 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 20/500\n",
      "1843/1843 [==============================] - 1s 319us/step - loss: 3.2677 - acc: 0.9691 - recall: 0.2360 - fbeta_score: 0.2458 - val_loss: 3.3591 - val_acc: 0.9171 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 21/500\n",
      "1843/1843 [==============================] - 0s 269us/step - loss: 3.2238 - acc: 0.9658 - recall: 0.2324 - fbeta_score: 0.2415 - val_loss: 3.2902 - val_acc: 0.9317 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 22/500\n",
      "1843/1843 [==============================] - 0s 250us/step - loss: 3.1574 - acc: 0.9718 - recall: 0.2686 - fbeta_score: 0.2785 - val_loss: 3.2148 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 23/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 3.1073 - acc: 0.9734 - recall: 0.3093 - fbeta_score: 0.3145 - val_loss: 3.1741 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 24/500\n",
      "1843/1843 [==============================] - 1s 283us/step - loss: 3.0638 - acc: 0.9723 - recall: 0.2767 - fbeta_score: 0.2856 - val_loss: 3.1428 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 25/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 3.0074 - acc: 0.9718 - recall: 0.2577 - fbeta_score: 0.2639 - val_loss: 3.0870 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 26/500\n",
      "1843/1843 [==============================] - 0s 264us/step - loss: 2.9608 - acc: 0.9712 - recall: 0.2460 - fbeta_score: 0.2487 - val_loss: 3.0541 - val_acc: 0.9268 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 27/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 2.9201 - acc: 0.9718 - recall: 0.2659 - fbeta_score: 0.2765 - val_loss: 3.0006 - val_acc: 0.9366 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 28/500\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 2.8746 - acc: 0.9685 - recall: 0.2523 - fbeta_score: 0.2548 - val_loss: 2.9593 - val_acc: 0.9268 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 29/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 2.8239 - acc: 0.9740 - recall: 0.3066 - fbeta_score: 0.3129 - val_loss: 2.9177 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 30/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 2.7809 - acc: 0.9723 - recall: 0.2604 - fbeta_score: 0.2677 - val_loss: 2.8510 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 31/500\n",
      "1843/1843 [==============================] - 0s 262us/step - loss: 2.7313 - acc: 0.9729 - recall: 0.2894 - fbeta_score: 0.2935 - val_loss: 2.7885 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 32/500\n",
      "1843/1843 [==============================] - 0s 204us/step - loss: 2.6786 - acc: 0.9718 - recall: 0.2686 - fbeta_score: 0.2749 - val_loss: 2.7870 - val_acc: 0.9366 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 33/500\n",
      "1843/1843 [==============================] - 0s 256us/step - loss: 2.6359 - acc: 0.9712 - recall: 0.2613 - fbeta_score: 0.2746 - val_loss: 2.7211 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 34/500\n",
      "1843/1843 [==============================] - 1s 278us/step - loss: 2.5877 - acc: 0.9761 - recall: 0.2957 - fbeta_score: 0.3019 - val_loss: 2.6693 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 35/500\n",
      "1843/1843 [==============================] - 1s 273us/step - loss: 2.5401 - acc: 0.9772 - recall: 0.3093 - fbeta_score: 0.3127 - val_loss: 2.6367 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 36/500\n",
      "1843/1843 [==============================] - 1s 296us/step - loss: 2.4910 - acc: 0.9723 - recall: 0.2885 - fbeta_score: 0.2984 - val_loss: 2.5974 - val_acc: 0.9561 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 1s 276us/step - loss: 2.4513 - acc: 0.9799 - recall: 0.3156 - fbeta_score: 0.3234 - val_loss: 2.5547 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 38/500\n",
      "1843/1843 [==============================] - 0s 262us/step - loss: 2.4046 - acc: 0.9799 - recall: 0.3219 - fbeta_score: 0.3216 - val_loss: 2.4990 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 39/500\n",
      "1843/1843 [==============================] - 0s 258us/step - loss: 2.3551 - acc: 0.9837 - recall: 0.3491 - fbeta_score: 0.3554 - val_loss: 2.4651 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 40/500\n",
      "1843/1843 [==============================] - 0s 264us/step - loss: 2.3172 - acc: 0.9810 - recall: 0.2975 - fbeta_score: 0.3066 - val_loss: 2.4203 - val_acc: 0.9366 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 41/500\n",
      "1843/1843 [==============================] - 0s 265us/step - loss: 2.2842 - acc: 0.9772 - recall: 0.3020 - fbeta_score: 0.3100 - val_loss: 2.4354 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 42/500\n",
      "1843/1843 [==============================] - 0s 264us/step - loss: 2.2600 - acc: 0.9674 - recall: 0.2288 - fbeta_score: 0.2395 - val_loss: 2.3473 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 43/500\n",
      "1843/1843 [==============================] - 1s 279us/step - loss: 2.2023 - acc: 0.9767 - recall: 0.3002 - fbeta_score: 0.3107 - val_loss: 2.3540 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 44/500\n",
      "1843/1843 [==============================] - 0s 269us/step - loss: 2.1701 - acc: 0.9729 - recall: 0.2831 - fbeta_score: 0.2892 - val_loss: 2.2675 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 45/500\n",
      "1843/1843 [==============================] - 1s 332us/step - loss: 2.1207 - acc: 0.9788 - recall: 0.3057 - fbeta_score: 0.3100 - val_loss: 2.2532 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 46/500\n",
      "1843/1843 [==============================] - 0s 264us/step - loss: 2.0859 - acc: 0.9767 - recall: 0.3002 - fbeta_score: 0.3071 - val_loss: 2.1992 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 47/500\n",
      "1843/1843 [==============================] - 1s 322us/step - loss: 2.0299 - acc: 0.9848 - recall: 0.3744 - fbeta_score: 0.3796 - val_loss: 2.1774 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 48/500\n",
      "1843/1843 [==============================] - 0s 265us/step - loss: 1.9994 - acc: 0.9799 - recall: 0.3364 - fbeta_score: 0.3382 - val_loss: 2.0917 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 49/500\n",
      "1843/1843 [==============================] - 1s 284us/step - loss: 1.9577 - acc: 0.9788 - recall: 0.3464 - fbeta_score: 0.3552 - val_loss: 2.0655 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 50/500\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 1.9353 - acc: 0.9772 - recall: 0.2831 - fbeta_score: 0.2894 - val_loss: 2.0908 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 51/500\n",
      "1843/1843 [==============================] - 1s 272us/step - loss: 1.8978 - acc: 0.9745 - recall: 0.3002 - fbeta_score: 0.3062 - val_loss: 1.9988 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 52/500\n",
      "1843/1843 [==============================] - 1s 303us/step - loss: 1.8557 - acc: 0.9767 - recall: 0.3066 - fbeta_score: 0.3120 - val_loss: 1.9529 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 53/500\n",
      "1843/1843 [==============================] - 1s 393us/step - loss: 1.8123 - acc: 0.9761 - recall: 0.2984 - fbeta_score: 0.3039 - val_loss: 1.9112 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 54/500\n",
      "1843/1843 [==============================] - 1s 290us/step - loss: 1.7720 - acc: 0.9810 - recall: 0.3346 - fbeta_score: 0.3389 - val_loss: 1.9103 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 55/500\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 1.7510 - acc: 0.9783 - recall: 0.3201 - fbeta_score: 0.3252 - val_loss: 1.8462 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2033\n",
      "Epoch 56/500\n",
      "1843/1843 [==============================] - 1s 285us/step - loss: 1.7143 - acc: 0.9761 - recall: 0.2948 - fbeta_score: 0.3017 - val_loss: 1.8536 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 57/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 1.7011 - acc: 0.9712 - recall: 0.3111 - fbeta_score: 0.3138 - val_loss: 1.8408 - val_acc: 0.9317 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 58/500\n",
      "1843/1843 [==============================] - 0s 256us/step - loss: 1.6538 - acc: 0.9750 - recall: 0.2849 - fbeta_score: 0.2858 - val_loss: 1.7471 - val_acc: 0.9512 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 59/500\n",
      "1843/1843 [==============================] - 1s 361us/step - loss: 1.6304 - acc: 0.9767 - recall: 0.3002 - fbeta_score: 0.3064 - val_loss: 1.8155 - val_acc: 0.9268 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 60/500\n",
      "1843/1843 [==============================] - 1s 277us/step - loss: 1.6140 - acc: 0.9756 - recall: 0.3283 - fbeta_score: 0.3254 - val_loss: 1.6997 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 61/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 1.5802 - acc: 0.9718 - recall: 0.2785 - fbeta_score: 0.2812 - val_loss: 1.6759 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 62/500\n",
      "1843/1843 [==============================] - 0s 250us/step - loss: 1.5352 - acc: 0.9772 - recall: 0.2867 - fbeta_score: 0.2991 - val_loss: 1.6483 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 63/500\n",
      "1843/1843 [==============================] - 0s 252us/step - loss: 1.5105 - acc: 0.9729 - recall: 0.2831 - fbeta_score: 0.2910 - val_loss: 1.6977 - val_acc: 0.9268 - val_recall: 0.3171 - val_fbeta_score: 0.2846\n",
      "Epoch 64/500\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 1.4845 - acc: 0.9729 - recall: 0.3066 - fbeta_score: 0.3129 - val_loss: 1.5655 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 65/500\n",
      "1843/1843 [==============================] - 1s 302us/step - loss: 1.4371 - acc: 0.9783 - recall: 0.3147 - fbeta_score: 0.3201 - val_loss: 1.5367 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 66/500\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 1.4032 - acc: 0.9772 - recall: 0.3256 - fbeta_score: 0.3290 - val_loss: 1.5776 - val_acc: 0.9268 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 67/500\n",
      "1843/1843 [==============================] - 0s 263us/step - loss: 1.3912 - acc: 0.9658 - recall: 0.2686 - fbeta_score: 0.2698 - val_loss: 1.5028 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 68/500\n",
      "1843/1843 [==============================] - 0s 242us/step - loss: 1.3462 - acc: 0.9761 - recall: 0.3174 - fbeta_score: 0.3212 - val_loss: 1.5129 - val_acc: 0.9366 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 69/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 1.3232 - acc: 0.9772 - recall: 0.2966 - fbeta_score: 0.3020 - val_loss: 1.6319 - val_acc: 0.8927 - val_recall: 0.0976 - val_fbeta_score: 0.0813\n",
      "Epoch 70/500\n",
      "1843/1843 [==============================] - 0s 256us/step - loss: 1.3215 - acc: 0.9685 - recall: 0.2672 - fbeta_score: 0.2715 - val_loss: 1.4090 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 71/500\n",
      "1843/1843 [==============================] - 0s 264us/step - loss: 1.2737 - acc: 0.9745 - recall: 0.3002 - fbeta_score: 0.3048 - val_loss: 1.4116 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 72/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 1.2297 - acc: 0.9794 - recall: 0.3527 - fbeta_score: 0.3563 - val_loss: 1.3553 - val_acc: 0.9415 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 73/500\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 1.2114 - acc: 0.9740 - recall: 0.2856 - fbeta_score: 0.2845 - val_loss: 1.4942 - val_acc: 0.9024 - val_recall: 0.3659 - val_fbeta_score: 0.3203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 1.2021 - acc: 0.9685 - recall: 0.2894 - fbeta_score: 0.2917 - val_loss: 1.3143 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 75/500\n",
      "1843/1843 [==============================] - 0s 268us/step - loss: 1.1662 - acc: 0.9712 - recall: 0.2903 - fbeta_score: 0.2948 - val_loss: 1.2538 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 76/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 1.1327 - acc: 0.9767 - recall: 0.2993 - fbeta_score: 0.3087 - val_loss: 1.2723 - val_acc: 0.9415 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 77/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 1.1126 - acc: 0.9712 - recall: 0.2966 - fbeta_score: 0.2966 - val_loss: 1.2167 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 78/500\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 1.1014 - acc: 0.9691 - recall: 0.2993 - fbeta_score: 0.3010 - val_loss: 1.3065 - val_acc: 0.9317 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 79/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 1.0950 - acc: 0.9691 - recall: 0.2668 - fbeta_score: 0.2754 - val_loss: 1.1639 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 80/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 1.0313 - acc: 0.9799 - recall: 0.3380 - fbeta_score: 0.3435 - val_loss: 1.1164 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 81/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 1.0286 - acc: 0.9718 - recall: 0.2668 - fbeta_score: 0.2742 - val_loss: 1.1117 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 82/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.9890 - acc: 0.9729 - recall: 0.3002 - fbeta_score: 0.3029 - val_loss: 1.1829 - val_acc: 0.9268 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 83/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.9683 - acc: 0.9745 - recall: 0.3183 - fbeta_score: 0.3201 - val_loss: 1.1288 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 84/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.9705 - acc: 0.9680 - recall: 0.2677 - fbeta_score: 0.2746 - val_loss: 1.1132 - val_acc: 0.9268 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 85/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.9485 - acc: 0.9669 - recall: 0.2641 - fbeta_score: 0.2650 - val_loss: 1.1547 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 86/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.9063 - acc: 0.9761 - recall: 0.3245 - fbeta_score: 0.3254 - val_loss: 0.9867 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 87/500\n",
      "1843/1843 [==============================] - 1s 282us/step - loss: 0.8865 - acc: 0.9723 - recall: 0.2946 - fbeta_score: 0.3037 - val_loss: 0.9839 - val_acc: 0.9463 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 88/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.8866 - acc: 0.9664 - recall: 0.2532 - fbeta_score: 0.2623 - val_loss: 1.0836 - val_acc: 0.9366 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 89/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.8646 - acc: 0.9707 - recall: 0.2966 - fbeta_score: 0.2982 - val_loss: 0.9405 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 90/500\n",
      "1843/1843 [==============================] - 1s 291us/step - loss: 0.8398 - acc: 0.9674 - recall: 0.2604 - fbeta_score: 0.2623 - val_loss: 0.9243 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 91/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.8116 - acc: 0.9729 - recall: 0.3002 - fbeta_score: 0.3071 - val_loss: 0.9945 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 92/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.8141 - acc: 0.9647 - recall: 0.2170 - fbeta_score: 0.2306 - val_loss: 0.9164 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 93/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.7875 - acc: 0.9647 - recall: 0.2598 - fbeta_score: 0.2670 - val_loss: 0.8539 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2634\n",
      "Epoch 94/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.7686 - acc: 0.9696 - recall: 0.2948 - fbeta_score: 0.2921 - val_loss: 0.9110 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 95/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.7599 - acc: 0.9642 - recall: 0.2559 - fbeta_score: 0.2604 - val_loss: 0.8347 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 96/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.7318 - acc: 0.9685 - recall: 0.2523 - fbeta_score: 0.2568 - val_loss: 0.8363 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2520\n",
      "Epoch 97/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.7274 - acc: 0.9680 - recall: 0.2451 - fbeta_score: 0.2496 - val_loss: 0.8505 - val_acc: 0.9415 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 98/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.7150 - acc: 0.9674 - recall: 0.2572 - fbeta_score: 0.2670 - val_loss: 0.8358 - val_acc: 0.9610 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 99/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.6968 - acc: 0.9647 - recall: 0.2731 - fbeta_score: 0.2756 - val_loss: 0.8250 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 100/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.6825 - acc: 0.9707 - recall: 0.2668 - fbeta_score: 0.2758 - val_loss: 0.7630 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 101/500\n",
      "1843/1843 [==============================] - 1s 275us/step - loss: 0.6687 - acc: 0.9653 - recall: 0.2613 - fbeta_score: 0.2666 - val_loss: 0.7798 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 102/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.6460 - acc: 0.9696 - recall: 0.2659 - fbeta_score: 0.2755 - val_loss: 0.7894 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 103/500\n",
      "1843/1843 [==============================] - 0s 255us/step - loss: 0.6399 - acc: 0.9653 - recall: 0.2568 - fbeta_score: 0.2577 - val_loss: 0.7643 - val_acc: 0.9317 - val_recall: 0.2683 - val_fbeta_score: 0.2683\n",
      "Epoch 104/500\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 0.6320 - acc: 0.9626 - recall: 0.2431 - fbeta_score: 0.2454 - val_loss: 0.7153 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2195\n",
      "Epoch 105/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.6253 - acc: 0.9615 - recall: 0.2107 - fbeta_score: 0.2201 - val_loss: 0.7775 - val_acc: 0.9268 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 106/500\n",
      "1843/1843 [==============================] - 1s 292us/step - loss: 0.6161 - acc: 0.9647 - recall: 0.2315 - fbeta_score: 0.2330 - val_loss: 0.7357 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 107/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.5787 - acc: 0.9723 - recall: 0.3093 - fbeta_score: 0.3093 - val_loss: 0.7201 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 108/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.5738 - acc: 0.9680 - recall: 0.2704 - fbeta_score: 0.2722 - val_loss: 0.6757 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 109/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.5622 - acc: 0.9674 - recall: 0.2451 - fbeta_score: 0.2519 - val_loss: 0.6387 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.5651 - acc: 0.9653 - recall: 0.2442 - fbeta_score: 0.2469 - val_loss: 0.6391 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 111/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.5433 - acc: 0.9691 - recall: 0.2686 - fbeta_score: 0.2686 - val_loss: 0.7681 - val_acc: 0.9220 - val_recall: 0.1707 - val_fbeta_score: 0.1626\n",
      "Epoch 112/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.5490 - acc: 0.9636 - recall: 0.2577 - fbeta_score: 0.2550 - val_loss: 0.6610 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 113/500\n",
      "1843/1843 [==============================] - 0s 220us/step - loss: 0.5244 - acc: 0.9696 - recall: 0.2566 - fbeta_score: 0.2630 - val_loss: 0.6143 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 114/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.5254 - acc: 0.9669 - recall: 0.2613 - fbeta_score: 0.2601 - val_loss: 0.6456 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 115/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.5249 - acc: 0.9598 - recall: 0.2125 - fbeta_score: 0.2207 - val_loss: 0.8435 - val_acc: 0.8732 - val_recall: 0.3659 - val_fbeta_score: 0.3073\n",
      "Epoch 116/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.5412 - acc: 0.9544 - recall: 0.2012 - fbeta_score: 0.2038 - val_loss: 0.5985 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 117/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.5016 - acc: 0.9669 - recall: 0.2555 - fbeta_score: 0.2615 - val_loss: 0.6109 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 118/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.4871 - acc: 0.9636 - recall: 0.2396 - fbeta_score: 0.2413 - val_loss: 0.5750 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 119/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.4700 - acc: 0.9707 - recall: 0.2867 - fbeta_score: 0.2908 - val_loss: 0.5916 - val_acc: 0.9317 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 120/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.4665 - acc: 0.9680 - recall: 0.2713 - fbeta_score: 0.2758 - val_loss: 0.5618 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 121/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.4569 - acc: 0.9664 - recall: 0.2478 - fbeta_score: 0.2514 - val_loss: 0.5556 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 122/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.4550 - acc: 0.9636 - recall: 0.2232 - fbeta_score: 0.2235 - val_loss: 0.5366 - val_acc: 0.9463 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 123/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.4492 - acc: 0.9658 - recall: 0.2458 - fbeta_score: 0.2530 - val_loss: 0.5109 - val_acc: 0.9512 - val_recall: 0.2683 - val_fbeta_score: 0.2683\n",
      "Epoch 124/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.4376 - acc: 0.9696 - recall: 0.2677 - fbeta_score: 0.2758 - val_loss: 0.5334 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 125/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.4377 - acc: 0.9691 - recall: 0.2591 - fbeta_score: 0.2626 - val_loss: 0.5294 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 126/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.4259 - acc: 0.9674 - recall: 0.2749 - fbeta_score: 0.2765 - val_loss: 0.5434 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 127/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.4258 - acc: 0.9609 - recall: 0.2324 - fbeta_score: 0.2396 - val_loss: 0.6257 - val_acc: 0.9024 - val_recall: 0.3171 - val_fbeta_score: 0.2927\n",
      "Epoch 128/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 0.4080 - acc: 0.9664 - recall: 0.2776 - fbeta_score: 0.2845 - val_loss: 0.5709 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 129/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.4028 - acc: 0.9696 - recall: 0.2623 - fbeta_score: 0.2650 - val_loss: 0.5937 - val_acc: 0.9317 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 130/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.4198 - acc: 0.9674 - recall: 0.2695 - fbeta_score: 0.2784 - val_loss: 0.5339 - val_acc: 0.9317 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 131/500\n",
      "1843/1843 [==============================] - 1s 299us/step - loss: 0.4206 - acc: 0.9598 - recall: 0.2062 - fbeta_score: 0.2107 - val_loss: 0.4722 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 132/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.4014 - acc: 0.9647 - recall: 0.2496 - fbeta_score: 0.2545 - val_loss: 0.5873 - val_acc: 0.9415 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 133/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.3992 - acc: 0.9593 - recall: 0.2270 - fbeta_score: 0.2297 - val_loss: 0.5023 - val_acc: 0.9415 - val_recall: 0.0244 - val_fbeta_score: 0.0325\n",
      "Epoch 134/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.3842 - acc: 0.9647 - recall: 0.2387 - fbeta_score: 0.2405 - val_loss: 0.4711 - val_acc: 0.9366 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 135/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.3989 - acc: 0.9577 - recall: 0.2044 - fbeta_score: 0.2132 - val_loss: 0.4674 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 136/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.3771 - acc: 0.9664 - recall: 0.2577 - fbeta_score: 0.2623 - val_loss: 0.4506 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 137/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 0.3845 - acc: 0.9664 - recall: 0.2234 - fbeta_score: 0.2311 - val_loss: 0.4457 - val_acc: 0.9512 - val_recall: 0.2927 - val_fbeta_score: 0.3008\n",
      "Epoch 138/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 0.3669 - acc: 0.9620 - recall: 0.2532 - fbeta_score: 0.2557 - val_loss: 0.5453 - val_acc: 0.9317 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 139/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.3934 - acc: 0.9626 - recall: 0.2387 - fbeta_score: 0.2458 - val_loss: 0.5225 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 140/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.3662 - acc: 0.9696 - recall: 0.2604 - fbeta_score: 0.2623 - val_loss: 0.4544 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 141/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.3735 - acc: 0.9653 - recall: 0.2342 - fbeta_score: 0.2449 - val_loss: 0.4319 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 142/500\n",
      "1843/1843 [==============================] - 0s 254us/step - loss: 0.3506 - acc: 0.9680 - recall: 0.2577 - fbeta_score: 0.2612 - val_loss: 0.4419 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 143/500\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.3743 - acc: 0.9598 - recall: 0.2107 - fbeta_score: 0.2114 - val_loss: 0.4772 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 144/500\n",
      "1843/1843 [==============================] - 0s 268us/step - loss: 0.3448 - acc: 0.9674 - recall: 0.2686 - fbeta_score: 0.2713 - val_loss: 0.4379 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 145/500\n",
      "1843/1843 [==============================] - 0s 266us/step - loss: 0.3527 - acc: 0.9615 - recall: 0.2433 - fbeta_score: 0.2433 - val_loss: 0.4529 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 146/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.3439 - acc: 0.9642 - recall: 0.2396 - fbeta_score: 0.2485 - val_loss: 0.4676 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 147/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.3443 - acc: 0.9626 - recall: 0.2442 - fbeta_score: 0.2440 - val_loss: 0.4781 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 148/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.3181 - acc: 0.9712 - recall: 0.2840 - fbeta_score: 0.2921 - val_loss: 0.4254 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 149/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.3174 - acc: 0.9680 - recall: 0.2395 - fbeta_score: 0.2467 - val_loss: 0.3979 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 150/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.3219 - acc: 0.9615 - recall: 0.2243 - fbeta_score: 0.2324 - val_loss: 0.3919 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 151/500\n",
      "1843/1843 [==============================] - 1s 310us/step - loss: 0.3149 - acc: 0.9691 - recall: 0.2532 - fbeta_score: 0.2550 - val_loss: 0.4295 - val_acc: 0.9512 - val_recall: 0.3415 - val_fbeta_score: 0.3415\n",
      "Epoch 152/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.3304 - acc: 0.9609 - recall: 0.2223 - fbeta_score: 0.2268 - val_loss: 0.3747 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 153/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.3092 - acc: 0.9658 - recall: 0.2609 - fbeta_score: 0.2644 - val_loss: 0.4255 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2520\n",
      "Epoch 154/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.3142 - acc: 0.9669 - recall: 0.2849 - fbeta_score: 0.2876 - val_loss: 0.4258 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 155/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.3029 - acc: 0.9631 - recall: 0.2460 - fbeta_score: 0.2496 - val_loss: 0.4057 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 156/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.2935 - acc: 0.9669 - recall: 0.2594 - fbeta_score: 0.2621 - val_loss: 0.3858 - val_acc: 0.9610 - val_recall: 0.3659 - val_fbeta_score: 0.3659\n",
      "Epoch 157/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.2995 - acc: 0.9685 - recall: 0.2650 - fbeta_score: 0.2727 - val_loss: 0.3709 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 158/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.2967 - acc: 0.9642 - recall: 0.2225 - fbeta_score: 0.2279 - val_loss: 0.3873 - val_acc: 0.9366 - val_recall: 0.2439 - val_fbeta_score: 0.2520\n",
      "Epoch 159/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.2825 - acc: 0.9734 - recall: 0.2840 - fbeta_score: 0.2892 - val_loss: 0.4300 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 160/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.3160 - acc: 0.9593 - recall: 0.2179 - fbeta_score: 0.2160 - val_loss: 0.3969 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 161/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.2937 - acc: 0.9653 - recall: 0.2428 - fbeta_score: 0.2500 - val_loss: 0.3537 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 162/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.3012 - acc: 0.9658 - recall: 0.2559 - fbeta_score: 0.2576 - val_loss: 0.3834 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 163/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.2835 - acc: 0.9680 - recall: 0.2487 - fbeta_score: 0.2566 - val_loss: 0.3820 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 164/500\n",
      "1843/1843 [==============================] - ETA: 0s - loss: 0.2883 - acc: 0.9674 - recall: 0.2835 - fbeta_score: 0.28 - 0s 245us/step - loss: 0.2882 - acc: 0.9674 - recall: 0.2831 - fbeta_score: 0.2840 - val_loss: 0.3756 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 165/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.2734 - acc: 0.9712 - recall: 0.2912 - fbeta_score: 0.2955 - val_loss: 0.3559 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 166/500\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 0.2731 - acc: 0.9680 - recall: 0.2704 - fbeta_score: 0.2722 - val_loss: 0.4087 - val_acc: 0.9415 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 167/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.2795 - acc: 0.9636 - recall: 0.2243 - fbeta_score: 0.2293 - val_loss: 0.3386 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 168/500\n",
      "1843/1843 [==============================] - 0s 260us/step - loss: 0.2700 - acc: 0.9680 - recall: 0.2478 - fbeta_score: 0.2532 - val_loss: 0.3701 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 169/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.2682 - acc: 0.9702 - recall: 0.2812 - fbeta_score: 0.2881 - val_loss: 0.3411 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 170/500\n",
      "1843/1843 [==============================] - 0s 260us/step - loss: 0.2522 - acc: 0.9669 - recall: 0.2568 - fbeta_score: 0.2626 - val_loss: 0.3728 - val_acc: 0.9317 - val_recall: 0.2439 - val_fbeta_score: 0.2520\n",
      "Epoch 171/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.2583 - acc: 0.9696 - recall: 0.2550 - fbeta_score: 0.2657 - val_loss: 0.3332 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 172/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.2668 - acc: 0.9664 - recall: 0.2546 - fbeta_score: 0.2577 - val_loss: 0.3870 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 173/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.2623 - acc: 0.9680 - recall: 0.2641 - fbeta_score: 0.2677 - val_loss: 0.3710 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 174/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.2638 - acc: 0.9664 - recall: 0.2541 - fbeta_score: 0.2559 - val_loss: 0.3274 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 175/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.2621 - acc: 0.9588 - recall: 0.2216 - fbeta_score: 0.2297 - val_loss: 0.3559 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 176/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.2447 - acc: 0.9691 - recall: 0.2758 - fbeta_score: 0.2831 - val_loss: 0.3397 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 177/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.2509 - acc: 0.9696 - recall: 0.2627 - fbeta_score: 0.2717 - val_loss: 0.3670 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 178/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.2494 - acc: 0.9685 - recall: 0.2469 - fbeta_score: 0.2503 - val_loss: 0.3053 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 179/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.2420 - acc: 0.9674 - recall: 0.2776 - fbeta_score: 0.2829 - val_loss: 0.3376 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 180/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.2366 - acc: 0.9702 - recall: 0.2677 - fbeta_score: 0.2729 - val_loss: 0.2856 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 181/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.2335 - acc: 0.9691 - recall: 0.2469 - fbeta_score: 0.2532 - val_loss: 0.4943 - val_acc: 0.8878 - val_recall: 0.3659 - val_fbeta_score: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.2483 - acc: 0.9647 - recall: 0.2586 - fbeta_score: 0.2641 - val_loss: 0.3277 - val_acc: 0.9463 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 183/500\n",
      "1843/1843 [==============================] - 1s 295us/step - loss: 0.2444 - acc: 0.9615 - recall: 0.2216 - fbeta_score: 0.2243 - val_loss: 0.3311 - val_acc: 0.9415 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 184/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.2311 - acc: 0.9696 - recall: 0.2690 - fbeta_score: 0.2708 - val_loss: 0.3526 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 185/500\n",
      "1843/1843 [==============================] - 0s 271us/step - loss: 0.2374 - acc: 0.9669 - recall: 0.2261 - fbeta_score: 0.2349 - val_loss: 0.3150 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 186/500\n",
      "1843/1843 [==============================] - 1s 273us/step - loss: 0.2386 - acc: 0.9669 - recall: 0.2433 - fbeta_score: 0.2487 - val_loss: 0.3242 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 187/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.2209 - acc: 0.9740 - recall: 0.2892 - fbeta_score: 0.2928 - val_loss: 0.3328 - val_acc: 0.9512 - val_recall: 0.3171 - val_fbeta_score: 0.3171\n",
      "Epoch 188/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.2327 - acc: 0.9680 - recall: 0.2378 - fbeta_score: 0.2373 - val_loss: 0.3174 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 189/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.2298 - acc: 0.9685 - recall: 0.2387 - fbeta_score: 0.2422 - val_loss: 0.3212 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 190/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 0.2037 - acc: 0.9740 - recall: 0.2821 - fbeta_score: 0.2912 - val_loss: 0.2897 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 191/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.2061 - acc: 0.9734 - recall: 0.2849 - fbeta_score: 0.2946 - val_loss: 0.2863 - val_acc: 0.9659 - val_recall: 0.4146 - val_fbeta_score: 0.4228\n",
      "Epoch 192/500\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 0.2197 - acc: 0.9680 - recall: 0.2758 - fbeta_score: 0.2758 - val_loss: 0.2777 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 193/500\n",
      "1843/1843 [==============================] - 0s 252us/step - loss: 0.2197 - acc: 0.9636 - recall: 0.2451 - fbeta_score: 0.2521 - val_loss: 0.3557 - val_acc: 0.9366 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 194/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.2151 - acc: 0.9707 - recall: 0.2478 - fbeta_score: 0.2539 - val_loss: 0.2573 - val_acc: 0.9659 - val_recall: 0.3171 - val_fbeta_score: 0.3171\n",
      "Epoch 195/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.2029 - acc: 0.9702 - recall: 0.2315 - fbeta_score: 0.2357 - val_loss: 0.2998 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 196/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.2082 - acc: 0.9674 - recall: 0.2627 - fbeta_score: 0.2688 - val_loss: 0.2844 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 197/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.2125 - acc: 0.9664 - recall: 0.2623 - fbeta_score: 0.2686 - val_loss: 0.4220 - val_acc: 0.9317 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 198/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.2082 - acc: 0.9680 - recall: 0.2785 - fbeta_score: 0.2831 - val_loss: 0.3217 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 199/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.2051 - acc: 0.9718 - recall: 0.2826 - fbeta_score: 0.2906 - val_loss: 0.2582 - val_acc: 0.9561 - val_recall: 0.3171 - val_fbeta_score: 0.3171\n",
      "Epoch 200/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.2117 - acc: 0.9685 - recall: 0.2333 - fbeta_score: 0.2396 - val_loss: 0.3317 - val_acc: 0.9073 - val_recall: 0.2683 - val_fbeta_score: 0.2439\n",
      "Epoch 201/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.2016 - acc: 0.9712 - recall: 0.2677 - fbeta_score: 0.2722 - val_loss: 0.6395 - val_acc: 0.8146 - val_recall: 0.2683 - val_fbeta_score: 0.1984\n",
      "Epoch 202/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.2210 - acc: 0.9642 - recall: 0.2270 - fbeta_score: 0.2292 - val_loss: 0.2959 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2520\n",
      "Epoch 203/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.2057 - acc: 0.9685 - recall: 0.2912 - fbeta_score: 0.2901 - val_loss: 0.2716 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2033\n",
      "Epoch 204/500\n",
      "1843/1843 [==============================] - 0s 250us/step - loss: 0.2022 - acc: 0.9718 - recall: 0.2686 - fbeta_score: 0.2803 - val_loss: 0.2949 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 205/500\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.1986 - acc: 0.9685 - recall: 0.2564 - fbeta_score: 0.2606 - val_loss: 0.2765 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 206/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.1966 - acc: 0.9691 - recall: 0.2686 - fbeta_score: 0.2735 - val_loss: 0.2768 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 207/500\n",
      "1843/1843 [==============================] - 1s 303us/step - loss: 0.2081 - acc: 0.9653 - recall: 0.2396 - fbeta_score: 0.2509 - val_loss: 0.2839 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 208/500\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 0.1905 - acc: 0.9707 - recall: 0.2686 - fbeta_score: 0.2713 - val_loss: 0.2662 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 209/500\n",
      "1843/1843 [==============================] - 0s 242us/step - loss: 0.1798 - acc: 0.9750 - recall: 0.2876 - fbeta_score: 0.2930 - val_loss: 0.2627 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 210/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.1873 - acc: 0.9680 - recall: 0.2541 - fbeta_score: 0.2666 - val_loss: 0.3101 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 211/500\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.1828 - acc: 0.9740 - recall: 0.2550 - fbeta_score: 0.2619 - val_loss: 0.3775 - val_acc: 0.9073 - val_recall: 0.3171 - val_fbeta_score: 0.2846\n",
      "Epoch 212/500\n",
      "1843/1843 [==============================] - 0s 251us/step - loss: 0.1881 - acc: 0.9718 - recall: 0.2803 - fbeta_score: 0.2829 - val_loss: 0.2816 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 213/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1727 - acc: 0.9723 - recall: 0.2650 - fbeta_score: 0.2684 - val_loss: 0.2659 - val_acc: 0.9512 - val_recall: 0.2927 - val_fbeta_score: 0.3008\n",
      "Epoch 214/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1773 - acc: 0.9712 - recall: 0.2867 - fbeta_score: 0.2939 - val_loss: 0.2613 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 215/500\n",
      "1843/1843 [==============================] - 1s 284us/step - loss: 0.1795 - acc: 0.9718 - recall: 0.2876 - fbeta_score: 0.2966 - val_loss: 0.2945 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1545\n",
      "Epoch 216/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.1723 - acc: 0.9718 - recall: 0.2785 - fbeta_score: 0.2847 - val_loss: 0.2696 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 217/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1872 - acc: 0.9642 - recall: 0.2125 - fbeta_score: 0.2196 - val_loss: 0.2496 - val_acc: 0.9463 - val_recall: 0.4146 - val_fbeta_score: 0.3984\n",
      "Epoch 218/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1813 - acc: 0.9685 - recall: 0.2876 - fbeta_score: 0.2876 - val_loss: 0.2889 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 219/500\n",
      "1843/1843 [==============================] - 1s 280us/step - loss: 0.1786 - acc: 0.9669 - recall: 0.2632 - fbeta_score: 0.2704 - val_loss: 0.2750 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 220/500\n",
      "1843/1843 [==============================] - 1s 280us/step - loss: 0.1804 - acc: 0.9631 - recall: 0.2225 - fbeta_score: 0.2223 - val_loss: 0.2762 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 221/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1765 - acc: 0.9696 - recall: 0.2623 - fbeta_score: 0.2668 - val_loss: 0.2376 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2683\n",
      "Epoch 222/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1827 - acc: 0.9680 - recall: 0.2609 - fbeta_score: 0.2635 - val_loss: 0.2948 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 223/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1702 - acc: 0.9680 - recall: 0.2577 - fbeta_score: 0.2623 - val_loss: 0.2678 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 224/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1785 - acc: 0.9691 - recall: 0.2650 - fbeta_score: 0.2704 - val_loss: 0.2303 - val_acc: 0.9512 - val_recall: 0.3171 - val_fbeta_score: 0.3171\n",
      "Epoch 225/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1713 - acc: 0.9723 - recall: 0.2672 - fbeta_score: 0.2762 - val_loss: 0.2917 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 226/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1735 - acc: 0.9691 - recall: 0.2546 - fbeta_score: 0.2543 - val_loss: 0.2587 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 227/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1739 - acc: 0.9674 - recall: 0.2405 - fbeta_score: 0.2492 - val_loss: 0.3598 - val_acc: 0.9415 - val_recall: 0.0488 - val_fbeta_score: 0.0488\n",
      "Epoch 228/500\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.1786 - acc: 0.9653 - recall: 0.2342 - fbeta_score: 0.2369 - val_loss: 0.2669 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 229/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1660 - acc: 0.9707 - recall: 0.2903 - fbeta_score: 0.2912 - val_loss: 0.3201 - val_acc: 0.9268 - val_recall: 0.4146 - val_fbeta_score: 0.3528\n",
      "Epoch 230/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1685 - acc: 0.9680 - recall: 0.2758 - fbeta_score: 0.2776 - val_loss: 0.2881 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 231/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1697 - acc: 0.9702 - recall: 0.2604 - fbeta_score: 0.2675 - val_loss: 0.2673 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 232/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1632 - acc: 0.9723 - recall: 0.2568 - fbeta_score: 0.2632 - val_loss: 0.2997 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 233/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1603 - acc: 0.9696 - recall: 0.2677 - fbeta_score: 0.2740 - val_loss: 0.2609 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 234/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1623 - acc: 0.9707 - recall: 0.2704 - fbeta_score: 0.2758 - val_loss: 0.2583 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2520\n",
      "Epoch 235/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1673 - acc: 0.9696 - recall: 0.2704 - fbeta_score: 0.2793 - val_loss: 0.2392 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 236/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1563 - acc: 0.9718 - recall: 0.2745 - fbeta_score: 0.2798 - val_loss: 0.2752 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 237/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1646 - acc: 0.9685 - recall: 0.2695 - fbeta_score: 0.2747 - val_loss: 0.2797 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 238/500\n",
      "1843/1843 [==============================] - 1s 296us/step - loss: 0.1643 - acc: 0.9680 - recall: 0.2514 - fbeta_score: 0.2563 - val_loss: 0.2895 - val_acc: 0.9415 - val_recall: 0.3902 - val_fbeta_score: 0.3984\n",
      "Epoch 239/500\n",
      "1843/1843 [==============================] - 1s 291us/step - loss: 0.1691 - acc: 0.9712 - recall: 0.2743 - fbeta_score: 0.2821 - val_loss: 0.2653 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 240/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1729 - acc: 0.9680 - recall: 0.2471 - fbeta_score: 0.2559 - val_loss: 0.2020 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 241/500\n",
      "1843/1843 [==============================] - 0s 267us/step - loss: 0.1694 - acc: 0.9636 - recall: 0.2460 - fbeta_score: 0.2521 - val_loss: 0.3340 - val_acc: 0.9463 - val_recall: 0.0732 - val_fbeta_score: 0.0813\n",
      "Epoch 242/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1610 - acc: 0.9691 - recall: 0.2550 - fbeta_score: 0.2604 - val_loss: 0.2421 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 243/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1631 - acc: 0.9696 - recall: 0.2424 - fbeta_score: 0.2483 - val_loss: 0.2577 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 244/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1633 - acc: 0.9669 - recall: 0.2261 - fbeta_score: 0.2357 - val_loss: 0.2249 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 245/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1505 - acc: 0.9723 - recall: 0.2731 - fbeta_score: 0.2782 - val_loss: 0.2273 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 246/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1581 - acc: 0.9707 - recall: 0.2713 - fbeta_score: 0.2811 - val_loss: 0.2268 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 247/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1527 - acc: 0.9740 - recall: 0.2559 - fbeta_score: 0.2657 - val_loss: 0.2273 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 248/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1576 - acc: 0.9685 - recall: 0.2609 - fbeta_score: 0.2635 - val_loss: 0.2324 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 249/500\n",
      "1843/1843 [==============================] - 0s 263us/step - loss: 0.1426 - acc: 0.9729 - recall: 0.2948 - fbeta_score: 0.2939 - val_loss: 0.2719 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 250/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.1571 - acc: 0.9723 - recall: 0.2722 - fbeta_score: 0.2773 - val_loss: 0.2163 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 251/500\n",
      "1843/1843 [==============================] - 1s 315us/step - loss: 0.1467 - acc: 0.9723 - recall: 0.2776 - fbeta_score: 0.2863 - val_loss: 0.2620 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 252/500\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.1521 - acc: 0.9712 - recall: 0.2794 - fbeta_score: 0.2840 - val_loss: 0.2060 - val_acc: 0.9659 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 253/500\n",
      "1843/1843 [==============================] - 1s 304us/step - loss: 0.1423 - acc: 0.9696 - recall: 0.2613 - fbeta_score: 0.2711 - val_loss: 0.2012 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 254/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1505 - acc: 0.9718 - recall: 0.2946 - fbeta_score: 0.2982 - val_loss: 0.2175 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2195\n",
      "Epoch 255/500\n",
      "1843/1843 [==============================] - 1s 278us/step - loss: 0.1465 - acc: 0.9685 - recall: 0.2469 - fbeta_score: 0.2541 - val_loss: 0.2336 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 256/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1446 - acc: 0.9702 - recall: 0.2604 - fbeta_score: 0.2657 - val_loss: 0.2690 - val_acc: 0.9317 - val_recall: 0.1951 - val_fbeta_score: 0.2033\n",
      "Epoch 257/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.1435 - acc: 0.9718 - recall: 0.3048 - fbeta_score: 0.3118 - val_loss: 0.2177 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 258/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1481 - acc: 0.9664 - recall: 0.2387 - fbeta_score: 0.2469 - val_loss: 0.2079 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 259/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.1456 - acc: 0.9718 - recall: 0.2849 - fbeta_score: 0.2849 - val_loss: 0.2349 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 260/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1473 - acc: 0.9674 - recall: 0.2586 - fbeta_score: 0.2648 - val_loss: 0.2138 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 261/500\n",
      "1843/1843 [==============================] - ETA: 0s - loss: 0.1592 - acc: 0.9706 - recall: 0.2676 - fbeta_score: 0.27 - 0s 240us/step - loss: 0.1591 - acc: 0.9696 - recall: 0.2668 - fbeta_score: 0.2702 - val_loss: 0.2545 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 262/500\n",
      "1843/1843 [==============================] - 0s 254us/step - loss: 0.1470 - acc: 0.9729 - recall: 0.2632 - fbeta_score: 0.2729 - val_loss: 0.2133 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 263/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1462 - acc: 0.9691 - recall: 0.2677 - fbeta_score: 0.2702 - val_loss: 0.2385 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 264/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1364 - acc: 0.9750 - recall: 0.2749 - fbeta_score: 0.2840 - val_loss: 0.2366 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 265/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1423 - acc: 0.9658 - recall: 0.2365 - fbeta_score: 0.2427 - val_loss: 0.1889 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 266/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1359 - acc: 0.9745 - recall: 0.2885 - fbeta_score: 0.2939 - val_loss: 0.2216 - val_acc: 0.9463 - val_recall: 0.3659 - val_fbeta_score: 0.3659\n",
      "Epoch 267/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1510 - acc: 0.9669 - recall: 0.2333 - fbeta_score: 0.2431 - val_loss: 0.1965 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 268/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1291 - acc: 0.9778 - recall: 0.2821 - fbeta_score: 0.2930 - val_loss: 0.2003 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 269/500\n",
      "1843/1843 [==============================] - 1s 283us/step - loss: 0.1439 - acc: 0.9707 - recall: 0.2613 - fbeta_score: 0.2657 - val_loss: 0.2084 - val_acc: 0.9610 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 270/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1383 - acc: 0.9691 - recall: 0.2740 - fbeta_score: 0.2831 - val_loss: 0.2495 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 271/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1493 - acc: 0.9712 - recall: 0.2568 - fbeta_score: 0.2630 - val_loss: 0.2289 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 272/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.1389 - acc: 0.9756 - recall: 0.2921 - fbeta_score: 0.2970 - val_loss: 0.2203 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 273/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1426 - acc: 0.9712 - recall: 0.2749 - fbeta_score: 0.2845 - val_loss: 0.1992 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 274/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.1371 - acc: 0.9702 - recall: 0.2576 - fbeta_score: 0.2617 - val_loss: 0.2212 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 275/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1366 - acc: 0.9734 - recall: 0.2758 - fbeta_score: 0.2784 - val_loss: 0.2237 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 276/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.1297 - acc: 0.9740 - recall: 0.2921 - fbeta_score: 0.2981 - val_loss: 0.2318 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 277/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1306 - acc: 0.9729 - recall: 0.2776 - fbeta_score: 0.2856 - val_loss: 0.2334 - val_acc: 0.9366 - val_recall: 0.2195 - val_fbeta_score: 0.1984\n",
      "Epoch 278/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.1323 - acc: 0.9729 - recall: 0.2821 - fbeta_score: 0.2903 - val_loss: 0.2266 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 279/500\n",
      "1843/1843 [==============================] - 1s 294us/step - loss: 0.1358 - acc: 0.9702 - recall: 0.2469 - fbeta_score: 0.2568 - val_loss: 0.2095 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 280/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1393 - acc: 0.9680 - recall: 0.2713 - fbeta_score: 0.2767 - val_loss: 0.2615 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 281/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1305 - acc: 0.9729 - recall: 0.2749 - fbeta_score: 0.2827 - val_loss: 0.2510 - val_acc: 0.9415 - val_recall: 0.3171 - val_fbeta_score: 0.2927\n",
      "Epoch 282/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.1350 - acc: 0.9691 - recall: 0.2630 - fbeta_score: 0.2718 - val_loss: 0.2439 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 283/500\n",
      "1843/1843 [==============================] - 0s 250us/step - loss: 0.1319 - acc: 0.9691 - recall: 0.2722 - fbeta_score: 0.2749 - val_loss: 0.2327 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 284/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.1229 - acc: 0.9761 - recall: 0.3247 - fbeta_score: 0.3252 - val_loss: 0.2109 - val_acc: 0.9610 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 285/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.1349 - acc: 0.9718 - recall: 0.2722 - fbeta_score: 0.2756 - val_loss: 0.2511 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 286/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.1293 - acc: 0.9740 - recall: 0.2650 - fbeta_score: 0.2708 - val_loss: 0.2416 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 287/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.1397 - acc: 0.9723 - recall: 0.2722 - fbeta_score: 0.2789 - val_loss: 0.2842 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 288/500\n",
      "1843/1843 [==============================] - 0s 250us/step - loss: 0.1319 - acc: 0.9702 - recall: 0.2496 - fbeta_score: 0.2603 - val_loss: 0.2143 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 289/500\n",
      "1843/1843 [==============================] - 0s 253us/step - loss: 0.1344 - acc: 0.9707 - recall: 0.2496 - fbeta_score: 0.2577 - val_loss: 0.2410 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 290/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1285 - acc: 0.9729 - recall: 0.2903 - fbeta_score: 0.2984 - val_loss: 0.2287 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 291/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1288 - acc: 0.9734 - recall: 0.2641 - fbeta_score: 0.2746 - val_loss: 0.1989 - val_acc: 0.9707 - val_recall: 0.3659 - val_fbeta_score: 0.3659\n",
      "Epoch 292/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1431 - acc: 0.9702 - recall: 0.2442 - fbeta_score: 0.2465 - val_loss: 0.2175 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 293/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1262 - acc: 0.9734 - recall: 0.2794 - fbeta_score: 0.2811 - val_loss: 0.2476 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 294/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1226 - acc: 0.9734 - recall: 0.2921 - fbeta_score: 0.2948 - val_loss: 0.2504 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2033\n",
      "Epoch 295/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1236 - acc: 0.9729 - recall: 0.2840 - fbeta_score: 0.2867 - val_loss: 0.2434 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 296/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.1396 - acc: 0.9707 - recall: 0.2650 - fbeta_score: 0.2774 - val_loss: 0.2288 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 297/500\n",
      "1843/1843 [==============================] - 1s 292us/step - loss: 0.1324 - acc: 0.9723 - recall: 0.2831 - fbeta_score: 0.2894 - val_loss: 0.2440 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 298/500\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.1327 - acc: 0.9729 - recall: 0.2722 - fbeta_score: 0.2821 - val_loss: 0.2210 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 299/500\n",
      "1843/1843 [==============================] - 1s 286us/step - loss: 0.1253 - acc: 0.9772 - recall: 0.2975 - fbeta_score: 0.3048 - val_loss: 0.3586 - val_acc: 0.8829 - val_recall: 0.3659 - val_fbeta_score: 0.3041\n",
      "Epoch 300/500\n",
      "1843/1843 [==============================] - 1s 321us/step - loss: 0.1534 - acc: 0.9658 - recall: 0.2595 - fbeta_score: 0.2619 - val_loss: 0.2931 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 301/500\n",
      "1843/1843 [==============================] - 1s 278us/step - loss: 0.1396 - acc: 0.9685 - recall: 0.2179 - fbeta_score: 0.2230 - val_loss: 0.2161 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 302/500\n",
      "1843/1843 [==============================] - 1s 287us/step - loss: 0.1354 - acc: 0.9696 - recall: 0.2586 - fbeta_score: 0.2664 - val_loss: 0.1999 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 303/500\n",
      "1843/1843 [==============================] - 0s 268us/step - loss: 0.1380 - acc: 0.9647 - recall: 0.2460 - fbeta_score: 0.2487 - val_loss: 0.2370 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 304/500\n",
      "1843/1843 [==============================] - 0s 268us/step - loss: 0.1329 - acc: 0.9702 - recall: 0.2686 - fbeta_score: 0.2776 - val_loss: 0.2633 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 305/500\n",
      "1843/1843 [==============================] - 1s 281us/step - loss: 0.1344 - acc: 0.9723 - recall: 0.2785 - fbeta_score: 0.2867 - val_loss: 0.2153 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 306/500\n",
      "1843/1843 [==============================] - 1s 280us/step - loss: 0.1286 - acc: 0.9723 - recall: 0.2948 - fbeta_score: 0.3029 - val_loss: 0.2122 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 307/500\n",
      "1843/1843 [==============================] - 1s 280us/step - loss: 0.1316 - acc: 0.9718 - recall: 0.2668 - fbeta_score: 0.2729 - val_loss: 0.2024 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 308/500\n",
      "1843/1843 [==============================] - 1s 280us/step - loss: 0.1254 - acc: 0.9750 - recall: 0.3057 - fbeta_score: 0.3084 - val_loss: 0.2477 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 309/500\n",
      "1843/1843 [==============================] - 1s 298us/step - loss: 0.1295 - acc: 0.9712 - recall: 0.2695 - fbeta_score: 0.2774 - val_loss: 0.2902 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 310/500\n",
      "1843/1843 [==============================] - 1s 279us/step - loss: 0.1361 - acc: 0.9718 - recall: 0.2677 - fbeta_score: 0.2762 - val_loss: 0.2035 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 311/500\n",
      "1843/1843 [==============================] - 1s 276us/step - loss: 0.1331 - acc: 0.9669 - recall: 0.2410 - fbeta_score: 0.2471 - val_loss: 0.2141 - val_acc: 0.9512 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 312/500\n",
      "1843/1843 [==============================] - 1s 307us/step - loss: 0.1286 - acc: 0.9750 - recall: 0.2740 - fbeta_score: 0.2794 - val_loss: 0.2228 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 313/500\n",
      "1843/1843 [==============================] - 1s 286us/step - loss: 0.1305 - acc: 0.9723 - recall: 0.2632 - fbeta_score: 0.2684 - val_loss: 0.2167 - val_acc: 0.9463 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 314/500\n",
      "1843/1843 [==============================] - 1s 279us/step - loss: 0.1319 - acc: 0.9729 - recall: 0.2623 - fbeta_score: 0.2738 - val_loss: 0.2138 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 315/500\n",
      "1843/1843 [==============================] - 1s 286us/step - loss: 0.1233 - acc: 0.9723 - recall: 0.2876 - fbeta_score: 0.2910 - val_loss: 0.2546 - val_acc: 0.9415 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 316/500\n",
      "1843/1843 [==============================] - 1s 285us/step - loss: 0.1298 - acc: 0.9691 - recall: 0.2821 - fbeta_score: 0.2818 - val_loss: 0.2696 - val_acc: 0.9463 - val_recall: 0.0976 - val_fbeta_score: 0.0976\n",
      "Epoch 317/500\n",
      "1843/1843 [==============================] - 1s 381us/step - loss: 0.1335 - acc: 0.9680 - recall: 0.2297 - fbeta_score: 0.2340 - val_loss: 0.2316 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 318/500\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.1299 - acc: 0.9702 - recall: 0.2803 - fbeta_score: 0.2858 - val_loss: 0.2270 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 319/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1260 - acc: 0.9707 - recall: 0.2704 - fbeta_score: 0.2776 - val_loss: 0.2286 - val_acc: 0.9561 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 320/500\n",
      "1843/1843 [==============================] - 0s 263us/step - loss: 0.1274 - acc: 0.9729 - recall: 0.2758 - fbeta_score: 0.2831 - val_loss: 0.2351 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 321/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.1233 - acc: 0.9712 - recall: 0.2840 - fbeta_score: 0.2921 - val_loss: 0.2195 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 322/500\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.1306 - acc: 0.9702 - recall: 0.2641 - fbeta_score: 0.2668 - val_loss: 0.2101 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 323/500\n",
      "1843/1843 [==============================] - 1s 395us/step - loss: 0.1245 - acc: 0.9745 - recall: 0.2912 - fbeta_score: 0.2928 - val_loss: 0.2257 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 324/500\n",
      "1843/1843 [==============================] - 0s 266us/step - loss: 0.1171 - acc: 0.9767 - recall: 0.2998 - fbeta_score: 0.2968 - val_loss: 0.2612 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 325/500\n",
      "1843/1843 [==============================] - 1s 277us/step - loss: 0.1313 - acc: 0.9691 - recall: 0.2776 - fbeta_score: 0.2849 - val_loss: 0.2348 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 269us/step - loss: 0.1259 - acc: 0.9767 - recall: 0.3075 - fbeta_score: 0.3129 - val_loss: 0.2177 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 327/500\n",
      "1843/1843 [==============================] - 0s 265us/step - loss: 0.1257 - acc: 0.9712 - recall: 0.2731 - fbeta_score: 0.2776 - val_loss: 0.2031 - val_acc: 0.9707 - val_recall: 0.3659 - val_fbeta_score: 0.3740\n",
      "Epoch 328/500\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.1291 - acc: 0.9729 - recall: 0.2704 - fbeta_score: 0.2829 - val_loss: 0.2335 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 329/500\n",
      "1843/1843 [==============================] - 0s 261us/step - loss: 0.1277 - acc: 0.9712 - recall: 0.2831 - fbeta_score: 0.2881 - val_loss: 0.2123 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 330/500\n",
      "1843/1843 [==============================] - 1s 284us/step - loss: 0.1163 - acc: 0.9756 - recall: 0.3147 - fbeta_score: 0.3165 - val_loss: 0.2198 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 331/500\n",
      "1843/1843 [==============================] - 1s 324us/step - loss: 0.1317 - acc: 0.9691 - recall: 0.2713 - fbeta_score: 0.2773 - val_loss: 0.2168 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 332/500\n",
      "1843/1843 [==============================] - 0s 262us/step - loss: 0.1270 - acc: 0.9707 - recall: 0.2632 - fbeta_score: 0.2711 - val_loss: 0.2106 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 333/500\n",
      "1843/1843 [==============================] - 0s 263us/step - loss: 0.1208 - acc: 0.9729 - recall: 0.2722 - fbeta_score: 0.2738 - val_loss: 0.2129 - val_acc: 0.9512 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 334/500\n",
      "1843/1843 [==============================] - 0s 262us/step - loss: 0.1294 - acc: 0.9707 - recall: 0.2568 - fbeta_score: 0.2619 - val_loss: 0.2196 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 335/500\n",
      "1843/1843 [==============================] - 0s 271us/step - loss: 0.1270 - acc: 0.9696 - recall: 0.2749 - fbeta_score: 0.2793 - val_loss: 0.2310 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 336/500\n",
      "1843/1843 [==============================] - 0s 262us/step - loss: 0.1228 - acc: 0.9729 - recall: 0.2858 - fbeta_score: 0.2901 - val_loss: 0.2102 - val_acc: 0.9512 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 337/500\n",
      "1843/1843 [==============================] - 0s 264us/step - loss: 0.1247 - acc: 0.9674 - recall: 0.2613 - fbeta_score: 0.2639 - val_loss: 0.2291 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 338/500\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 0.1155 - acc: 0.9761 - recall: 0.2885 - fbeta_score: 0.2919 - val_loss: 0.2365 - val_acc: 0.9463 - val_recall: 0.3171 - val_fbeta_score: 0.3171\n",
      "Epoch 339/500\n",
      "1843/1843 [==============================] - 0s 260us/step - loss: 0.1203 - acc: 0.9707 - recall: 0.2802 - fbeta_score: 0.2780 - val_loss: 0.2237 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 340/500\n",
      "1843/1843 [==============================] - 0s 267us/step - loss: 0.1168 - acc: 0.9772 - recall: 0.3120 - fbeta_score: 0.3174 - val_loss: 0.2191 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 341/500\n",
      "1843/1843 [==============================] - 0s 263us/step - loss: 0.1206 - acc: 0.9734 - recall: 0.2912 - fbeta_score: 0.2954 - val_loss: 0.2095 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 342/500\n",
      "1843/1843 [==============================] - 1s 365us/step - loss: 0.1012 - acc: 0.9805 - recall: 0.3237 - fbeta_score: 0.3317 - val_loss: 0.2669 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 343/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.1246 - acc: 0.9723 - recall: 0.2930 - fbeta_score: 0.3019 - val_loss: 0.2220 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 344/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.1187 - acc: 0.9745 - recall: 0.2675 - fbeta_score: 0.2764 - val_loss: 0.2151 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 345/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1179 - acc: 0.9729 - recall: 0.2821 - fbeta_score: 0.2812 - val_loss: 0.1785 - val_acc: 0.9512 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 346/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.1193 - acc: 0.9718 - recall: 0.2889 - fbeta_score: 0.2868 - val_loss: 0.1910 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 347/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.1189 - acc: 0.9767 - recall: 0.2930 - fbeta_score: 0.3024 - val_loss: 0.2430 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 348/500\n",
      "1843/1843 [==============================] - 1s 339us/step - loss: 0.1326 - acc: 0.9702 - recall: 0.2514 - fbeta_score: 0.2595 - val_loss: 0.1947 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 349/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 0.1104 - acc: 0.9767 - recall: 0.3147 - fbeta_score: 0.3201 - val_loss: 0.2216 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 350/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1137 - acc: 0.9788 - recall: 0.2975 - fbeta_score: 0.3001 - val_loss: 0.2009 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 351/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1211 - acc: 0.9691 - recall: 0.2604 - fbeta_score: 0.2639 - val_loss: 0.1989 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 352/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1150 - acc: 0.9783 - recall: 0.3093 - fbeta_score: 0.3145 - val_loss: 0.2119 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 353/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1048 - acc: 0.9805 - recall: 0.3106 - fbeta_score: 0.3121 - val_loss: 0.2490 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 354/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1192 - acc: 0.9723 - recall: 0.2966 - fbeta_score: 0.2972 - val_loss: 0.2439 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 355/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1134 - acc: 0.9745 - recall: 0.2975 - fbeta_score: 0.3029 - val_loss: 0.2145 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 356/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1094 - acc: 0.9783 - recall: 0.3002 - fbeta_score: 0.3064 - val_loss: 0.2444 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 357/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.1186 - acc: 0.9734 - recall: 0.2984 - fbeta_score: 0.3055 - val_loss: 0.2537 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 358/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1183 - acc: 0.9707 - recall: 0.2550 - fbeta_score: 0.2586 - val_loss: 0.2332 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 359/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.1185 - acc: 0.9750 - recall: 0.2704 - fbeta_score: 0.2780 - val_loss: 0.2159 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 360/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1287 - acc: 0.9718 - recall: 0.2803 - fbeta_score: 0.2876 - val_loss: 0.1716 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 361/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1185 - acc: 0.9712 - recall: 0.2767 - fbeta_score: 0.2784 - val_loss: 0.2187 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 362/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1193 - acc: 0.9729 - recall: 0.2740 - fbeta_score: 0.2849 - val_loss: 0.2027 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 363/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.1158 - acc: 0.9740 - recall: 0.2912 - fbeta_score: 0.2966 - val_loss: 0.2312 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 364/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1344 - acc: 0.9664 - recall: 0.2654 - fbeta_score: 0.2708 - val_loss: 0.2286 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 365/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1140 - acc: 0.9772 - recall: 0.2984 - fbeta_score: 0.3037 - val_loss: 0.2127 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 366/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1175 - acc: 0.9712 - recall: 0.3120 - fbeta_score: 0.3129 - val_loss: 0.2583 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 367/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1205 - acc: 0.9718 - recall: 0.2595 - fbeta_score: 0.2704 - val_loss: 0.2196 - val_acc: 0.9463 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 368/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1080 - acc: 0.9772 - recall: 0.2948 - fbeta_score: 0.2999 - val_loss: 0.2011 - val_acc: 0.9463 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 369/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1151 - acc: 0.9745 - recall: 0.2966 - fbeta_score: 0.3001 - val_loss: 0.2393 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 370/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1186 - acc: 0.9729 - recall: 0.2867 - fbeta_score: 0.2928 - val_loss: 0.2302 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 371/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1200 - acc: 0.9740 - recall: 0.2826 - fbeta_score: 0.2943 - val_loss: 0.1916 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 372/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1303 - acc: 0.9718 - recall: 0.2776 - fbeta_score: 0.2847 - val_loss: 0.2201 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 373/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1179 - acc: 0.9718 - recall: 0.2785 - fbeta_score: 0.2829 - val_loss: 0.2268 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 374/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.1206 - acc: 0.9772 - recall: 0.3025 - fbeta_score: 0.3069 - val_loss: 0.2079 - val_acc: 0.9512 - val_recall: 0.2683 - val_fbeta_score: 0.2683\n",
      "Epoch 375/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1152 - acc: 0.9691 - recall: 0.2758 - fbeta_score: 0.2767 - val_loss: 0.2331 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 376/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1147 - acc: 0.9750 - recall: 0.2713 - fbeta_score: 0.2784 - val_loss: 0.2659 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 377/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1172 - acc: 0.9723 - recall: 0.2695 - fbeta_score: 0.2735 - val_loss: 0.2255 - val_acc: 0.9561 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 378/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1166 - acc: 0.9761 - recall: 0.2966 - fbeta_score: 0.3001 - val_loss: 0.2055 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 379/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1148 - acc: 0.9761 - recall: 0.3011 - fbeta_score: 0.3057 - val_loss: 0.2300 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 380/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1122 - acc: 0.9723 - recall: 0.2867 - fbeta_score: 0.2878 - val_loss: 0.2076 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 381/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1201 - acc: 0.9685 - recall: 0.2912 - fbeta_score: 0.2937 - val_loss: 0.2271 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 382/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1105 - acc: 0.9767 - recall: 0.2776 - fbeta_score: 0.2821 - val_loss: 0.2203 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 383/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1069 - acc: 0.9772 - recall: 0.3237 - fbeta_score: 0.3272 - val_loss: 0.2502 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 384/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1138 - acc: 0.9734 - recall: 0.3228 - fbeta_score: 0.3218 - val_loss: 0.2318 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 385/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1090 - acc: 0.9729 - recall: 0.2939 - fbeta_score: 0.2928 - val_loss: 0.2348 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 386/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1162 - acc: 0.9767 - recall: 0.2921 - fbeta_score: 0.2979 - val_loss: 0.2299 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 387/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1170 - acc: 0.9729 - recall: 0.2912 - fbeta_score: 0.2981 - val_loss: 0.2355 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 388/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1199 - acc: 0.9734 - recall: 0.2794 - fbeta_score: 0.2874 - val_loss: 0.2211 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 389/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.1120 - acc: 0.9772 - recall: 0.2831 - fbeta_score: 0.2930 - val_loss: 0.2242 - val_acc: 0.9561 - val_recall: 0.2439 - val_fbeta_score: 0.2520\n",
      "Epoch 390/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1161 - acc: 0.9740 - recall: 0.2862 - fbeta_score: 0.2896 - val_loss: 0.2388 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1463\n",
      "Epoch 391/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1174 - acc: 0.9750 - recall: 0.3133 - fbeta_score: 0.3221 - val_loss: 0.2814 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 392/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1195 - acc: 0.9729 - recall: 0.2460 - fbeta_score: 0.2557 - val_loss: 0.2024 - val_acc: 0.9756 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 393/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1140 - acc: 0.9767 - recall: 0.2803 - fbeta_score: 0.2858 - val_loss: 0.2418 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 394/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1150 - acc: 0.9767 - recall: 0.2821 - fbeta_score: 0.2908 - val_loss: 0.2383 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 395/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1166 - acc: 0.9723 - recall: 0.2514 - fbeta_score: 0.2563 - val_loss: 0.2384 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 396/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1149 - acc: 0.9745 - recall: 0.2957 - fbeta_score: 0.3002 - val_loss: 0.2639 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 397/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1213 - acc: 0.9702 - recall: 0.2478 - fbeta_score: 0.2585 - val_loss: 0.2246 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1151 - acc: 0.9772 - recall: 0.2975 - fbeta_score: 0.3049 - val_loss: 0.2410 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 399/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1141 - acc: 0.9761 - recall: 0.2758 - fbeta_score: 0.2847 - val_loss: 0.2009 - val_acc: 0.9756 - val_recall: 0.3659 - val_fbeta_score: 0.3740\n",
      "Epoch 400/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.1184 - acc: 0.9696 - recall: 0.2803 - fbeta_score: 0.2791 - val_loss: 0.2087 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 401/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1051 - acc: 0.9783 - recall: 0.3183 - fbeta_score: 0.3198 - val_loss: 0.2377 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 402/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1220 - acc: 0.9745 - recall: 0.2623 - fbeta_score: 0.2668 - val_loss: 0.2371 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 403/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1061 - acc: 0.9788 - recall: 0.3029 - fbeta_score: 0.3066 - val_loss: 0.2221 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 404/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1059 - acc: 0.9767 - recall: 0.2975 - fbeta_score: 0.3066 - val_loss: 0.2925 - val_acc: 0.9073 - val_recall: 0.3659 - val_fbeta_score: 0.3203\n",
      "Epoch 405/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1237 - acc: 0.9712 - recall: 0.2767 - fbeta_score: 0.2840 - val_loss: 0.2310 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 406/500\n",
      "1843/1843 [==============================] - 0s 215us/step - loss: 0.1233 - acc: 0.9723 - recall: 0.2925 - fbeta_score: 0.2977 - val_loss: 0.2453 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 407/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1172 - acc: 0.9723 - recall: 0.3029 - fbeta_score: 0.3010 - val_loss: 0.1970 - val_acc: 0.9561 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 408/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1142 - acc: 0.9718 - recall: 0.2812 - fbeta_score: 0.2849 - val_loss: 0.2207 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 409/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1220 - acc: 0.9778 - recall: 0.3102 - fbeta_score: 0.3145 - val_loss: 0.1931 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 410/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1070 - acc: 0.9778 - recall: 0.3002 - fbeta_score: 0.3029 - val_loss: 0.2000 - val_acc: 0.9512 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 411/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1269 - acc: 0.9718 - recall: 0.2749 - fbeta_score: 0.2803 - val_loss: 0.2384 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 412/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1108 - acc: 0.9772 - recall: 0.3075 - fbeta_score: 0.3100 - val_loss: 0.1939 - val_acc: 0.9659 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 413/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1196 - acc: 0.9740 - recall: 0.2862 - fbeta_score: 0.2932 - val_loss: 0.2096 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 414/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1214 - acc: 0.9729 - recall: 0.2713 - fbeta_score: 0.2729 - val_loss: 0.2020 - val_acc: 0.9707 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 415/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1099 - acc: 0.9756 - recall: 0.3147 - fbeta_score: 0.3156 - val_loss: 0.2368 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 416/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1178 - acc: 0.9750 - recall: 0.2948 - fbeta_score: 0.2984 - val_loss: 0.2047 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 417/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1125 - acc: 0.9799 - recall: 0.3129 - fbeta_score: 0.3216 - val_loss: 0.1780 - val_acc: 0.9707 - val_recall: 0.3659 - val_fbeta_score: 0.3740\n",
      "Epoch 418/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1115 - acc: 0.9799 - recall: 0.3445 - fbeta_score: 0.3455 - val_loss: 0.1912 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 419/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1142 - acc: 0.9767 - recall: 0.3165 - fbeta_score: 0.3263 - val_loss: 0.2176 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 420/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1151 - acc: 0.9745 - recall: 0.2885 - fbeta_score: 0.2991 - val_loss: 0.2285 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 421/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1161 - acc: 0.9750 - recall: 0.2849 - fbeta_score: 0.2957 - val_loss: 0.2098 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 422/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1176 - acc: 0.9767 - recall: 0.3296 - fbeta_score: 0.3336 - val_loss: 0.1953 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 423/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1120 - acc: 0.9761 - recall: 0.2921 - fbeta_score: 0.2991 - val_loss: 0.2022 - val_acc: 0.9561 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 424/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1125 - acc: 0.9729 - recall: 0.2740 - fbeta_score: 0.2802 - val_loss: 0.2607 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 425/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1189 - acc: 0.9723 - recall: 0.2957 - fbeta_score: 0.3015 - val_loss: 0.2224 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 426/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1184 - acc: 0.9750 - recall: 0.2648 - fbeta_score: 0.2751 - val_loss: 0.1928 - val_acc: 0.9659 - val_recall: 0.3659 - val_fbeta_score: 0.3740\n",
      "Epoch 427/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1159 - acc: 0.9723 - recall: 0.2740 - fbeta_score: 0.2802 - val_loss: 0.2072 - val_acc: 0.9610 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 428/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.1168 - acc: 0.9740 - recall: 0.2898 - fbeta_score: 0.2932 - val_loss: 0.2565 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 429/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.1113 - acc: 0.9788 - recall: 0.3066 - fbeta_score: 0.3136 - val_loss: 0.2382 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 430/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1110 - acc: 0.9745 - recall: 0.2912 - fbeta_score: 0.3017 - val_loss: 0.2787 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 431/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1142 - acc: 0.9772 - recall: 0.3066 - fbeta_score: 0.3147 - val_loss: 0.2189 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 432/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.1185 - acc: 0.9740 - recall: 0.3147 - fbeta_score: 0.3210 - val_loss: 0.2591 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 433/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1153 - acc: 0.9734 - recall: 0.2921 - fbeta_score: 0.2981 - val_loss: 0.2246 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 434/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1075 - acc: 0.9745 - recall: 0.3011 - fbeta_score: 0.3046 - val_loss: 0.2529 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 435/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.1086 - acc: 0.9783 - recall: 0.3057 - fbeta_score: 0.3174 - val_loss: 0.2207 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 436/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1137 - acc: 0.9740 - recall: 0.2812 - fbeta_score: 0.2870 - val_loss: 0.2195 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 437/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.1099 - acc: 0.9756 - recall: 0.3165 - fbeta_score: 0.3185 - val_loss: 0.2019 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 438/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1201 - acc: 0.9734 - recall: 0.2767 - fbeta_score: 0.2820 - val_loss: 0.1952 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 439/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1080 - acc: 0.9740 - recall: 0.3039 - fbeta_score: 0.3147 - val_loss: 0.2111 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 440/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1067 - acc: 0.9718 - recall: 0.2785 - fbeta_score: 0.2847 - val_loss: 0.1885 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 441/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1066 - acc: 0.9799 - recall: 0.3039 - fbeta_score: 0.3053 - val_loss: 0.1929 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 442/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1121 - acc: 0.9778 - recall: 0.3048 - fbeta_score: 0.3118 - val_loss: 0.2173 - val_acc: 0.9610 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 443/500\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.1098 - acc: 0.9761 - recall: 0.2894 - fbeta_score: 0.3019 - val_loss: 0.2150 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2439\n",
      "Epoch 444/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1094 - acc: 0.9772 - recall: 0.3265 - fbeta_score: 0.3299 - val_loss: 0.2047 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 445/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1211 - acc: 0.9712 - recall: 0.2889 - fbeta_score: 0.2943 - val_loss: 0.2535 - val_acc: 0.9463 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 446/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1123 - acc: 0.9740 - recall: 0.2774 - fbeta_score: 0.2829 - val_loss: 0.2094 - val_acc: 0.9610 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n",
      "Epoch 447/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1199 - acc: 0.9734 - recall: 0.2633 - fbeta_score: 0.2713 - val_loss: 0.2272 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 448/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1117 - acc: 0.9778 - recall: 0.3237 - fbeta_score: 0.3281 - val_loss: 0.2604 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 449/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1044 - acc: 0.9778 - recall: 0.2912 - fbeta_score: 0.2973 - val_loss: 0.2437 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 450/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1062 - acc: 0.9778 - recall: 0.3527 - fbeta_score: 0.3527 - val_loss: 0.2130 - val_acc: 0.9707 - val_recall: 0.3659 - val_fbeta_score: 0.3740\n",
      "Epoch 451/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1164 - acc: 0.9707 - recall: 0.2894 - fbeta_score: 0.2916 - val_loss: 0.2216 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 452/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1042 - acc: 0.9745 - recall: 0.2957 - fbeta_score: 0.3002 - val_loss: 0.2325 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 453/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1139 - acc: 0.9745 - recall: 0.2803 - fbeta_score: 0.2894 - val_loss: 0.2146 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 454/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1131 - acc: 0.9772 - recall: 0.3084 - fbeta_score: 0.3180 - val_loss: 0.2371 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 455/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1115 - acc: 0.9734 - recall: 0.2860 - fbeta_score: 0.2878 - val_loss: 0.2438 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 456/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1131 - acc: 0.9794 - recall: 0.2948 - fbeta_score: 0.3035 - val_loss: 0.2410 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 457/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1087 - acc: 0.9767 - recall: 0.3219 - fbeta_score: 0.3245 - val_loss: 0.2159 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 458/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.1106 - acc: 0.9783 - recall: 0.3314 - fbeta_score: 0.3341 - val_loss: 0.2295 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 459/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1132 - acc: 0.9729 - recall: 0.2912 - fbeta_score: 0.2917 - val_loss: 0.2246 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 460/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.1097 - acc: 0.9778 - recall: 0.3120 - fbeta_score: 0.3209 - val_loss: 0.2088 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 461/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1005 - acc: 0.9805 - recall: 0.3317 - fbeta_score: 0.3359 - val_loss: 0.2219 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 462/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1097 - acc: 0.9788 - recall: 0.3064 - fbeta_score: 0.3109 - val_loss: 0.2029 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 463/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.1130 - acc: 0.9718 - recall: 0.2704 - fbeta_score: 0.2744 - val_loss: 0.2244 - val_acc: 0.9512 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 464/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1078 - acc: 0.9750 - recall: 0.2831 - fbeta_score: 0.2905 - val_loss: 0.2237 - val_acc: 0.9512 - val_recall: 0.1463 - val_fbeta_score: 0.1626\n",
      "Epoch 465/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.1149 - acc: 0.9712 - recall: 0.2758 - fbeta_score: 0.2856 - val_loss: 0.1967 - val_acc: 0.9512 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 466/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1169 - acc: 0.9718 - recall: 0.2546 - fbeta_score: 0.2597 - val_loss: 0.2161 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 467/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1050 - acc: 0.9778 - recall: 0.2939 - fbeta_score: 0.2973 - val_loss: 0.1995 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 468/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1064 - acc: 0.9767 - recall: 0.2966 - fbeta_score: 0.2991 - val_loss: 0.2361 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 469/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1025 - acc: 0.9783 - recall: 0.3111 - fbeta_score: 0.3190 - val_loss: 0.2247 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 470/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1013 - acc: 0.9794 - recall: 0.3206 - fbeta_score: 0.3219 - val_loss: 0.2600 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 471/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1077 - acc: 0.9756 - recall: 0.3100 - fbeta_score: 0.3109 - val_loss: 0.2193 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 472/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1064 - acc: 0.9756 - recall: 0.3111 - fbeta_score: 0.3136 - val_loss: 0.2219 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 473/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1059 - acc: 0.9778 - recall: 0.3075 - fbeta_score: 0.3136 - val_loss: 0.2422 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 474/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1117 - acc: 0.9740 - recall: 0.2803 - fbeta_score: 0.2892 - val_loss: 0.2168 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 475/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1152 - acc: 0.9745 - recall: 0.3328 - fbeta_score: 0.3351 - val_loss: 0.2059 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 476/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1108 - acc: 0.9778 - recall: 0.3237 - fbeta_score: 0.3308 - val_loss: 0.2212 - val_acc: 0.9463 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 477/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1022 - acc: 0.9788 - recall: 0.3219 - fbeta_score: 0.3265 - val_loss: 0.2170 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 478/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.0996 - acc: 0.9794 - recall: 0.3391 - fbeta_score: 0.3436 - val_loss: 0.2340 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 479/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1000 - acc: 0.9783 - recall: 0.3283 - fbeta_score: 0.3328 - val_loss: 0.2451 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 480/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1110 - acc: 0.9745 - recall: 0.3129 - fbeta_score: 0.3172 - val_loss: 0.2238 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 481/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1080 - acc: 0.9778 - recall: 0.3373 - fbeta_score: 0.3444 - val_loss: 0.2097 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 482/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1037 - acc: 0.9799 - recall: 0.3346 - fbeta_score: 0.3407 - val_loss: 0.2312 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 483/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1183 - acc: 0.9745 - recall: 0.2776 - fbeta_score: 0.2881 - val_loss: 0.2425 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 484/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1067 - acc: 0.9750 - recall: 0.2975 - fbeta_score: 0.2970 - val_loss: 0.3095 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 485/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1192 - acc: 0.9718 - recall: 0.2478 - fbeta_score: 0.2556 - val_loss: 0.2677 - val_acc: 0.9512 - val_recall: 0.1220 - val_fbeta_score: 0.1301\n",
      "Epoch 486/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.1169 - acc: 0.9734 - recall: 0.2840 - fbeta_score: 0.2919 - val_loss: 0.2124 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 487/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1036 - acc: 0.9788 - recall: 0.2867 - fbeta_score: 0.2935 - val_loss: 0.2126 - val_acc: 0.9659 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 488/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1042 - acc: 0.9767 - recall: 0.3268 - fbeta_score: 0.3241 - val_loss: 0.2360 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.2114\n",
      "Epoch 489/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1040 - acc: 0.9778 - recall: 0.2937 - fbeta_score: 0.3019 - val_loss: 0.2152 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 490/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1183 - acc: 0.9734 - recall: 0.2885 - fbeta_score: 0.2957 - val_loss: 0.2316 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 491/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1012 - acc: 0.9810 - recall: 0.3147 - fbeta_score: 0.3118 - val_loss: 0.2122 - val_acc: 0.9707 - val_recall: 0.3171 - val_fbeta_score: 0.3252\n",
      "Epoch 492/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1107 - acc: 0.9778 - recall: 0.3147 - fbeta_score: 0.3147 - val_loss: 0.2485 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 493/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.0981 - acc: 0.9794 - recall: 0.3283 - fbeta_score: 0.3290 - val_loss: 0.2148 - val_acc: 0.9659 - val_recall: 0.2195 - val_fbeta_score: 0.2276\n",
      "Epoch 494/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1076 - acc: 0.9767 - recall: 0.2858 - fbeta_score: 0.2869 - val_loss: 0.2530 - val_acc: 0.9561 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 495/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1170 - acc: 0.9734 - recall: 0.2876 - fbeta_score: 0.2964 - val_loss: 0.1926 - val_acc: 0.9610 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 496/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.1132 - acc: 0.9712 - recall: 0.2758 - fbeta_score: 0.2811 - val_loss: 0.2369 - val_acc: 0.9659 - val_recall: 0.2683 - val_fbeta_score: 0.2764\n",
      "Epoch 497/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1092 - acc: 0.9756 - recall: 0.3188 - fbeta_score: 0.3230 - val_loss: 0.2058 - val_acc: 0.9610 - val_recall: 0.1951 - val_fbeta_score: 0.1951\n",
      "Epoch 498/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1026 - acc: 0.9778 - recall: 0.2921 - fbeta_score: 0.2991 - val_loss: 0.2147 - val_acc: 0.9610 - val_recall: 0.2439 - val_fbeta_score: 0.2602\n",
      "Epoch 499/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.0992 - acc: 0.9767 - recall: 0.3418 - fbeta_score: 0.3455 - val_loss: 0.2433 - val_acc: 0.9561 - val_recall: 0.1707 - val_fbeta_score: 0.1789\n",
      "Epoch 500/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.1035 - acc: 0.9767 - recall: 0.2948 - fbeta_score: 0.3035 - val_loss: 0.2175 - val_acc: 0.9659 - val_recall: 0.2927 - val_fbeta_score: 0.3089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1916a8dbb38>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp4.fit(X_scale_train, y_train,\n",
    "                epochs=500,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_split=0.1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               2400      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 34,401\n",
      "Trainable params: 33,601\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejora en accuracy y Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Capa (Lasso y 2 unidades de salida)\n",
    "\n",
    "Vamos a usar una capa de salida con dos unidades a ver si aprende mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4))\n",
    "\n",
    "#l=0.007\n",
    "l=0.001\n",
    "\n",
    "x = Input(shape=(23,))\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l1(l))(x)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l1(l))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l1(l))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dense(100, activation='softsign', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l1(l))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "y = Dense(2, activation='sigmoid',kernel_initializer='he_uniform')(layer)\n",
    "mlp5 = Model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp5.compile(optimizer='sgd',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', recall, fbeta_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1843 samples, validate on 205 samples\n",
      "Epoch 1/500\n",
      "1843/1843 [==============================] - 2s 969us/step - loss: 4.7841 - acc: 0.6750 - recall: 0.6468 - fbeta_score: 0.6211 - val_loss: 4.5837 - val_acc: 0.8146 - val_recall: 0.6585 - val_fbeta_score: 0.6481\n",
      "Epoch 2/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 4.5525 - acc: 0.8394 - recall: 0.7200 - fbeta_score: 0.6941 - val_loss: 4.4602 - val_acc: 0.9268 - val_recall: 0.6829 - val_fbeta_score: 0.6862\n",
      "Epoch 3/500\n",
      "1843/1843 [==============================] - 0s 242us/step - loss: 4.4020 - acc: 0.9305 - recall: 0.8003 - fbeta_score: 0.7925 - val_loss: 4.3400 - val_acc: 0.9415 - val_recall: 0.8829 - val_fbeta_score: 0.8728\n",
      "Epoch 4/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 4.2740 - acc: 0.9468 - recall: 0.8801 - fbeta_score: 0.8839 - val_loss: 4.2380 - val_acc: 0.9463 - val_recall: 0.9122 - val_fbeta_score: 0.9159\n",
      "Epoch 5/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 4.1777 - acc: 0.9468 - recall: 0.9284 - fbeta_score: 0.9274 - val_loss: 4.1660 - val_acc: 0.9415 - val_recall: 0.9415 - val_fbeta_score: 0.9356\n",
      "Epoch 6/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 4.0954 - acc: 0.9501 - recall: 0.9381 - fbeta_score: 0.9375 - val_loss: 4.0954 - val_acc: 0.9463 - val_recall: 0.9512 - val_fbeta_score: 0.9407\n",
      "Epoch 7/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 4.0312 - acc: 0.9512 - recall: 0.9539 - fbeta_score: 0.9449 - val_loss: 4.0352 - val_acc: 0.9463 - val_recall: 0.9561 - val_fbeta_score: 0.9473\n",
      "Epoch 8/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 3.9649 - acc: 0.9506 - recall: 0.9560 - fbeta_score: 0.9466 - val_loss: 3.9842 - val_acc: 0.9415 - val_recall: 0.9512 - val_fbeta_score: 0.9445\n",
      "Epoch 9/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 3.8987 - acc: 0.9560 - recall: 0.9598 - fbeta_score: 0.9528 - val_loss: 3.9201 - val_acc: 0.9463 - val_recall: 0.9512 - val_fbeta_score: 0.9445\n",
      "Epoch 10/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 3.8442 - acc: 0.9550 - recall: 0.9528 - fbeta_score: 0.9494 - val_loss: 3.8630 - val_acc: 0.9415 - val_recall: 0.9463 - val_fbeta_score: 0.9442\n",
      "Epoch 11/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 3.7835 - acc: 0.9577 - recall: 0.9512 - fbeta_score: 0.9508 - val_loss: 3.8078 - val_acc: 0.9415 - val_recall: 0.9366 - val_fbeta_score: 0.9391\n",
      "Epoch 12/500\n",
      "1843/1843 [==============================] - 0s 258us/step - loss: 3.7240 - acc: 0.9598 - recall: 0.9550 - fbeta_score: 0.9529 - val_loss: 3.7541 - val_acc: 0.9415 - val_recall: 0.9463 - val_fbeta_score: 0.9442\n",
      "Epoch 13/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 3.6637 - acc: 0.9604 - recall: 0.9517 - fbeta_score: 0.9556 - val_loss: 3.7070 - val_acc: 0.9415 - val_recall: 0.9415 - val_fbeta_score: 0.9440\n",
      "Epoch 14/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 3.6032 - acc: 0.9642 - recall: 0.9485 - fbeta_score: 0.9561 - val_loss: 3.6482 - val_acc: 0.9415 - val_recall: 0.9415 - val_fbeta_score: 0.9461\n",
      "Epoch 15/500\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 3.5573 - acc: 0.9609 - recall: 0.9403 - fbeta_score: 0.9533 - val_loss: 3.5915 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9473\n",
      "Epoch 16/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 3.5030 - acc: 0.9615 - recall: 0.9349 - fbeta_score: 0.9509 - val_loss: 3.5496 - val_acc: 0.9415 - val_recall: 0.9463 - val_fbeta_score: 0.9488\n",
      "Epoch 17/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 3.4394 - acc: 0.9664 - recall: 0.9387 - fbeta_score: 0.9533 - val_loss: 3.4934 - val_acc: 0.9463 - val_recall: 0.9366 - val_fbeta_score: 0.9458\n",
      "Epoch 18/500\n",
      "1843/1843 [==============================] - 1s 285us/step - loss: 3.3880 - acc: 0.9685 - recall: 0.9235 - fbeta_score: 0.9468 - val_loss: 3.4471 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9481\n",
      "Epoch 19/500\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 3.3371 - acc: 0.9647 - recall: 0.9300 - fbeta_score: 0.9493 - val_loss: 3.3917 - val_acc: 0.9463 - val_recall: 0.9366 - val_fbeta_score: 0.9456\n",
      "Epoch 20/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 3.2799 - acc: 0.9696 - recall: 0.9257 - fbeta_score: 0.9490 - val_loss: 3.3503 - val_acc: 0.9415 - val_recall: 0.9317 - val_fbeta_score: 0.9433\n",
      "Epoch 21/500\n",
      "1843/1843 [==============================] - 1s 280us/step - loss: 3.2327 - acc: 0.9664 - recall: 0.9132 - fbeta_score: 0.9423 - val_loss: 3.2971 - val_acc: 0.9463 - val_recall: 0.9220 - val_fbeta_score: 0.9401\n",
      "Epoch 22/500\n",
      "1843/1843 [==============================] - 1s 274us/step - loss: 3.1702 - acc: 0.9740 - recall: 0.9208 - fbeta_score: 0.9484 - val_loss: 3.2245 - val_acc: 0.9610 - val_recall: 0.9220 - val_fbeta_score: 0.9445\n",
      "Epoch 23/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 3.1179 - acc: 0.9718 - recall: 0.9126 - fbeta_score: 0.9450 - val_loss: 3.1822 - val_acc: 0.9561 - val_recall: 0.9317 - val_fbeta_score: 0.9497\n",
      "Epoch 24/500\n",
      "1843/1843 [==============================] - 1s 273us/step - loss: 3.0694 - acc: 0.9756 - recall: 0.9078 - fbeta_score: 0.9434 - val_loss: 3.1356 - val_acc: 0.9707 - val_recall: 0.8878 - val_fbeta_score: 0.9223\n",
      "Epoch 25/500\n",
      "1843/1843 [==============================] - 0s 259us/step - loss: 3.0314 - acc: 0.9685 - recall: 0.9078 - fbeta_score: 0.9423 - val_loss: 3.0871 - val_acc: 0.9512 - val_recall: 0.9268 - val_fbeta_score: 0.9453\n",
      "Epoch 26/500\n",
      "1843/1843 [==============================] - 0s 254us/step - loss: 2.9765 - acc: 0.9718 - recall: 0.9012 - fbeta_score: 0.9387 - val_loss: 3.0382 - val_acc: 0.9610 - val_recall: 0.9122 - val_fbeta_score: 0.9388\n",
      "Epoch 27/500\n",
      "1843/1843 [==============================] - 1s 277us/step - loss: 2.9295 - acc: 0.9702 - recall: 0.9088 - fbeta_score: 0.9416 - val_loss: 3.0052 - val_acc: 0.9512 - val_recall: 0.9171 - val_fbeta_score: 0.9422\n",
      "Epoch 28/500\n",
      "1843/1843 [==============================] - 0s 256us/step - loss: 2.8748 - acc: 0.9756 - recall: 0.9083 - fbeta_score: 0.9438 - val_loss: 2.9598 - val_acc: 0.9463 - val_recall: 0.9268 - val_fbeta_score: 0.9474\n",
      "Epoch 29/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 2.8305 - acc: 0.9707 - recall: 0.8996 - fbeta_score: 0.9382 - val_loss: 2.9004 - val_acc: 0.9561 - val_recall: 0.9122 - val_fbeta_score: 0.9365\n",
      "Epoch 30/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 2.7844 - acc: 0.9712 - recall: 0.9007 - fbeta_score: 0.9385 - val_loss: 2.8393 - val_acc: 0.9659 - val_recall: 0.9073 - val_fbeta_score: 0.9360\n",
      "Epoch 31/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 2.7394 - acc: 0.9750 - recall: 0.8931 - fbeta_score: 0.9354 - val_loss: 2.8165 - val_acc: 0.9463 - val_recall: 0.9122 - val_fbeta_score: 0.9392\n",
      "Epoch 32/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 2.6929 - acc: 0.9718 - recall: 0.8888 - fbeta_score: 0.9321 - val_loss: 2.7837 - val_acc: 0.9561 - val_recall: 0.9171 - val_fbeta_score: 0.9394\n",
      "Epoch 33/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 2.6382 - acc: 0.9810 - recall: 0.9056 - fbeta_score: 0.9414 - val_loss: 2.7118 - val_acc: 0.9512 - val_recall: 0.9220 - val_fbeta_score: 0.9469\n",
      "Epoch 34/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 2.6035 - acc: 0.9696 - recall: 0.8893 - fbeta_score: 0.9322 - val_loss: 2.6861 - val_acc: 0.9463 - val_recall: 0.9122 - val_fbeta_score: 0.9352\n",
      "Epoch 35/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 2.5461 - acc: 0.9794 - recall: 0.8920 - fbeta_score: 0.9360 - val_loss: 2.6286 - val_acc: 0.9561 - val_recall: 0.8634 - val_fbeta_score: 0.9135\n",
      "Epoch 36/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 2.5097 - acc: 0.9772 - recall: 0.8806 - fbeta_score: 0.9298 - val_loss: 2.6138 - val_acc: 0.9415 - val_recall: 0.8976 - val_fbeta_score: 0.9283\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 228us/step - loss: 2.4572 - acc: 0.9805 - recall: 0.8785 - fbeta_score: 0.9265 - val_loss: 2.5327 - val_acc: 0.9610 - val_recall: 0.8976 - val_fbeta_score: 0.9318\n",
      "Epoch 38/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 2.4169 - acc: 0.9783 - recall: 0.8741 - fbeta_score: 0.9258 - val_loss: 2.5328 - val_acc: 0.9463 - val_recall: 0.9073 - val_fbeta_score: 0.9337\n",
      "Epoch 39/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 2.3761 - acc: 0.9767 - recall: 0.8866 - fbeta_score: 0.9324 - val_loss: 2.4775 - val_acc: 0.9463 - val_recall: 0.9024 - val_fbeta_score: 0.9279\n",
      "Epoch 40/500\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 2.3288 - acc: 0.9772 - recall: 0.8899 - fbeta_score: 0.9359 - val_loss: 2.4972 - val_acc: 0.9415 - val_recall: 0.8829 - val_fbeta_score: 0.9174\n",
      "Epoch 41/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 2.2960 - acc: 0.9756 - recall: 0.8747 - fbeta_score: 0.9252 - val_loss: 2.4634 - val_acc: 0.9317 - val_recall: 0.9073 - val_fbeta_score: 0.9343\n",
      "Epoch 42/500\n",
      "1843/1843 [==============================] - 1s 284us/step - loss: 2.2549 - acc: 0.9783 - recall: 0.8801 - fbeta_score: 0.9284 - val_loss: 2.3653 - val_acc: 0.9610 - val_recall: 0.8927 - val_fbeta_score: 0.9294\n",
      "Epoch 43/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 2.2123 - acc: 0.9772 - recall: 0.8785 - fbeta_score: 0.9271 - val_loss: 2.3384 - val_acc: 0.9415 - val_recall: 0.9024 - val_fbeta_score: 0.9291\n",
      "Epoch 44/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 2.1759 - acc: 0.9778 - recall: 0.8779 - fbeta_score: 0.9280 - val_loss: 2.2858 - val_acc: 0.9512 - val_recall: 0.8927 - val_fbeta_score: 0.9303\n",
      "Epoch 45/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 2.1335 - acc: 0.9772 - recall: 0.8616 - fbeta_score: 0.9186 - val_loss: 2.2261 - val_acc: 0.9463 - val_recall: 0.8683 - val_fbeta_score: 0.9195\n",
      "Epoch 46/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 2.0901 - acc: 0.9783 - recall: 0.8638 - fbeta_score: 0.9210 - val_loss: 2.2078 - val_acc: 0.9366 - val_recall: 0.8976 - val_fbeta_score: 0.9306\n",
      "Epoch 47/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 2.0512 - acc: 0.9783 - recall: 0.8606 - fbeta_score: 0.9179 - val_loss: 2.1559 - val_acc: 0.9561 - val_recall: 0.9122 - val_fbeta_score: 0.9426\n",
      "Epoch 48/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 2.0218 - acc: 0.9799 - recall: 0.8709 - fbeta_score: 0.9248 - val_loss: 2.1505 - val_acc: 0.9463 - val_recall: 0.8927 - val_fbeta_score: 0.9254\n",
      "Epoch 49/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 1.9802 - acc: 0.9778 - recall: 0.8719 - fbeta_score: 0.9261 - val_loss: 2.1745 - val_acc: 0.9073 - val_recall: 0.8195 - val_fbeta_score: 0.8735\n",
      "Epoch 50/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 1.9703 - acc: 0.9729 - recall: 0.8719 - fbeta_score: 0.9223 - val_loss: 2.0556 - val_acc: 0.9463 - val_recall: 0.8732 - val_fbeta_score: 0.9229\n",
      "Epoch 51/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 1.9174 - acc: 0.9767 - recall: 0.8638 - fbeta_score: 0.9183 - val_loss: 2.0303 - val_acc: 0.9463 - val_recall: 0.8585 - val_fbeta_score: 0.9055\n",
      "Epoch 52/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 1.8853 - acc: 0.9740 - recall: 0.8573 - fbeta_score: 0.9133 - val_loss: 1.9938 - val_acc: 0.9463 - val_recall: 0.8585 - val_fbeta_score: 0.9088\n",
      "Epoch 53/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 1.8492 - acc: 0.9756 - recall: 0.8578 - fbeta_score: 0.9134 - val_loss: 1.9633 - val_acc: 0.9415 - val_recall: 0.8439 - val_fbeta_score: 0.8985\n",
      "Epoch 54/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 1.8138 - acc: 0.9788 - recall: 0.8486 - fbeta_score: 0.9099 - val_loss: 1.9293 - val_acc: 0.9415 - val_recall: 0.8927 - val_fbeta_score: 0.9321\n",
      "Epoch 55/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 1.7818 - acc: 0.9750 - recall: 0.8589 - fbeta_score: 0.9158 - val_loss: 1.8921 - val_acc: 0.9463 - val_recall: 0.8927 - val_fbeta_score: 0.9278\n",
      "Epoch 56/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 1.7443 - acc: 0.9761 - recall: 0.8698 - fbeta_score: 0.9193 - val_loss: 1.8249 - val_acc: 0.9463 - val_recall: 0.8683 - val_fbeta_score: 0.9114\n",
      "Epoch 57/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 1.7240 - acc: 0.9691 - recall: 0.8530 - fbeta_score: 0.9098 - val_loss: 1.8071 - val_acc: 0.9415 - val_recall: 0.9122 - val_fbeta_score: 0.9362\n",
      "Epoch 58/500\n",
      "1843/1843 [==============================] - 0s 262us/step - loss: 1.6678 - acc: 0.9788 - recall: 0.8627 - fbeta_score: 0.9174 - val_loss: 1.8154 - val_acc: 0.9463 - val_recall: 0.8634 - val_fbeta_score: 0.9053\n",
      "Epoch 59/500\n",
      "1843/1843 [==============================] - 0s 268us/step - loss: 1.6294 - acc: 0.9767 - recall: 0.8616 - fbeta_score: 0.9172 - val_loss: 1.7573 - val_acc: 0.9561 - val_recall: 0.8634 - val_fbeta_score: 0.9081\n",
      "Epoch 60/500\n",
      "1843/1843 [==============================] - 0s 265us/step - loss: 1.6103 - acc: 0.9712 - recall: 0.8454 - fbeta_score: 0.9070 - val_loss: 1.7206 - val_acc: 0.9512 - val_recall: 0.8293 - val_fbeta_score: 0.8912\n",
      "Epoch 61/500\n",
      "1843/1843 [==============================] - 1s 291us/step - loss: 1.5714 - acc: 0.9750 - recall: 0.8741 - fbeta_score: 0.9234 - val_loss: 1.6965 - val_acc: 0.9610 - val_recall: 0.8878 - val_fbeta_score: 0.9246\n",
      "Epoch 62/500\n",
      "1843/1843 [==============================] - 1s 281us/step - loss: 1.5349 - acc: 0.9756 - recall: 0.8692 - fbeta_score: 0.9206 - val_loss: 1.6673 - val_acc: 0.9463 - val_recall: 0.8878 - val_fbeta_score: 0.9252\n",
      "Epoch 63/500\n",
      "1843/1843 [==============================] - 1s 279us/step - loss: 1.5054 - acc: 0.9745 - recall: 0.8622 - fbeta_score: 0.9172 - val_loss: 1.6425 - val_acc: 0.9366 - val_recall: 0.9073 - val_fbeta_score: 0.9270\n",
      "Epoch 64/500\n",
      "1843/1843 [==============================] - 1s 284us/step - loss: 1.4701 - acc: 0.9783 - recall: 0.8497 - fbeta_score: 0.9098 - val_loss: 1.6426 - val_acc: 0.9415 - val_recall: 0.8488 - val_fbeta_score: 0.8921\n",
      "Epoch 65/500\n",
      "1843/1843 [==============================] - 1s 281us/step - loss: 1.4505 - acc: 0.9750 - recall: 0.8448 - fbeta_score: 0.9063 - val_loss: 1.5913 - val_acc: 0.9463 - val_recall: 0.8341 - val_fbeta_score: 0.8882\n",
      "Epoch 66/500\n",
      "1843/1843 [==============================] - 1s 282us/step - loss: 1.4144 - acc: 0.9778 - recall: 0.8595 - fbeta_score: 0.9155 - val_loss: 1.5353 - val_acc: 0.9415 - val_recall: 0.8829 - val_fbeta_score: 0.9143\n",
      "Epoch 67/500\n",
      "1843/1843 [==============================] - 1s 281us/step - loss: 1.4067 - acc: 0.9712 - recall: 0.8616 - fbeta_score: 0.9129 - val_loss: 1.5802 - val_acc: 0.9463 - val_recall: 0.8732 - val_fbeta_score: 0.9086\n",
      "Epoch 68/500\n",
      "1843/1843 [==============================] - 1s 301us/step - loss: 1.3852 - acc: 0.9707 - recall: 0.8562 - fbeta_score: 0.9100 - val_loss: 1.5943 - val_acc: 0.9073 - val_recall: 0.7268 - val_fbeta_score: 0.8159\n",
      "Epoch 69/500\n",
      "1843/1843 [==============================] - 1s 285us/step - loss: 1.3354 - acc: 0.9756 - recall: 0.8519 - fbeta_score: 0.9106 - val_loss: 1.4792 - val_acc: 0.9366 - val_recall: 0.8878 - val_fbeta_score: 0.9206\n",
      "Epoch 70/500\n",
      "1843/1843 [==============================] - 1s 296us/step - loss: 1.2957 - acc: 0.9805 - recall: 0.8568 - fbeta_score: 0.9154 - val_loss: 1.4379 - val_acc: 0.9366 - val_recall: 0.8732 - val_fbeta_score: 0.9160\n",
      "Epoch 71/500\n",
      "1843/1843 [==============================] - 1s 292us/step - loss: 1.2773 - acc: 0.9745 - recall: 0.8502 - fbeta_score: 0.9094 - val_loss: 1.4335 - val_acc: 0.9463 - val_recall: 0.8927 - val_fbeta_score: 0.9176\n",
      "Epoch 72/500\n",
      "1843/1843 [==============================] - 1s 287us/step - loss: 1.2645 - acc: 0.9723 - recall: 0.8426 - fbeta_score: 0.9001 - val_loss: 1.4079 - val_acc: 0.9512 - val_recall: 0.8195 - val_fbeta_score: 0.8766\n",
      "Epoch 73/500\n",
      "1843/1843 [==============================] - 1s 278us/step - loss: 1.2201 - acc: 0.9761 - recall: 0.8475 - fbeta_score: 0.9079 - val_loss: 1.3637 - val_acc: 0.9463 - val_recall: 0.8780 - val_fbeta_score: 0.9188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "1843/1843 [==============================] - 0s 263us/step - loss: 1.2088 - acc: 0.9702 - recall: 0.8367 - fbeta_score: 0.8974 - val_loss: 1.3649 - val_acc: 0.9415 - val_recall: 0.8878 - val_fbeta_score: 0.9105\n",
      "Epoch 75/500\n",
      "1843/1843 [==============================] - 0s 270us/step - loss: 1.1879 - acc: 0.9767 - recall: 0.8606 - fbeta_score: 0.9143 - val_loss: 1.3395 - val_acc: 0.9463 - val_recall: 0.8537 - val_fbeta_score: 0.8952\n",
      "Epoch 76/500\n",
      "1843/1843 [==============================] - 1s 373us/step - loss: 1.1602 - acc: 0.9729 - recall: 0.8313 - fbeta_score: 0.8951 - val_loss: 1.2734 - val_acc: 0.9317 - val_recall: 0.8146 - val_fbeta_score: 0.8659\n",
      "Epoch 77/500\n",
      "1843/1843 [==============================] - 0s 256us/step - loss: 1.1239 - acc: 0.9734 - recall: 0.8291 - fbeta_score: 0.8947 - val_loss: 1.2425 - val_acc: 0.9512 - val_recall: 0.8927 - val_fbeta_score: 0.9207\n",
      "Epoch 78/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 1.1038 - acc: 0.9734 - recall: 0.8492 - fbeta_score: 0.9089 - val_loss: 1.2418 - val_acc: 0.9463 - val_recall: 0.8829 - val_fbeta_score: 0.9128\n",
      "Epoch 79/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 1.0695 - acc: 0.9750 - recall: 0.8633 - fbeta_score: 0.9147 - val_loss: 1.1792 - val_acc: 0.9659 - val_recall: 0.8732 - val_fbeta_score: 0.9189\n",
      "Epoch 80/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 1.0631 - acc: 0.9707 - recall: 0.8378 - fbeta_score: 0.8993 - val_loss: 1.1590 - val_acc: 0.9463 - val_recall: 0.9122 - val_fbeta_score: 0.9289\n",
      "Epoch 81/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 1.0316 - acc: 0.9712 - recall: 0.8410 - fbeta_score: 0.8997 - val_loss: 1.1714 - val_acc: 0.9366 - val_recall: 0.9220 - val_fbeta_score: 0.9314\n",
      "Epoch 82/500\n",
      "1843/1843 [==============================] - 1s 327us/step - loss: 0.9980 - acc: 0.9750 - recall: 0.8524 - fbeta_score: 0.9069 - val_loss: 1.1014 - val_acc: 0.9512 - val_recall: 0.8683 - val_fbeta_score: 0.9053\n",
      "Epoch 83/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.9752 - acc: 0.9729 - recall: 0.8492 - fbeta_score: 0.9055 - val_loss: 1.1270 - val_acc: 0.9512 - val_recall: 0.8390 - val_fbeta_score: 0.8904\n",
      "Epoch 84/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.9599 - acc: 0.9696 - recall: 0.8421 - fbeta_score: 0.9013 - val_loss: 1.1513 - val_acc: 0.9073 - val_recall: 0.7951 - val_fbeta_score: 0.8455\n",
      "Epoch 85/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.9602 - acc: 0.9696 - recall: 0.8497 - fbeta_score: 0.9021 - val_loss: 1.0556 - val_acc: 0.9561 - val_recall: 0.8341 - val_fbeta_score: 0.8832\n",
      "Epoch 86/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.9061 - acc: 0.9761 - recall: 0.8584 - fbeta_score: 0.9104 - val_loss: 1.0280 - val_acc: 0.9512 - val_recall: 0.8878 - val_fbeta_score: 0.9191\n",
      "Epoch 87/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.9009 - acc: 0.9718 - recall: 0.8313 - fbeta_score: 0.8922 - val_loss: 1.0245 - val_acc: 0.9561 - val_recall: 0.8293 - val_fbeta_score: 0.8706\n",
      "Epoch 88/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.8774 - acc: 0.9750 - recall: 0.8399 - fbeta_score: 0.9018 - val_loss: 1.0343 - val_acc: 0.9463 - val_recall: 0.8244 - val_fbeta_score: 0.8795\n",
      "Epoch 89/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.8623 - acc: 0.9723 - recall: 0.8573 - fbeta_score: 0.9085 - val_loss: 0.9542 - val_acc: 0.9610 - val_recall: 0.8878 - val_fbeta_score: 0.9194\n",
      "Epoch 90/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.8444 - acc: 0.9685 - recall: 0.8584 - fbeta_score: 0.9083 - val_loss: 0.9512 - val_acc: 0.9415 - val_recall: 0.8293 - val_fbeta_score: 0.8750\n",
      "Epoch 91/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.8209 - acc: 0.9723 - recall: 0.8372 - fbeta_score: 0.8957 - val_loss: 0.9401 - val_acc: 0.9317 - val_recall: 0.8732 - val_fbeta_score: 0.8841\n",
      "Epoch 92/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.8142 - acc: 0.9707 - recall: 0.8752 - fbeta_score: 0.9108 - val_loss: 0.9688 - val_acc: 0.9415 - val_recall: 0.8927 - val_fbeta_score: 0.9142\n",
      "Epoch 93/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.7974 - acc: 0.9669 - recall: 0.8812 - fbeta_score: 0.9227 - val_loss: 0.9012 - val_acc: 0.9415 - val_recall: 0.8780 - val_fbeta_score: 0.9037\n",
      "Epoch 94/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.7778 - acc: 0.9685 - recall: 0.8530 - fbeta_score: 0.9024 - val_loss: 0.8610 - val_acc: 0.9610 - val_recall: 0.9366 - val_fbeta_score: 0.9367\n",
      "Epoch 95/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.7608 - acc: 0.9723 - recall: 0.8356 - fbeta_score: 0.8945 - val_loss: 0.8939 - val_acc: 0.9415 - val_recall: 0.8341 - val_fbeta_score: 0.8819\n",
      "Epoch 96/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.7514 - acc: 0.9664 - recall: 0.8459 - fbeta_score: 0.8969 - val_loss: 0.8652 - val_acc: 0.9561 - val_recall: 0.8634 - val_fbeta_score: 0.9042\n",
      "Epoch 97/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.7343 - acc: 0.9658 - recall: 0.8524 - fbeta_score: 0.9039 - val_loss: 0.8173 - val_acc: 0.9659 - val_recall: 0.8585 - val_fbeta_score: 0.9110\n",
      "Epoch 98/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.7002 - acc: 0.9745 - recall: 0.8546 - fbeta_score: 0.9034 - val_loss: 0.8154 - val_acc: 0.9512 - val_recall: 0.8829 - val_fbeta_score: 0.9082\n",
      "Epoch 99/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.6919 - acc: 0.9707 - recall: 0.8481 - fbeta_score: 0.8996 - val_loss: 0.8158 - val_acc: 0.9512 - val_recall: 0.8585 - val_fbeta_score: 0.9006\n",
      "Epoch 100/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.6768 - acc: 0.9745 - recall: 0.8448 - fbeta_score: 0.8998 - val_loss: 0.8220 - val_acc: 0.9415 - val_recall: 0.7268 - val_fbeta_score: 0.8110\n",
      "Epoch 101/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.6693 - acc: 0.9636 - recall: 0.8085 - fbeta_score: 0.8752 - val_loss: 0.7686 - val_acc: 0.9561 - val_recall: 0.8634 - val_fbeta_score: 0.8986\n",
      "Epoch 102/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.6560 - acc: 0.9653 - recall: 0.8394 - fbeta_score: 0.8941 - val_loss: 0.7521 - val_acc: 0.9610 - val_recall: 0.8439 - val_fbeta_score: 0.8994\n",
      "Epoch 103/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.6504 - acc: 0.9566 - recall: 0.8204 - fbeta_score: 0.8784 - val_loss: 0.7388 - val_acc: 0.9512 - val_recall: 0.8732 - val_fbeta_score: 0.9004\n",
      "Epoch 104/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.6194 - acc: 0.9702 - recall: 0.8313 - fbeta_score: 0.8881 - val_loss: 0.7288 - val_acc: 0.9512 - val_recall: 0.7171 - val_fbeta_score: 0.8085\n",
      "Epoch 105/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.6149 - acc: 0.9729 - recall: 0.8323 - fbeta_score: 0.8906 - val_loss: 0.7090 - val_acc: 0.9561 - val_recall: 0.7854 - val_fbeta_score: 0.8495\n",
      "Epoch 106/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.5942 - acc: 0.9680 - recall: 0.8188 - fbeta_score: 0.8780 - val_loss: 0.6948 - val_acc: 0.9707 - val_recall: 0.9073 - val_fbeta_score: 0.9240\n",
      "Epoch 107/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.5840 - acc: 0.9653 - recall: 0.8334 - fbeta_score: 0.8874 - val_loss: 0.7234 - val_acc: 0.9463 - val_recall: 0.9073 - val_fbeta_score: 0.9182\n",
      "Epoch 108/500\n",
      "1843/1843 [==============================] - 0s 242us/step - loss: 0.5856 - acc: 0.9712 - recall: 0.8394 - fbeta_score: 0.8928 - val_loss: 0.7051 - val_acc: 0.9512 - val_recall: 0.8488 - val_fbeta_score: 0.8960\n",
      "Epoch 109/500\n",
      "1843/1843 [==============================] - 0s 242us/step - loss: 0.5903 - acc: 0.9658 - recall: 0.8524 - fbeta_score: 0.8987 - val_loss: 0.6867 - val_acc: 0.9463 - val_recall: 0.8146 - val_fbeta_score: 0.8705\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.5652 - acc: 0.9647 - recall: 0.8546 - fbeta_score: 0.8978 - val_loss: 0.6480 - val_acc: 0.9561 - val_recall: 0.9317 - val_fbeta_score: 0.9429\n",
      "Epoch 111/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.5526 - acc: 0.9636 - recall: 0.8530 - fbeta_score: 0.8959 - val_loss: 0.6378 - val_acc: 0.9463 - val_recall: 0.9268 - val_fbeta_score: 0.9143\n",
      "Epoch 112/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.5520 - acc: 0.9680 - recall: 0.8562 - fbeta_score: 0.8979 - val_loss: 0.6520 - val_acc: 0.9366 - val_recall: 0.7902 - val_fbeta_score: 0.8400\n",
      "Epoch 113/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.5316 - acc: 0.9680 - recall: 0.8047 - fbeta_score: 0.8683 - val_loss: 0.6066 - val_acc: 0.9610 - val_recall: 0.9024 - val_fbeta_score: 0.9150\n",
      "Epoch 114/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.5182 - acc: 0.9664 - recall: 0.8698 - fbeta_score: 0.9089 - val_loss: 0.6383 - val_acc: 0.9512 - val_recall: 0.8878 - val_fbeta_score: 0.9176\n",
      "Epoch 115/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.5118 - acc: 0.9669 - recall: 0.8757 - fbeta_score: 0.9094 - val_loss: 0.6005 - val_acc: 0.9463 - val_recall: 0.9317 - val_fbeta_score: 0.9338\n",
      "Epoch 116/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.5003 - acc: 0.9712 - recall: 0.9105 - fbeta_score: 0.9322 - val_loss: 0.5867 - val_acc: 0.9561 - val_recall: 0.8341 - val_fbeta_score: 0.8973\n",
      "Epoch 117/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.4868 - acc: 0.9626 - recall: 0.8709 - fbeta_score: 0.9065 - val_loss: 0.5636 - val_acc: 0.9561 - val_recall: 0.8683 - val_fbeta_score: 0.8970\n",
      "Epoch 118/500\n",
      "1843/1843 [==============================] - 0s 256us/step - loss: 0.5185 - acc: 0.9631 - recall: 0.8779 - fbeta_score: 0.9073 - val_loss: 0.6125 - val_acc: 0.9463 - val_recall: 0.9268 - val_fbeta_score: 0.9295\n",
      "Epoch 119/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.4826 - acc: 0.9631 - recall: 0.8492 - fbeta_score: 0.8918 - val_loss: 0.6214 - val_acc: 0.9463 - val_recall: 0.7463 - val_fbeta_score: 0.8231\n",
      "Epoch 120/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.4952 - acc: 0.9598 - recall: 0.8334 - fbeta_score: 0.8736 - val_loss: 0.5992 - val_acc: 0.9561 - val_recall: 0.9073 - val_fbeta_score: 0.9316\n",
      "Epoch 121/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.4620 - acc: 0.9631 - recall: 0.8606 - fbeta_score: 0.8949 - val_loss: 0.6695 - val_acc: 0.8878 - val_recall: 0.8049 - val_fbeta_score: 0.7756\n",
      "Epoch 122/500\n",
      "1843/1843 [==============================] - 1s 280us/step - loss: 0.4921 - acc: 0.9620 - recall: 0.8188 - fbeta_score: 0.8690 - val_loss: 0.6091 - val_acc: 0.9463 - val_recall: 0.8537 - val_fbeta_score: 0.8999\n",
      "Epoch 123/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.4614 - acc: 0.9647 - recall: 0.8247 - fbeta_score: 0.8725 - val_loss: 0.5373 - val_acc: 0.9659 - val_recall: 0.8683 - val_fbeta_score: 0.9108\n",
      "Epoch 124/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.4438 - acc: 0.9674 - recall: 0.8166 - fbeta_score: 0.8763 - val_loss: 0.5329 - val_acc: 0.9317 - val_recall: 0.8049 - val_fbeta_score: 0.8614\n",
      "Epoch 125/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.4571 - acc: 0.9593 - recall: 0.8638 - fbeta_score: 0.8964 - val_loss: 0.5609 - val_acc: 0.9463 - val_recall: 0.8585 - val_fbeta_score: 0.8898\n",
      "Epoch 126/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.4557 - acc: 0.9626 - recall: 0.8307 - fbeta_score: 0.8791 - val_loss: 0.6305 - val_acc: 0.9122 - val_recall: 0.7415 - val_fbeta_score: 0.8097\n",
      "Epoch 127/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.4568 - acc: 0.9582 - recall: 0.8719 - fbeta_score: 0.8976 - val_loss: 0.5335 - val_acc: 0.9610 - val_recall: 0.8439 - val_fbeta_score: 0.8740\n",
      "Epoch 128/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.4219 - acc: 0.9588 - recall: 0.8437 - fbeta_score: 0.8866 - val_loss: 0.4863 - val_acc: 0.9659 - val_recall: 0.9415 - val_fbeta_score: 0.9481\n",
      "Epoch 129/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.4634 - acc: 0.9501 - recall: 0.8974 - fbeta_score: 0.9026 - val_loss: 0.5314 - val_acc: 0.9366 - val_recall: 0.9463 - val_fbeta_score: 0.9390\n",
      "Epoch 130/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.4221 - acc: 0.9604 - recall: 0.9164 - fbeta_score: 0.9184 - val_loss: 0.5235 - val_acc: 0.9463 - val_recall: 0.8098 - val_fbeta_score: 0.8583\n",
      "Epoch 131/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.4280 - acc: 0.9609 - recall: 0.8215 - fbeta_score: 0.8750 - val_loss: 0.4800 - val_acc: 0.9512 - val_recall: 0.9268 - val_fbeta_score: 0.9273\n",
      "Epoch 132/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.4092 - acc: 0.9642 - recall: 0.8606 - fbeta_score: 0.9015 - val_loss: 0.5776 - val_acc: 0.9610 - val_recall: 0.8439 - val_fbeta_score: 0.8691\n",
      "Epoch 133/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.4124 - acc: 0.9577 - recall: 0.8823 - fbeta_score: 0.9092 - val_loss: 0.4706 - val_acc: 0.9610 - val_recall: 0.9512 - val_fbeta_score: 0.9535\n",
      "Epoch 134/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.4115 - acc: 0.9588 - recall: 0.8774 - fbeta_score: 0.9007 - val_loss: 0.4646 - val_acc: 0.9512 - val_recall: 0.8146 - val_fbeta_score: 0.8498\n",
      "Epoch 135/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.3966 - acc: 0.9647 - recall: 0.8242 - fbeta_score: 0.8716 - val_loss: 0.5032 - val_acc: 0.9463 - val_recall: 0.9073 - val_fbeta_score: 0.9290\n",
      "Epoch 136/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.3965 - acc: 0.9609 - recall: 0.8980 - fbeta_score: 0.9122 - val_loss: 0.5111 - val_acc: 0.9463 - val_recall: 0.9512 - val_fbeta_score: 0.9473\n",
      "Epoch 137/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.3901 - acc: 0.9626 - recall: 0.8681 - fbeta_score: 0.9005 - val_loss: 0.4475 - val_acc: 0.9512 - val_recall: 0.9561 - val_fbeta_score: 0.9386\n",
      "Epoch 138/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.3851 - acc: 0.9674 - recall: 0.8768 - fbeta_score: 0.9062 - val_loss: 0.4473 - val_acc: 0.9415 - val_recall: 0.9561 - val_fbeta_score: 0.9583\n",
      "Epoch 139/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.3809 - acc: 0.9588 - recall: 0.9322 - fbeta_score: 0.9330 - val_loss: 0.5793 - val_acc: 0.9415 - val_recall: 0.9512 - val_fbeta_score: 0.9211\n",
      "Epoch 140/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.3847 - acc: 0.9626 - recall: 0.9539 - fbeta_score: 0.9435 - val_loss: 0.4593 - val_acc: 0.9659 - val_recall: 0.8976 - val_fbeta_score: 0.9287\n",
      "Epoch 141/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.3786 - acc: 0.9593 - recall: 0.9278 - fbeta_score: 0.9318 - val_loss: 0.5136 - val_acc: 0.9024 - val_recall: 0.8390 - val_fbeta_score: 0.8346\n",
      "Epoch 142/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.3921 - acc: 0.9593 - recall: 0.8622 - fbeta_score: 0.8967 - val_loss: 0.4688 - val_acc: 0.9610 - val_recall: 0.9512 - val_fbeta_score: 0.9231\n",
      "Epoch 143/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.3760 - acc: 0.9636 - recall: 0.8741 - fbeta_score: 0.9030 - val_loss: 0.4718 - val_acc: 0.9512 - val_recall: 0.8878 - val_fbeta_score: 0.9038\n",
      "Epoch 144/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.3632 - acc: 0.9615 - recall: 0.9392 - fbeta_score: 0.9382 - val_loss: 0.4192 - val_acc: 0.9659 - val_recall: 0.9707 - val_fbeta_score: 0.9442\n",
      "Epoch 145/500\n",
      "1843/1843 [==============================] - 0s 249us/step - loss: 0.3665 - acc: 0.9588 - recall: 0.9273 - fbeta_score: 0.9319 - val_loss: 0.5077 - val_acc: 0.9415 - val_recall: 0.9366 - val_fbeta_score: 0.9391\n",
      "Epoch 146/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.3510 - acc: 0.9626 - recall: 0.8877 - fbeta_score: 0.9139 - val_loss: 0.4640 - val_acc: 0.9317 - val_recall: 0.9024 - val_fbeta_score: 0.9089\n",
      "Epoch 147/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.3498 - acc: 0.9626 - recall: 0.8937 - fbeta_score: 0.9145 - val_loss: 0.4677 - val_acc: 0.9610 - val_recall: 0.8634 - val_fbeta_score: 0.8952\n",
      "Epoch 148/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.3497 - acc: 0.9658 - recall: 0.9110 - fbeta_score: 0.9273 - val_loss: 0.4205 - val_acc: 0.9463 - val_recall: 0.9366 - val_fbeta_score: 0.9479\n",
      "Epoch 149/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.3493 - acc: 0.9593 - recall: 0.9116 - fbeta_score: 0.9232 - val_loss: 0.4186 - val_acc: 0.9610 - val_recall: 0.8878 - val_fbeta_score: 0.8944\n",
      "Epoch 150/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.3406 - acc: 0.9653 - recall: 0.9110 - fbeta_score: 0.9269 - val_loss: 0.3941 - val_acc: 0.9659 - val_recall: 0.9220 - val_fbeta_score: 0.9425\n",
      "Epoch 151/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.3450 - acc: 0.9582 - recall: 0.8996 - fbeta_score: 0.9208 - val_loss: 0.4362 - val_acc: 0.9463 - val_recall: 0.8488 - val_fbeta_score: 0.8859\n",
      "Epoch 152/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.3266 - acc: 0.9636 - recall: 0.9061 - fbeta_score: 0.9265 - val_loss: 0.4162 - val_acc: 0.9512 - val_recall: 0.8195 - val_fbeta_score: 0.8593\n",
      "Epoch 153/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.3232 - acc: 0.9631 - recall: 0.9159 - fbeta_score: 0.9339 - val_loss: 0.3988 - val_acc: 0.9366 - val_recall: 0.9659 - val_fbeta_score: 0.9435\n",
      "Epoch 154/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.3291 - acc: 0.9653 - recall: 0.9642 - fbeta_score: 0.9550 - val_loss: 0.3948 - val_acc: 0.9512 - val_recall: 0.9463 - val_fbeta_score: 0.9487\n",
      "Epoch 155/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.3250 - acc: 0.9658 - recall: 0.9528 - fbeta_score: 0.9540 - val_loss: 0.3706 - val_acc: 0.9659 - val_recall: 0.9659 - val_fbeta_score: 0.9570\n",
      "Epoch 156/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.2968 - acc: 0.9642 - recall: 0.9311 - fbeta_score: 0.9408 - val_loss: 0.4290 - val_acc: 0.9610 - val_recall: 0.8634 - val_fbeta_score: 0.9054\n",
      "Epoch 157/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.2993 - acc: 0.9680 - recall: 0.9099 - fbeta_score: 0.9308 - val_loss: 0.3878 - val_acc: 0.9512 - val_recall: 0.9561 - val_fbeta_score: 0.9496\n",
      "Epoch 158/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.3192 - acc: 0.9626 - recall: 0.9067 - fbeta_score: 0.9248 - val_loss: 0.4597 - val_acc: 0.9512 - val_recall: 0.8488 - val_fbeta_score: 0.8965\n",
      "Epoch 159/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.2920 - acc: 0.9707 - recall: 0.8730 - fbeta_score: 0.9166 - val_loss: 0.4139 - val_acc: 0.9512 - val_recall: 0.8878 - val_fbeta_score: 0.9113\n",
      "Epoch 160/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.2959 - acc: 0.9647 - recall: 0.9208 - fbeta_score: 0.9423 - val_loss: 0.4195 - val_acc: 0.9659 - val_recall: 0.8634 - val_fbeta_score: 0.9056\n",
      "Epoch 161/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.2869 - acc: 0.9718 - recall: 0.9083 - fbeta_score: 0.9351 - val_loss: 0.4227 - val_acc: 0.9463 - val_recall: 0.8537 - val_fbeta_score: 0.8981\n",
      "Epoch 162/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.3180 - acc: 0.9615 - recall: 0.9067 - fbeta_score: 0.9285 - val_loss: 0.3731 - val_acc: 0.9561 - val_recall: 0.8488 - val_fbeta_score: 0.8820\n",
      "Epoch 163/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.3018 - acc: 0.9620 - recall: 0.9159 - fbeta_score: 0.9284 - val_loss: 0.3671 - val_acc: 0.9512 - val_recall: 0.8585 - val_fbeta_score: 0.8948\n",
      "Epoch 164/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.2893 - acc: 0.9626 - recall: 0.8747 - fbeta_score: 0.9110 - val_loss: 0.3555 - val_acc: 0.9561 - val_recall: 0.9122 - val_fbeta_score: 0.9056\n",
      "Epoch 165/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.2830 - acc: 0.9685 - recall: 0.8785 - fbeta_score: 0.9160 - val_loss: 0.3828 - val_acc: 0.9561 - val_recall: 0.8146 - val_fbeta_score: 0.8710\n",
      "Epoch 166/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.2810 - acc: 0.9647 - recall: 0.9164 - fbeta_score: 0.9348 - val_loss: 0.3842 - val_acc: 0.9561 - val_recall: 0.9512 - val_fbeta_score: 0.9465\n",
      "Epoch 167/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.2830 - acc: 0.9647 - recall: 0.8817 - fbeta_score: 0.9111 - val_loss: 0.3680 - val_acc: 0.9171 - val_recall: 0.9171 - val_fbeta_score: 0.9117\n",
      "Epoch 168/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.2951 - acc: 0.9593 - recall: 0.8991 - fbeta_score: 0.9239 - val_loss: 0.4474 - val_acc: 0.9415 - val_recall: 0.8098 - val_fbeta_score: 0.8696\n",
      "Epoch 169/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.3031 - acc: 0.9609 - recall: 0.8220 - fbeta_score: 0.8798 - val_loss: 0.4182 - val_acc: 0.9463 - val_recall: 0.7073 - val_fbeta_score: 0.7887\n",
      "Epoch 170/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.2743 - acc: 0.9636 - recall: 0.8893 - fbeta_score: 0.9191 - val_loss: 0.3571 - val_acc: 0.9561 - val_recall: 0.9561 - val_fbeta_score: 0.9475\n",
      "Epoch 171/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.2618 - acc: 0.9669 - recall: 0.8828 - fbeta_score: 0.9173 - val_loss: 0.3816 - val_acc: 0.9317 - val_recall: 0.7951 - val_fbeta_score: 0.8487\n",
      "Epoch 172/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.2687 - acc: 0.9685 - recall: 0.8817 - fbeta_score: 0.9142 - val_loss: 0.8358 - val_acc: 0.7951 - val_recall: 0.6976 - val_fbeta_score: 0.7256\n",
      "Epoch 173/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.3087 - acc: 0.9598 - recall: 0.9061 - fbeta_score: 0.9189 - val_loss: 0.3356 - val_acc: 0.9610 - val_recall: 0.9659 - val_fbeta_score: 0.9616\n",
      "Epoch 174/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.2661 - acc: 0.9691 - recall: 0.9105 - fbeta_score: 0.9322 - val_loss: 0.3144 - val_acc: 0.9561 - val_recall: 0.9610 - val_fbeta_score: 0.9523\n",
      "Epoch 175/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.2674 - acc: 0.9664 - recall: 0.8790 - fbeta_score: 0.9132 - val_loss: 0.3262 - val_acc: 0.9561 - val_recall: 0.9073 - val_fbeta_score: 0.9224\n",
      "Epoch 176/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.2571 - acc: 0.9691 - recall: 0.8882 - fbeta_score: 0.9221 - val_loss: 0.3711 - val_acc: 0.9366 - val_recall: 0.8000 - val_fbeta_score: 0.8507\n",
      "Epoch 177/500\n",
      "1843/1843 [==============================] - 0s 241us/step - loss: 0.2764 - acc: 0.9588 - recall: 0.9072 - fbeta_score: 0.9223 - val_loss: 0.3240 - val_acc: 0.9512 - val_recall: 0.9561 - val_fbeta_score: 0.9473\n",
      "Epoch 178/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.2533 - acc: 0.9685 - recall: 0.9387 - fbeta_score: 0.9481 - val_loss: 0.3386 - val_acc: 0.9463 - val_recall: 0.9366 - val_fbeta_score: 0.9460\n",
      "Epoch 179/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.2505 - acc: 0.9653 - recall: 0.9262 - fbeta_score: 0.9402 - val_loss: 0.3194 - val_acc: 0.9561 - val_recall: 0.8585 - val_fbeta_score: 0.8917\n",
      "Epoch 180/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.2348 - acc: 0.9702 - recall: 0.8937 - fbeta_score: 0.9253 - val_loss: 0.3666 - val_acc: 0.9463 - val_recall: 0.8829 - val_fbeta_score: 0.9059\n",
      "Epoch 181/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.2462 - acc: 0.9691 - recall: 0.9121 - fbeta_score: 0.9356 - val_loss: 0.2880 - val_acc: 0.9659 - val_recall: 0.9512 - val_fbeta_score: 0.9507\n",
      "Epoch 182/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.2511 - acc: 0.9647 - recall: 0.9012 - fbeta_score: 0.9270 - val_loss: 0.3096 - val_acc: 0.9561 - val_recall: 0.9268 - val_fbeta_score: 0.9373\n",
      "Epoch 183/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.2410 - acc: 0.9674 - recall: 0.9219 - fbeta_score: 0.9415 - val_loss: 0.3597 - val_acc: 0.9366 - val_recall: 0.9756 - val_fbeta_score: 0.9381\n",
      "Epoch 184/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.2420 - acc: 0.9696 - recall: 0.9311 - fbeta_score: 0.9444 - val_loss: 0.3390 - val_acc: 0.9561 - val_recall: 0.8927 - val_fbeta_score: 0.9275\n",
      "Epoch 185/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.2389 - acc: 0.9680 - recall: 0.8747 - fbeta_score: 0.9170 - val_loss: 0.3150 - val_acc: 0.9463 - val_recall: 0.9366 - val_fbeta_score: 0.9458\n",
      "Epoch 186/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.2362 - acc: 0.9702 - recall: 0.8969 - fbeta_score: 0.9294 - val_loss: 0.3352 - val_acc: 0.9512 - val_recall: 0.8293 - val_fbeta_score: 0.8857\n",
      "Epoch 187/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.2337 - acc: 0.9664 - recall: 0.9246 - fbeta_score: 0.9422 - val_loss: 0.2910 - val_acc: 0.9561 - val_recall: 0.9366 - val_fbeta_score: 0.9409\n",
      "Epoch 188/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.2344 - acc: 0.9718 - recall: 0.8779 - fbeta_score: 0.9164 - val_loss: 0.2786 - val_acc: 0.9463 - val_recall: 0.9463 - val_fbeta_score: 0.9259\n",
      "Epoch 189/500\n",
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.2221 - acc: 0.9712 - recall: 0.8785 - fbeta_score: 0.9132 - val_loss: 0.3050 - val_acc: 0.9512 - val_recall: 0.9024 - val_fbeta_score: 0.9227\n",
      "Epoch 190/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.2353 - acc: 0.9674 - recall: 0.8926 - fbeta_score: 0.9239 - val_loss: 0.3322 - val_acc: 0.9512 - val_recall: 0.9463 - val_fbeta_score: 0.9398\n",
      "Epoch 191/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.2301 - acc: 0.9658 - recall: 0.9376 - fbeta_score: 0.9451 - val_loss: 0.3139 - val_acc: 0.9610 - val_recall: 0.7951 - val_fbeta_score: 0.8476\n",
      "Epoch 192/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.2163 - acc: 0.9723 - recall: 0.8676 - fbeta_score: 0.9133 - val_loss: 0.3294 - val_acc: 0.9512 - val_recall: 0.8780 - val_fbeta_score: 0.9161\n",
      "Epoch 193/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.2355 - acc: 0.9658 - recall: 0.9186 - fbeta_score: 0.9393 - val_loss: 0.3089 - val_acc: 0.9659 - val_recall: 0.9366 - val_fbeta_score: 0.9231\n",
      "Epoch 194/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.2310 - acc: 0.9658 - recall: 0.9034 - fbeta_score: 0.9311 - val_loss: 0.3371 - val_acc: 0.9561 - val_recall: 0.7951 - val_fbeta_score: 0.8638\n",
      "Epoch 195/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.2172 - acc: 0.9669 - recall: 0.9121 - fbeta_score: 0.9364 - val_loss: 0.2744 - val_acc: 0.9659 - val_recall: 0.9268 - val_fbeta_score: 0.9424\n",
      "Epoch 196/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.2276 - acc: 0.9685 - recall: 0.9148 - fbeta_score: 0.9370 - val_loss: 0.2634 - val_acc: 0.9610 - val_recall: 0.9561 - val_fbeta_score: 0.9509\n",
      "Epoch 197/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.2131 - acc: 0.9723 - recall: 0.9040 - fbeta_score: 0.9324 - val_loss: 0.2913 - val_acc: 0.9561 - val_recall: 0.9366 - val_fbeta_score: 0.9502\n",
      "Epoch 198/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.2157 - acc: 0.9718 - recall: 0.9251 - fbeta_score: 0.9455 - val_loss: 0.2918 - val_acc: 0.9512 - val_recall: 0.9317 - val_fbeta_score: 0.9451\n",
      "Epoch 199/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.2188 - acc: 0.9642 - recall: 0.9154 - fbeta_score: 0.9406 - val_loss: 0.2880 - val_acc: 0.9659 - val_recall: 0.9561 - val_fbeta_score: 0.9540\n",
      "Epoch 200/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.2032 - acc: 0.9718 - recall: 0.9116 - fbeta_score: 0.9391 - val_loss: 0.3439 - val_acc: 0.9512 - val_recall: 0.8537 - val_fbeta_score: 0.8899\n",
      "Epoch 201/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.2040 - acc: 0.9718 - recall: 0.8958 - fbeta_score: 0.9308 - val_loss: 0.2983 - val_acc: 0.9561 - val_recall: 0.9220 - val_fbeta_score: 0.9394\n",
      "Epoch 202/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.2074 - acc: 0.9691 - recall: 0.9148 - fbeta_score: 0.9406 - val_loss: 0.2822 - val_acc: 0.9512 - val_recall: 0.9171 - val_fbeta_score: 0.9371\n",
      "Epoch 203/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1968 - acc: 0.9680 - recall: 0.9159 - fbeta_score: 0.9377 - val_loss: 0.2688 - val_acc: 0.9610 - val_recall: 0.8780 - val_fbeta_score: 0.9056\n",
      "Epoch 204/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1921 - acc: 0.9734 - recall: 0.9267 - fbeta_score: 0.9457 - val_loss: 0.2551 - val_acc: 0.9561 - val_recall: 0.9317 - val_fbeta_score: 0.9491\n",
      "Epoch 205/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.2127 - acc: 0.9674 - recall: 0.9278 - fbeta_score: 0.9489 - val_loss: 0.3610 - val_acc: 0.9171 - val_recall: 0.8878 - val_fbeta_score: 0.9074\n",
      "Epoch 206/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.2110 - acc: 0.9653 - recall: 0.8953 - fbeta_score: 0.9280 - val_loss: 0.2537 - val_acc: 0.9659 - val_recall: 0.9073 - val_fbeta_score: 0.9355\n",
      "Epoch 207/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1916 - acc: 0.9712 - recall: 0.8964 - fbeta_score: 0.9337 - val_loss: 0.3033 - val_acc: 0.9610 - val_recall: 0.8537 - val_fbeta_score: 0.9000\n",
      "Epoch 208/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.2103 - acc: 0.9631 - recall: 0.9154 - fbeta_score: 0.9381 - val_loss: 0.2736 - val_acc: 0.9463 - val_recall: 0.9561 - val_fbeta_score: 0.9428\n",
      "Epoch 209/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1964 - acc: 0.9680 - recall: 0.9419 - fbeta_score: 0.9521 - val_loss: 0.2820 - val_acc: 0.9561 - val_recall: 0.9024 - val_fbeta_score: 0.9215\n",
      "Epoch 210/500\n",
      "1843/1843 [==============================] - 0s 252us/step - loss: 0.1972 - acc: 0.9691 - recall: 0.9132 - fbeta_score: 0.9413 - val_loss: 0.2780 - val_acc: 0.9610 - val_recall: 0.9268 - val_fbeta_score: 0.9471\n",
      "Epoch 211/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1925 - acc: 0.9691 - recall: 0.9251 - fbeta_score: 0.9447 - val_loss: 0.2785 - val_acc: 0.9512 - val_recall: 0.8390 - val_fbeta_score: 0.8808\n",
      "Epoch 212/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1851 - acc: 0.9718 - recall: 0.9061 - fbeta_score: 0.9337 - val_loss: 0.2327 - val_acc: 0.9561 - val_recall: 0.9220 - val_fbeta_score: 0.9288\n",
      "Epoch 213/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1952 - acc: 0.9691 - recall: 0.9164 - fbeta_score: 0.9385 - val_loss: 0.2651 - val_acc: 0.9659 - val_recall: 0.9366 - val_fbeta_score: 0.9312\n",
      "Epoch 214/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1857 - acc: 0.9729 - recall: 0.9105 - fbeta_score: 0.9370 - val_loss: 0.2277 - val_acc: 0.9610 - val_recall: 0.9366 - val_fbeta_score: 0.9390\n",
      "Epoch 215/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1893 - acc: 0.9696 - recall: 0.9143 - fbeta_score: 0.9400 - val_loss: 0.2711 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9407\n",
      "Epoch 216/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.2101 - acc: 0.9642 - recall: 0.9278 - fbeta_score: 0.9438 - val_loss: 0.2664 - val_acc: 0.9463 - val_recall: 0.9415 - val_fbeta_score: 0.9396\n",
      "Epoch 217/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1886 - acc: 0.9685 - recall: 0.9246 - fbeta_score: 0.9467 - val_loss: 0.2425 - val_acc: 0.9610 - val_recall: 0.9610 - val_fbeta_score: 0.9609\n",
      "Epoch 218/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1761 - acc: 0.9740 - recall: 0.8974 - fbeta_score: 0.9312 - val_loss: 0.2511 - val_acc: 0.9561 - val_recall: 0.9317 - val_fbeta_score: 0.9473\n",
      "Epoch 219/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1767 - acc: 0.9718 - recall: 0.9078 - fbeta_score: 0.9367 - val_loss: 0.3995 - val_acc: 0.8829 - val_recall: 0.8585 - val_fbeta_score: 0.8464\n",
      "Epoch 220/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1927 - acc: 0.9707 - recall: 0.9262 - fbeta_score: 0.9413 - val_loss: 0.2495 - val_acc: 0.9610 - val_recall: 0.9561 - val_fbeta_score: 0.9581\n",
      "Epoch 221/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1899 - acc: 0.9734 - recall: 0.9284 - fbeta_score: 0.9516 - val_loss: 0.2608 - val_acc: 0.9512 - val_recall: 0.9220 - val_fbeta_score: 0.9374\n",
      "Epoch 222/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1870 - acc: 0.9702 - recall: 0.9197 - fbeta_score: 0.9437 - val_loss: 0.2608 - val_acc: 0.9463 - val_recall: 0.9561 - val_fbeta_score: 0.9517\n",
      "Epoch 223/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1757 - acc: 0.9702 - recall: 0.9181 - fbeta_score: 0.9423 - val_loss: 0.2883 - val_acc: 0.9512 - val_recall: 0.9220 - val_fbeta_score: 0.9399\n",
      "Epoch 224/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1795 - acc: 0.9680 - recall: 0.9273 - fbeta_score: 0.9448 - val_loss: 0.2402 - val_acc: 0.9512 - val_recall: 0.9317 - val_fbeta_score: 0.9473\n",
      "Epoch 225/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1720 - acc: 0.9729 - recall: 0.9273 - fbeta_score: 0.9488 - val_loss: 0.2338 - val_acc: 0.9659 - val_recall: 0.9610 - val_fbeta_score: 0.9565\n",
      "Epoch 226/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1814 - acc: 0.9653 - recall: 0.9517 - fbeta_score: 0.9551 - val_loss: 0.2286 - val_acc: 0.9659 - val_recall: 0.9610 - val_fbeta_score: 0.9630\n",
      "Epoch 227/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1841 - acc: 0.9669 - recall: 0.9403 - fbeta_score: 0.9535 - val_loss: 0.2236 - val_acc: 0.9610 - val_recall: 0.9707 - val_fbeta_score: 0.9530\n",
      "Epoch 228/500\n",
      "1843/1843 [==============================] - 0s 214us/step - loss: 0.1781 - acc: 0.9696 - recall: 0.9305 - fbeta_score: 0.9461 - val_loss: 0.2443 - val_acc: 0.9610 - val_recall: 0.9512 - val_fbeta_score: 0.9517\n",
      "Epoch 229/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1717 - acc: 0.9718 - recall: 0.9235 - fbeta_score: 0.9466 - val_loss: 0.2390 - val_acc: 0.9415 - val_recall: 0.9268 - val_fbeta_score: 0.9338\n",
      "Epoch 230/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1765 - acc: 0.9653 - recall: 0.8681 - fbeta_score: 0.9158 - val_loss: 0.2833 - val_acc: 0.9512 - val_recall: 0.7902 - val_fbeta_score: 0.8492\n",
      "Epoch 231/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1786 - acc: 0.9691 - recall: 0.9251 - fbeta_score: 0.9441 - val_loss: 0.3260 - val_acc: 0.9415 - val_recall: 0.8049 - val_fbeta_score: 0.8757\n",
      "Epoch 232/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1699 - acc: 0.9740 - recall: 0.9116 - fbeta_score: 0.9415 - val_loss: 0.2406 - val_acc: 0.9610 - val_recall: 0.9220 - val_fbeta_score: 0.9393\n",
      "Epoch 233/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1793 - acc: 0.9669 - recall: 0.9099 - fbeta_score: 0.9340 - val_loss: 0.2214 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9455\n",
      "Epoch 234/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1743 - acc: 0.9696 - recall: 0.9230 - fbeta_score: 0.9441 - val_loss: 0.2402 - val_acc: 0.9610 - val_recall: 0.9268 - val_fbeta_score: 0.9445\n",
      "Epoch 235/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1711 - acc: 0.9696 - recall: 0.8947 - fbeta_score: 0.9257 - val_loss: 0.2323 - val_acc: 0.9610 - val_recall: 0.9659 - val_fbeta_score: 0.9482\n",
      "Epoch 236/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1709 - acc: 0.9653 - recall: 0.9175 - fbeta_score: 0.9392 - val_loss: 0.2511 - val_acc: 0.9561 - val_recall: 0.9122 - val_fbeta_score: 0.9236\n",
      "Epoch 237/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1621 - acc: 0.9718 - recall: 0.9012 - fbeta_score: 0.9358 - val_loss: 0.2394 - val_acc: 0.9463 - val_recall: 0.8927 - val_fbeta_score: 0.9275\n",
      "Epoch 238/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1701 - acc: 0.9664 - recall: 0.8882 - fbeta_score: 0.9252 - val_loss: 0.2499 - val_acc: 0.9463 - val_recall: 0.9317 - val_fbeta_score: 0.9407\n",
      "Epoch 239/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1672 - acc: 0.9707 - recall: 0.9300 - fbeta_score: 0.9458 - val_loss: 0.2608 - val_acc: 0.9463 - val_recall: 0.9415 - val_fbeta_score: 0.9437\n",
      "Epoch 240/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1705 - acc: 0.9680 - recall: 0.9170 - fbeta_score: 0.9395 - val_loss: 0.2233 - val_acc: 0.9659 - val_recall: 0.9268 - val_fbeta_score: 0.9402\n",
      "Epoch 241/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1580 - acc: 0.9712 - recall: 0.9126 - fbeta_score: 0.9401 - val_loss: 0.2050 - val_acc: 0.9659 - val_recall: 0.9610 - val_fbeta_score: 0.9628\n",
      "Epoch 242/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1581 - acc: 0.9707 - recall: 0.9121 - fbeta_score: 0.9404 - val_loss: 0.2456 - val_acc: 0.9463 - val_recall: 0.9171 - val_fbeta_score: 0.9303\n",
      "Epoch 243/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1660 - acc: 0.9680 - recall: 0.9034 - fbeta_score: 0.9338 - val_loss: 0.2300 - val_acc: 0.9610 - val_recall: 0.9756 - val_fbeta_score: 0.9645\n",
      "Epoch 244/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1727 - acc: 0.9696 - recall: 0.9040 - fbeta_score: 0.9319 - val_loss: 0.2192 - val_acc: 0.9512 - val_recall: 0.9268 - val_fbeta_score: 0.9379\n",
      "Epoch 245/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1606 - acc: 0.9702 - recall: 0.9137 - fbeta_score: 0.9364 - val_loss: 0.2475 - val_acc: 0.9512 - val_recall: 0.8878 - val_fbeta_score: 0.9122\n",
      "Epoch 246/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1677 - acc: 0.9674 - recall: 0.9230 - fbeta_score: 0.9421 - val_loss: 0.2505 - val_acc: 0.9512 - val_recall: 0.8976 - val_fbeta_score: 0.9179\n",
      "Epoch 247/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.1482 - acc: 0.9745 - recall: 0.9300 - fbeta_score: 0.9487 - val_loss: 0.2124 - val_acc: 0.9512 - val_recall: 0.9463 - val_fbeta_score: 0.9512\n",
      "Epoch 248/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1510 - acc: 0.9745 - recall: 0.9219 - fbeta_score: 0.9482 - val_loss: 0.2379 - val_acc: 0.9610 - val_recall: 0.9366 - val_fbeta_score: 0.9470\n",
      "Epoch 249/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1615 - acc: 0.9691 - recall: 0.9300 - fbeta_score: 0.9455 - val_loss: 0.2234 - val_acc: 0.9561 - val_recall: 0.9317 - val_fbeta_score: 0.9442\n",
      "Epoch 250/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1616 - acc: 0.9712 - recall: 0.9029 - fbeta_score: 0.9351 - val_loss: 0.2245 - val_acc: 0.9561 - val_recall: 0.9220 - val_fbeta_score: 0.9394\n",
      "Epoch 251/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1597 - acc: 0.9691 - recall: 0.9040 - fbeta_score: 0.9296 - val_loss: 0.2298 - val_acc: 0.9512 - val_recall: 0.9122 - val_fbeta_score: 0.9311\n",
      "Epoch 252/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.1501 - acc: 0.9712 - recall: 0.9219 - fbeta_score: 0.9445 - val_loss: 0.2102 - val_acc: 0.9659 - val_recall: 0.9707 - val_fbeta_score: 0.9640\n",
      "Epoch 253/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1465 - acc: 0.9718 - recall: 0.9267 - fbeta_score: 0.9459 - val_loss: 0.2339 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9478\n",
      "Epoch 254/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1468 - acc: 0.9734 - recall: 0.9235 - fbeta_score: 0.9461 - val_loss: 0.2133 - val_acc: 0.9610 - val_recall: 0.9317 - val_fbeta_score: 0.9404\n",
      "Epoch 255/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1592 - acc: 0.9664 - recall: 0.9295 - fbeta_score: 0.9442 - val_loss: 0.2350 - val_acc: 0.9610 - val_recall: 0.9512 - val_fbeta_score: 0.9463\n",
      "Epoch 256/500\n",
      "1843/1843 [==============================] - 0s 218us/step - loss: 0.1574 - acc: 0.9669 - recall: 0.9273 - fbeta_score: 0.9436 - val_loss: 0.2021 - val_acc: 0.9512 - val_recall: 0.9707 - val_fbeta_score: 0.9531\n",
      "Epoch 257/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1557 - acc: 0.9723 - recall: 0.9197 - fbeta_score: 0.9412 - val_loss: 0.2317 - val_acc: 0.9512 - val_recall: 0.9415 - val_fbeta_score: 0.9461\n",
      "Epoch 258/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1457 - acc: 0.9712 - recall: 0.9398 - fbeta_score: 0.9552 - val_loss: 0.2955 - val_acc: 0.9122 - val_recall: 0.8878 - val_fbeta_score: 0.8695\n",
      "Epoch 259/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1651 - acc: 0.9685 - recall: 0.9430 - fbeta_score: 0.9498 - val_loss: 0.1994 - val_acc: 0.9561 - val_recall: 0.9073 - val_fbeta_score: 0.9332\n",
      "Epoch 260/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1582 - acc: 0.9734 - recall: 0.9246 - fbeta_score: 0.9464 - val_loss: 0.2530 - val_acc: 0.9512 - val_recall: 0.9268 - val_fbeta_score: 0.9381\n",
      "Epoch 261/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1505 - acc: 0.9674 - recall: 0.9213 - fbeta_score: 0.9430 - val_loss: 0.1965 - val_acc: 0.9610 - val_recall: 0.9610 - val_fbeta_score: 0.9588\n",
      "Epoch 262/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1548 - acc: 0.9696 - recall: 0.9208 - fbeta_score: 0.9456 - val_loss: 0.2189 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9527\n",
      "Epoch 263/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1496 - acc: 0.9702 - recall: 0.9186 - fbeta_score: 0.9403 - val_loss: 0.2297 - val_acc: 0.9610 - val_recall: 0.8927 - val_fbeta_score: 0.9224\n",
      "Epoch 264/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1501 - acc: 0.9729 - recall: 0.9148 - fbeta_score: 0.9370 - val_loss: 0.2091 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9527\n",
      "Epoch 265/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1464 - acc: 0.9707 - recall: 0.9143 - fbeta_score: 0.9391 - val_loss: 0.2658 - val_acc: 0.9512 - val_recall: 0.9171 - val_fbeta_score: 0.9370\n",
      "Epoch 266/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1451 - acc: 0.9712 - recall: 0.9208 - fbeta_score: 0.9435 - val_loss: 0.2028 - val_acc: 0.9463 - val_recall: 0.9415 - val_fbeta_score: 0.9465\n",
      "Epoch 267/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1500 - acc: 0.9696 - recall: 0.9213 - fbeta_score: 0.9411 - val_loss: 0.2341 - val_acc: 0.9707 - val_recall: 0.9366 - val_fbeta_score: 0.9410\n",
      "Epoch 268/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1586 - acc: 0.9653 - recall: 0.9078 - fbeta_score: 0.9309 - val_loss: 0.2299 - val_acc: 0.9561 - val_recall: 0.9561 - val_fbeta_score: 0.9494\n",
      "Epoch 269/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1451 - acc: 0.9723 - recall: 0.8882 - fbeta_score: 0.9269 - val_loss: 0.2503 - val_acc: 0.9561 - val_recall: 0.8585 - val_fbeta_score: 0.9033\n",
      "Epoch 270/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1465 - acc: 0.9712 - recall: 0.8964 - fbeta_score: 0.9291 - val_loss: 0.2156 - val_acc: 0.9512 - val_recall: 0.9463 - val_fbeta_score: 0.9423\n",
      "Epoch 271/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1411 - acc: 0.9723 - recall: 0.9034 - fbeta_score: 0.9300 - val_loss: 0.2474 - val_acc: 0.9512 - val_recall: 0.9122 - val_fbeta_score: 0.9296\n",
      "Epoch 272/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1449 - acc: 0.9740 - recall: 0.9083 - fbeta_score: 0.9384 - val_loss: 0.1869 - val_acc: 0.9610 - val_recall: 0.9171 - val_fbeta_score: 0.9344\n",
      "Epoch 273/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1425 - acc: 0.9691 - recall: 0.9170 - fbeta_score: 0.9410 - val_loss: 0.2075 - val_acc: 0.9610 - val_recall: 0.9366 - val_fbeta_score: 0.9476\n",
      "Epoch 274/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1379 - acc: 0.9718 - recall: 0.9284 - fbeta_score: 0.9504 - val_loss: 0.2167 - val_acc: 0.9659 - val_recall: 0.9512 - val_fbeta_score: 0.9540\n",
      "Epoch 275/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1421 - acc: 0.9691 - recall: 0.9278 - fbeta_score: 0.9469 - val_loss: 0.2201 - val_acc: 0.9610 - val_recall: 0.9610 - val_fbeta_score: 0.9656\n",
      "Epoch 276/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1353 - acc: 0.9734 - recall: 0.9316 - fbeta_score: 0.9524 - val_loss: 0.2280 - val_acc: 0.9610 - val_recall: 0.9463 - val_fbeta_score: 0.9555\n",
      "Epoch 277/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1452 - acc: 0.9653 - recall: 0.9094 - fbeta_score: 0.9354 - val_loss: 0.2000 - val_acc: 0.9707 - val_recall: 0.9512 - val_fbeta_score: 0.9607\n",
      "Epoch 278/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1316 - acc: 0.9723 - recall: 0.9045 - fbeta_score: 0.9381 - val_loss: 0.2070 - val_acc: 0.9512 - val_recall: 0.9073 - val_fbeta_score: 0.9280\n",
      "Epoch 279/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1434 - acc: 0.9718 - recall: 0.9067 - fbeta_score: 0.9398 - val_loss: 0.1835 - val_acc: 0.9659 - val_recall: 0.9512 - val_fbeta_score: 0.9553\n",
      "Epoch 280/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1372 - acc: 0.9664 - recall: 0.9050 - fbeta_score: 0.9330 - val_loss: 0.2265 - val_acc: 0.9610 - val_recall: 0.9366 - val_fbeta_score: 0.9481\n",
      "Epoch 281/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1379 - acc: 0.9712 - recall: 0.9029 - fbeta_score: 0.9342 - val_loss: 0.2374 - val_acc: 0.9512 - val_recall: 0.9220 - val_fbeta_score: 0.9376\n",
      "Epoch 282/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1337 - acc: 0.9712 - recall: 0.9186 - fbeta_score: 0.9447 - val_loss: 0.2181 - val_acc: 0.9561 - val_recall: 0.9512 - val_fbeta_score: 0.9512\n",
      "Epoch 283/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1372 - acc: 0.9707 - recall: 0.9143 - fbeta_score: 0.9437 - val_loss: 0.2498 - val_acc: 0.9512 - val_recall: 0.9317 - val_fbeta_score: 0.9404\n",
      "Epoch 284/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1316 - acc: 0.9734 - recall: 0.9327 - fbeta_score: 0.9529 - val_loss: 0.2156 - val_acc: 0.9561 - val_recall: 0.9561 - val_fbeta_score: 0.9560\n",
      "Epoch 285/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1339 - acc: 0.9734 - recall: 0.9170 - fbeta_score: 0.9430 - val_loss: 0.1897 - val_acc: 0.9610 - val_recall: 0.9659 - val_fbeta_score: 0.9591\n",
      "Epoch 286/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1310 - acc: 0.9756 - recall: 0.9202 - fbeta_score: 0.9467 - val_loss: 0.2181 - val_acc: 0.9610 - val_recall: 0.9610 - val_fbeta_score: 0.9589\n",
      "Epoch 287/500\n",
      "1843/1843 [==============================] - 0s 247us/step - loss: 0.1434 - acc: 0.9642 - recall: 0.9230 - fbeta_score: 0.9421 - val_loss: 0.2258 - val_acc: 0.9512 - val_recall: 0.9561 - val_fbeta_score: 0.9472\n",
      "Epoch 288/500\n",
      "1843/1843 [==============================] - 0s 242us/step - loss: 0.1345 - acc: 0.9707 - recall: 0.9311 - fbeta_score: 0.9474 - val_loss: 0.2212 - val_acc: 0.9561 - val_recall: 0.8585 - val_fbeta_score: 0.8958\n",
      "Epoch 289/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1301 - acc: 0.9734 - recall: 0.9159 - fbeta_score: 0.9396 - val_loss: 0.2042 - val_acc: 0.9512 - val_recall: 0.9415 - val_fbeta_score: 0.9481\n",
      "Epoch 290/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1283 - acc: 0.9734 - recall: 0.9240 - fbeta_score: 0.9446 - val_loss: 0.2230 - val_acc: 0.9512 - val_recall: 0.9268 - val_fbeta_score: 0.9399\n",
      "Epoch 291/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1289 - acc: 0.9707 - recall: 0.9197 - fbeta_score: 0.9437 - val_loss: 0.2002 - val_acc: 0.9659 - val_recall: 0.9512 - val_fbeta_score: 0.9489\n",
      "Epoch 292/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.1220 - acc: 0.9745 - recall: 0.9224 - fbeta_score: 0.9446 - val_loss: 0.2378 - val_acc: 0.9512 - val_recall: 0.9122 - val_fbeta_score: 0.9400\n",
      "Epoch 293/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1543 - acc: 0.9615 - recall: 0.9246 - fbeta_score: 0.9446 - val_loss: 0.1944 - val_acc: 0.9707 - val_recall: 0.9756 - val_fbeta_score: 0.9689\n",
      "Epoch 294/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1319 - acc: 0.9696 - recall: 0.9230 - fbeta_score: 0.9440 - val_loss: 0.2410 - val_acc: 0.9463 - val_recall: 0.9220 - val_fbeta_score: 0.9325\n",
      "Epoch 295/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1341 - acc: 0.9750 - recall: 0.9392 - fbeta_score: 0.9541 - val_loss: 0.2024 - val_acc: 0.9561 - val_recall: 0.9317 - val_fbeta_score: 0.9488\n",
      "Epoch 296/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1229 - acc: 0.9756 - recall: 0.9175 - fbeta_score: 0.9449 - val_loss: 0.2199 - val_acc: 0.9561 - val_recall: 0.9268 - val_fbeta_score: 0.9349\n",
      "Epoch 297/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1246 - acc: 0.9756 - recall: 0.9072 - fbeta_score: 0.9382 - val_loss: 0.2521 - val_acc: 0.9512 - val_recall: 0.8293 - val_fbeta_score: 0.8775\n",
      "Epoch 298/500\n",
      "1843/1843 [==============================] - 0s 222us/step - loss: 0.1364 - acc: 0.9718 - recall: 0.9088 - fbeta_score: 0.9339 - val_loss: 0.2251 - val_acc: 0.9512 - val_recall: 0.8976 - val_fbeta_score: 0.9200\n",
      "Epoch 299/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1217 - acc: 0.9788 - recall: 0.9208 - fbeta_score: 0.9465 - val_loss: 0.1984 - val_acc: 0.9610 - val_recall: 0.9268 - val_fbeta_score: 0.9437\n",
      "Epoch 300/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1259 - acc: 0.9778 - recall: 0.9126 - fbeta_score: 0.9433 - val_loss: 0.1962 - val_acc: 0.9610 - val_recall: 0.9317 - val_fbeta_score: 0.9476\n",
      "Epoch 301/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1318 - acc: 0.9718 - recall: 0.9343 - fbeta_score: 0.9518 - val_loss: 0.1936 - val_acc: 0.9707 - val_recall: 0.9366 - val_fbeta_score: 0.9543\n",
      "Epoch 302/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1322 - acc: 0.9707 - recall: 0.9007 - fbeta_score: 0.9365 - val_loss: 0.2273 - val_acc: 0.9512 - val_recall: 0.9220 - val_fbeta_score: 0.9379\n",
      "Epoch 303/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1346 - acc: 0.9723 - recall: 0.9267 - fbeta_score: 0.9476 - val_loss: 0.1791 - val_acc: 0.9463 - val_recall: 0.9415 - val_fbeta_score: 0.9440\n",
      "Epoch 304/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1401 - acc: 0.9680 - recall: 0.9262 - fbeta_score: 0.9450 - val_loss: 0.1971 - val_acc: 0.9512 - val_recall: 0.9610 - val_fbeta_score: 0.9614\n",
      "Epoch 305/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1260 - acc: 0.9734 - recall: 0.9224 - fbeta_score: 0.9458 - val_loss: 0.2400 - val_acc: 0.9512 - val_recall: 0.9317 - val_fbeta_score: 0.9386\n",
      "Epoch 306/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1262 - acc: 0.9734 - recall: 0.9376 - fbeta_score: 0.9556 - val_loss: 0.2289 - val_acc: 0.9512 - val_recall: 0.9268 - val_fbeta_score: 0.9360\n",
      "Epoch 307/500\n",
      "1843/1843 [==============================] - 0s 242us/step - loss: 0.1400 - acc: 0.9680 - recall: 0.9235 - fbeta_score: 0.9427 - val_loss: 0.2326 - val_acc: 0.9512 - val_recall: 0.9512 - val_fbeta_score: 0.9512\n",
      "Epoch 308/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1275 - acc: 0.9723 - recall: 0.9441 - fbeta_score: 0.9565 - val_loss: 0.1760 - val_acc: 0.9610 - val_recall: 0.9561 - val_fbeta_score: 0.9565\n",
      "Epoch 309/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1237 - acc: 0.9712 - recall: 0.9202 - fbeta_score: 0.9450 - val_loss: 0.2569 - val_acc: 0.9415 - val_recall: 0.9415 - val_fbeta_score: 0.9391\n",
      "Epoch 310/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.1241 - acc: 0.9756 - recall: 0.9257 - fbeta_score: 0.9495 - val_loss: 0.2035 - val_acc: 0.9610 - val_recall: 0.8829 - val_fbeta_score: 0.9136\n",
      "Epoch 311/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1281 - acc: 0.9756 - recall: 0.9186 - fbeta_score: 0.9462 - val_loss: 0.2458 - val_acc: 0.9415 - val_recall: 0.8049 - val_fbeta_score: 0.8617\n",
      "Epoch 312/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1318 - acc: 0.9718 - recall: 0.9305 - fbeta_score: 0.9489 - val_loss: 0.2070 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9412\n",
      "Epoch 313/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1333 - acc: 0.9712 - recall: 0.9311 - fbeta_score: 0.9485 - val_loss: 0.2133 - val_acc: 0.9512 - val_recall: 0.9171 - val_fbeta_score: 0.9325\n",
      "Epoch 314/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1360 - acc: 0.9740 - recall: 0.9202 - fbeta_score: 0.9435 - val_loss: 0.1981 - val_acc: 0.9561 - val_recall: 0.9366 - val_fbeta_score: 0.9499\n",
      "Epoch 315/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1344 - acc: 0.9745 - recall: 0.9262 - fbeta_score: 0.9506 - val_loss: 0.1971 - val_acc: 0.9561 - val_recall: 0.9317 - val_fbeta_score: 0.9474\n",
      "Epoch 316/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1317 - acc: 0.9702 - recall: 0.9126 - fbeta_score: 0.9414 - val_loss: 0.2072 - val_acc: 0.9561 - val_recall: 0.9463 - val_fbeta_score: 0.9528\n",
      "Epoch 317/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1394 - acc: 0.9680 - recall: 0.9392 - fbeta_score: 0.9532 - val_loss: 0.1799 - val_acc: 0.9512 - val_recall: 0.9659 - val_fbeta_score: 0.9553\n",
      "Epoch 318/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.1469 - acc: 0.9685 - recall: 0.9343 - fbeta_score: 0.9467 - val_loss: 0.2116 - val_acc: 0.9561 - val_recall: 0.9317 - val_fbeta_score: 0.9425\n",
      "Epoch 319/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.1386 - acc: 0.9718 - recall: 0.9126 - fbeta_score: 0.9378 - val_loss: 0.1987 - val_acc: 0.9561 - val_recall: 0.9171 - val_fbeta_score: 0.9389\n",
      "Epoch 320/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1261 - acc: 0.9761 - recall: 0.9132 - fbeta_score: 0.9440 - val_loss: 0.2084 - val_acc: 0.9512 - val_recall: 0.9171 - val_fbeta_score: 0.9368\n",
      "Epoch 321/500\n",
      "1843/1843 [==============================] - 0s 260us/step - loss: 0.1334 - acc: 0.9740 - recall: 0.9099 - fbeta_score: 0.9384 - val_loss: 0.1895 - val_acc: 0.9561 - val_recall: 0.9171 - val_fbeta_score: 0.9363\n",
      "Epoch 322/500\n",
      "1843/1843 [==============================] - 1s 274us/step - loss: 0.1231 - acc: 0.9778 - recall: 0.9175 - fbeta_score: 0.9465 - val_loss: 0.2053 - val_acc: 0.9463 - val_recall: 0.9415 - val_fbeta_score: 0.9507\n",
      "Epoch 323/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.1267 - acc: 0.9750 - recall: 0.9045 - fbeta_score: 0.9393 - val_loss: 0.1890 - val_acc: 0.9610 - val_recall: 0.9366 - val_fbeta_score: 0.9455\n",
      "Epoch 324/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1209 - acc: 0.9761 - recall: 0.9116 - fbeta_score: 0.9432 - val_loss: 0.1987 - val_acc: 0.9610 - val_recall: 0.9268 - val_fbeta_score: 0.9447\n",
      "Epoch 325/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1323 - acc: 0.9750 - recall: 0.9083 - fbeta_score: 0.9410 - val_loss: 0.2057 - val_acc: 0.9512 - val_recall: 0.9024 - val_fbeta_score: 0.9242\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 217us/step - loss: 0.1272 - acc: 0.9740 - recall: 0.8996 - fbeta_score: 0.9333 - val_loss: 0.1955 - val_acc: 0.9610 - val_recall: 0.9317 - val_fbeta_score: 0.9473\n",
      "Epoch 327/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1376 - acc: 0.9696 - recall: 0.9029 - fbeta_score: 0.9334 - val_loss: 0.2226 - val_acc: 0.9561 - val_recall: 0.9463 - val_fbeta_score: 0.9512\n",
      "Epoch 328/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1309 - acc: 0.9718 - recall: 0.9072 - fbeta_score: 0.9347 - val_loss: 0.1841 - val_acc: 0.9610 - val_recall: 0.9561 - val_fbeta_score: 0.9540\n",
      "Epoch 329/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1207 - acc: 0.9734 - recall: 0.9132 - fbeta_score: 0.9400 - val_loss: 0.1894 - val_acc: 0.9659 - val_recall: 0.9171 - val_fbeta_score: 0.9391\n",
      "Epoch 330/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1210 - acc: 0.9756 - recall: 0.9224 - fbeta_score: 0.9454 - val_loss: 0.2264 - val_acc: 0.9512 - val_recall: 0.8976 - val_fbeta_score: 0.9161\n",
      "Epoch 331/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1138 - acc: 0.9756 - recall: 0.8931 - fbeta_score: 0.9314 - val_loss: 0.2037 - val_acc: 0.9561 - val_recall: 0.9122 - val_fbeta_score: 0.9357\n",
      "Epoch 332/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.1358 - acc: 0.9680 - recall: 0.8980 - fbeta_score: 0.9281 - val_loss: 0.1847 - val_acc: 0.9659 - val_recall: 0.9756 - val_fbeta_score: 0.9623\n",
      "Epoch 333/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.1257 - acc: 0.9718 - recall: 0.9132 - fbeta_score: 0.9374 - val_loss: 0.1953 - val_acc: 0.9415 - val_recall: 0.9707 - val_fbeta_score: 0.9393\n",
      "Epoch 334/500\n",
      "1843/1843 [==============================] - 0s 250us/step - loss: 0.1260 - acc: 0.9756 - recall: 0.9414 - fbeta_score: 0.9545 - val_loss: 0.1766 - val_acc: 0.9659 - val_recall: 0.9561 - val_fbeta_score: 0.9604\n",
      "Epoch 335/500\n",
      "1843/1843 [==============================] - 0s 256us/step - loss: 0.1289 - acc: 0.9723 - recall: 0.9278 - fbeta_score: 0.9461 - val_loss: 0.1879 - val_acc: 0.9561 - val_recall: 0.9561 - val_fbeta_score: 0.9584\n",
      "Epoch 336/500\n",
      "1843/1843 [==============================] - 1s 289us/step - loss: 0.1299 - acc: 0.9734 - recall: 0.9132 - fbeta_score: 0.9407 - val_loss: 0.2357 - val_acc: 0.9512 - val_recall: 0.9024 - val_fbeta_score: 0.9209\n",
      "Epoch 337/500\n",
      "1843/1843 [==============================] - 0s 269us/step - loss: 0.1247 - acc: 0.9734 - recall: 0.9235 - fbeta_score: 0.9443 - val_loss: 0.1979 - val_acc: 0.9610 - val_recall: 0.9561 - val_fbeta_score: 0.9584\n",
      "Epoch 338/500\n",
      "1843/1843 [==============================] - 0s 266us/step - loss: 0.1303 - acc: 0.9767 - recall: 0.9376 - fbeta_score: 0.9553 - val_loss: 0.1983 - val_acc: 0.9561 - val_recall: 0.9415 - val_fbeta_score: 0.9436\n",
      "Epoch 339/500\n",
      "1843/1843 [==============================] - 0s 268us/step - loss: 0.1141 - acc: 0.9805 - recall: 0.9224 - fbeta_score: 0.9496 - val_loss: 0.1878 - val_acc: 0.9610 - val_recall: 0.9463 - val_fbeta_score: 0.9555\n",
      "Epoch 340/500\n",
      "1843/1843 [==============================] - 1s 313us/step - loss: 0.1210 - acc: 0.9767 - recall: 0.9088 - fbeta_score: 0.9412 - val_loss: 0.2053 - val_acc: 0.9512 - val_recall: 0.9220 - val_fbeta_score: 0.9440\n",
      "Epoch 341/500\n",
      "1843/1843 [==============================] - 1s 293us/step - loss: 0.1290 - acc: 0.9756 - recall: 0.9029 - fbeta_score: 0.9388 - val_loss: 0.2412 - val_acc: 0.9512 - val_recall: 0.9415 - val_fbeta_score: 0.9483\n",
      "Epoch 342/500\n",
      "1843/1843 [==============================] - 1s 316us/step - loss: 0.1277 - acc: 0.9702 - recall: 0.9387 - fbeta_score: 0.9546 - val_loss: 0.2128 - val_acc: 0.9561 - val_recall: 0.9561 - val_fbeta_score: 0.9563\n",
      "Epoch 343/500\n",
      "1843/1843 [==============================] - 1s 271us/step - loss: 0.1245 - acc: 0.9734 - recall: 0.9371 - fbeta_score: 0.9536 - val_loss: 0.1739 - val_acc: 0.9659 - val_recall: 0.9512 - val_fbeta_score: 0.9602\n",
      "Epoch 344/500\n",
      "1843/1843 [==============================] - 1s 284us/step - loss: 0.1151 - acc: 0.9783 - recall: 0.9414 - fbeta_score: 0.9587 - val_loss: 0.1553 - val_acc: 0.9659 - val_recall: 0.9561 - val_fbeta_score: 0.9628\n",
      "Epoch 345/500\n",
      "1843/1843 [==============================] - 1s 280us/step - loss: 0.1342 - acc: 0.9729 - recall: 0.9419 - fbeta_score: 0.9547 - val_loss: 0.1778 - val_acc: 0.9561 - val_recall: 0.9561 - val_fbeta_score: 0.9584\n",
      "Epoch 346/500\n",
      "1843/1843 [==============================] - 1s 279us/step - loss: 0.1219 - acc: 0.9767 - recall: 0.9414 - fbeta_score: 0.9576 - val_loss: 0.1801 - val_acc: 0.9561 - val_recall: 0.9561 - val_fbeta_score: 0.9560\n",
      "Epoch 347/500\n",
      "1843/1843 [==============================] - 0s 269us/step - loss: 0.1197 - acc: 0.9734 - recall: 0.9365 - fbeta_score: 0.9542 - val_loss: 0.2008 - val_acc: 0.9561 - val_recall: 0.9463 - val_fbeta_score: 0.9530\n",
      "Epoch 348/500\n",
      "1843/1843 [==============================] - 0s 270us/step - loss: 0.1207 - acc: 0.9761 - recall: 0.9327 - fbeta_score: 0.9531 - val_loss: 0.1961 - val_acc: 0.9659 - val_recall: 0.9317 - val_fbeta_score: 0.9491\n",
      "Epoch 349/500\n",
      "1843/1843 [==============================] - 1s 281us/step - loss: 0.1239 - acc: 0.9772 - recall: 0.9273 - fbeta_score: 0.9506 - val_loss: 0.2074 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9481\n",
      "Epoch 350/500\n",
      "1843/1843 [==============================] - 1s 366us/step - loss: 0.1191 - acc: 0.9712 - recall: 0.9230 - fbeta_score: 0.9489 - val_loss: 0.1895 - val_acc: 0.9512 - val_recall: 0.9415 - val_fbeta_score: 0.9481\n",
      "Epoch 351/500\n",
      "1843/1843 [==============================] - 1s 286us/step - loss: 0.1123 - acc: 0.9772 - recall: 0.9327 - fbeta_score: 0.9539 - val_loss: 0.2013 - val_acc: 0.9659 - val_recall: 0.9463 - val_fbeta_score: 0.9555\n",
      "Epoch 352/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.1142 - acc: 0.9761 - recall: 0.9376 - fbeta_score: 0.9558 - val_loss: 0.2031 - val_acc: 0.9610 - val_recall: 0.9317 - val_fbeta_score: 0.9474\n",
      "Epoch 353/500\n",
      "1843/1843 [==============================] - 0s 244us/step - loss: 0.1208 - acc: 0.9740 - recall: 0.9398 - fbeta_score: 0.9560 - val_loss: 0.2039 - val_acc: 0.9512 - val_recall: 0.9268 - val_fbeta_score: 0.9425\n",
      "Epoch 354/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.1192 - acc: 0.9750 - recall: 0.9327 - fbeta_score: 0.9517 - val_loss: 0.1790 - val_acc: 0.9610 - val_recall: 0.9512 - val_fbeta_score: 0.9558\n",
      "Epoch 355/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1208 - acc: 0.9707 - recall: 0.9322 - fbeta_score: 0.9497 - val_loss: 0.1724 - val_acc: 0.9659 - val_recall: 0.9659 - val_fbeta_score: 0.9569\n",
      "Epoch 356/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.1305 - acc: 0.9761 - recall: 0.9284 - fbeta_score: 0.9508 - val_loss: 0.1942 - val_acc: 0.9610 - val_recall: 0.9512 - val_fbeta_score: 0.9517\n",
      "Epoch 357/500\n",
      "1843/1843 [==============================] - 1s 354us/step - loss: 0.1205 - acc: 0.9740 - recall: 0.9360 - fbeta_score: 0.9503 - val_loss: 0.1868 - val_acc: 0.9610 - val_recall: 0.9268 - val_fbeta_score: 0.9437\n",
      "Epoch 358/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1147 - acc: 0.9767 - recall: 0.9371 - fbeta_score: 0.9585 - val_loss: 0.2124 - val_acc: 0.9561 - val_recall: 0.9268 - val_fbeta_score: 0.9422\n",
      "Epoch 359/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.1247 - acc: 0.9734 - recall: 0.9251 - fbeta_score: 0.9484 - val_loss: 0.1719 - val_acc: 0.9610 - val_recall: 0.9366 - val_fbeta_score: 0.9546\n",
      "Epoch 360/500\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.1196 - acc: 0.9756 - recall: 0.9116 - fbeta_score: 0.9439 - val_loss: 0.1884 - val_acc: 0.9561 - val_recall: 0.9366 - val_fbeta_score: 0.9453\n",
      "Epoch 361/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.1181 - acc: 0.9750 - recall: 0.9159 - fbeta_score: 0.9443 - val_loss: 0.1710 - val_acc: 0.9561 - val_recall: 0.9561 - val_fbeta_score: 0.9493\n",
      "Epoch 362/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1118 - acc: 0.9767 - recall: 0.9300 - fbeta_score: 0.9541 - val_loss: 0.2009 - val_acc: 0.9512 - val_recall: 0.9317 - val_fbeta_score: 0.9427\n",
      "Epoch 363/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1107 - acc: 0.9778 - recall: 0.9327 - fbeta_score: 0.9552 - val_loss: 0.2187 - val_acc: 0.9610 - val_recall: 0.8390 - val_fbeta_score: 0.8935\n",
      "Epoch 364/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1172 - acc: 0.9778 - recall: 0.9213 - fbeta_score: 0.9487 - val_loss: 0.2099 - val_acc: 0.9561 - val_recall: 0.9220 - val_fbeta_score: 0.9374\n",
      "Epoch 365/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1251 - acc: 0.9734 - recall: 0.9251 - fbeta_score: 0.9471 - val_loss: 0.2132 - val_acc: 0.9512 - val_recall: 0.9415 - val_fbeta_score: 0.9435\n",
      "Epoch 366/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1255 - acc: 0.9740 - recall: 0.9403 - fbeta_score: 0.9548 - val_loss: 0.1956 - val_acc: 0.9561 - val_recall: 0.9317 - val_fbeta_score: 0.9412\n",
      "Epoch 367/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1190 - acc: 0.9767 - recall: 0.9322 - fbeta_score: 0.9548 - val_loss: 0.1989 - val_acc: 0.9561 - val_recall: 0.8927 - val_fbeta_score: 0.9191\n",
      "Epoch 368/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1146 - acc: 0.9750 - recall: 0.9365 - fbeta_score: 0.9532 - val_loss: 0.1790 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9525\n",
      "Epoch 369/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1173 - acc: 0.9767 - recall: 0.9219 - fbeta_score: 0.9462 - val_loss: 0.1850 - val_acc: 0.9659 - val_recall: 0.9073 - val_fbeta_score: 0.9370\n",
      "Epoch 370/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1187 - acc: 0.9761 - recall: 0.9072 - fbeta_score: 0.9427 - val_loss: 0.2074 - val_acc: 0.9561 - val_recall: 0.9268 - val_fbeta_score: 0.9443\n",
      "Epoch 371/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1259 - acc: 0.9740 - recall: 0.9061 - fbeta_score: 0.9389 - val_loss: 0.1874 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9435\n",
      "Epoch 372/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1165 - acc: 0.9745 - recall: 0.9251 - fbeta_score: 0.9481 - val_loss: 0.1742 - val_acc: 0.9610 - val_recall: 0.9463 - val_fbeta_score: 0.9553\n",
      "Epoch 373/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1104 - acc: 0.9745 - recall: 0.9447 - fbeta_score: 0.9606 - val_loss: 0.1826 - val_acc: 0.9463 - val_recall: 0.9463 - val_fbeta_score: 0.9465\n",
      "Epoch 374/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1224 - acc: 0.9723 - recall: 0.9409 - fbeta_score: 0.9563 - val_loss: 0.2218 - val_acc: 0.9610 - val_recall: 0.9268 - val_fbeta_score: 0.9417\n",
      "Epoch 375/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1283 - acc: 0.9723 - recall: 0.9322 - fbeta_score: 0.9524 - val_loss: 0.2291 - val_acc: 0.9561 - val_recall: 0.8927 - val_fbeta_score: 0.9201\n",
      "Epoch 376/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1164 - acc: 0.9756 - recall: 0.9295 - fbeta_score: 0.9486 - val_loss: 0.2403 - val_acc: 0.9610 - val_recall: 0.9561 - val_fbeta_score: 0.9584\n",
      "Epoch 377/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1171 - acc: 0.9783 - recall: 0.9365 - fbeta_score: 0.9553 - val_loss: 0.1988 - val_acc: 0.9512 - val_recall: 0.9610 - val_fbeta_score: 0.9498\n",
      "Epoch 378/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1148 - acc: 0.9740 - recall: 0.9560 - fbeta_score: 0.9626 - val_loss: 0.1904 - val_acc: 0.9610 - val_recall: 0.9512 - val_fbeta_score: 0.9535\n",
      "Epoch 379/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1250 - acc: 0.9750 - recall: 0.9566 - fbeta_score: 0.9625 - val_loss: 0.1885 - val_acc: 0.9561 - val_recall: 0.9512 - val_fbeta_score: 0.9579\n",
      "Epoch 380/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1170 - acc: 0.9740 - recall: 0.9316 - fbeta_score: 0.9548 - val_loss: 0.2101 - val_acc: 0.9512 - val_recall: 0.9463 - val_fbeta_score: 0.9442\n",
      "Epoch 381/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1152 - acc: 0.9761 - recall: 0.9403 - fbeta_score: 0.9585 - val_loss: 0.2177 - val_acc: 0.9561 - val_recall: 0.9220 - val_fbeta_score: 0.9394\n",
      "Epoch 382/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1122 - acc: 0.9767 - recall: 0.9441 - fbeta_score: 0.9596 - val_loss: 0.2093 - val_acc: 0.9610 - val_recall: 0.9366 - val_fbeta_score: 0.9476\n",
      "Epoch 383/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1164 - acc: 0.9783 - recall: 0.9387 - fbeta_score: 0.9585 - val_loss: 0.1802 - val_acc: 0.9610 - val_recall: 0.9659 - val_fbeta_score: 0.9638\n",
      "Epoch 384/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1104 - acc: 0.9767 - recall: 0.9409 - fbeta_score: 0.9560 - val_loss: 0.1814 - val_acc: 0.9610 - val_recall: 0.9659 - val_fbeta_score: 0.9681\n",
      "Epoch 385/500\n",
      "1843/1843 [==============================] - 0s 236us/step - loss: 0.1129 - acc: 0.9788 - recall: 0.9333 - fbeta_score: 0.9544 - val_loss: 0.2128 - val_acc: 0.9366 - val_recall: 0.9220 - val_fbeta_score: 0.9336\n",
      "Epoch 386/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1202 - acc: 0.9740 - recall: 0.9305 - fbeta_score: 0.9516 - val_loss: 0.2114 - val_acc: 0.9561 - val_recall: 0.9512 - val_fbeta_score: 0.9537\n",
      "Epoch 387/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1107 - acc: 0.9745 - recall: 0.9208 - fbeta_score: 0.9489 - val_loss: 0.2055 - val_acc: 0.9610 - val_recall: 0.9463 - val_fbeta_score: 0.9555\n",
      "Epoch 388/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1305 - acc: 0.9750 - recall: 0.9333 - fbeta_score: 0.9528 - val_loss: 0.2404 - val_acc: 0.9512 - val_recall: 0.9415 - val_fbeta_score: 0.9461\n",
      "Epoch 389/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1124 - acc: 0.9756 - recall: 0.9159 - fbeta_score: 0.9453 - val_loss: 0.2297 - val_acc: 0.9512 - val_recall: 0.9220 - val_fbeta_score: 0.9340\n",
      "Epoch 390/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1200 - acc: 0.9740 - recall: 0.9365 - fbeta_score: 0.9566 - val_loss: 0.1806 - val_acc: 0.9610 - val_recall: 0.9610 - val_fbeta_score: 0.9525\n",
      "Epoch 391/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1289 - acc: 0.9707 - recall: 0.9403 - fbeta_score: 0.9547 - val_loss: 0.2451 - val_acc: 0.9512 - val_recall: 0.9415 - val_fbeta_score: 0.9458\n",
      "Epoch 392/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1209 - acc: 0.9740 - recall: 0.9246 - fbeta_score: 0.9472 - val_loss: 0.1879 - val_acc: 0.9610 - val_recall: 0.9463 - val_fbeta_score: 0.9550\n",
      "Epoch 393/500\n",
      "1843/1843 [==============================] - 0s 242us/step - loss: 0.1111 - acc: 0.9761 - recall: 0.9240 - fbeta_score: 0.9495 - val_loss: 0.1814 - val_acc: 0.9659 - val_recall: 0.9561 - val_fbeta_score: 0.9607\n",
      "Epoch 394/500\n",
      "1843/1843 [==============================] - 0s 242us/step - loss: 0.1185 - acc: 0.9734 - recall: 0.9305 - fbeta_score: 0.9511 - val_loss: 0.2017 - val_acc: 0.9561 - val_recall: 0.8976 - val_fbeta_score: 0.9247\n",
      "Epoch 395/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.1102 - acc: 0.9767 - recall: 0.9213 - fbeta_score: 0.9506 - val_loss: 0.2329 - val_acc: 0.9610 - val_recall: 0.9073 - val_fbeta_score: 0.9355\n",
      "Epoch 396/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1170 - acc: 0.9767 - recall: 0.9121 - fbeta_score: 0.9449 - val_loss: 0.1952 - val_acc: 0.9561 - val_recall: 0.9171 - val_fbeta_score: 0.9345\n",
      "Epoch 397/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.1240 - acc: 0.9750 - recall: 0.9295 - fbeta_score: 0.9516 - val_loss: 0.1986 - val_acc: 0.9561 - val_recall: 0.8732 - val_fbeta_score: 0.9086\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1198 - acc: 0.9740 - recall: 0.9289 - fbeta_score: 0.9499 - val_loss: 0.1828 - val_acc: 0.9561 - val_recall: 0.9415 - val_fbeta_score: 0.9391\n",
      "Epoch 399/500\n",
      "1843/1843 [==============================] - 0s 216us/step - loss: 0.1037 - acc: 0.9810 - recall: 0.9425 - fbeta_score: 0.9613 - val_loss: 0.1703 - val_acc: 0.9707 - val_recall: 0.9463 - val_fbeta_score: 0.9574\n",
      "Epoch 400/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1159 - acc: 0.9794 - recall: 0.9300 - fbeta_score: 0.9551 - val_loss: 0.1998 - val_acc: 0.9561 - val_recall: 0.9268 - val_fbeta_score: 0.9398\n",
      "Epoch 401/500\n",
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1170 - acc: 0.9767 - recall: 0.9197 - fbeta_score: 0.9490 - val_loss: 0.1753 - val_acc: 0.9561 - val_recall: 0.9317 - val_fbeta_score: 0.9496\n",
      "Epoch 402/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1140 - acc: 0.9794 - recall: 0.9300 - fbeta_score: 0.9522 - val_loss: 0.1992 - val_acc: 0.9463 - val_recall: 0.9268 - val_fbeta_score: 0.9468\n",
      "Epoch 403/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1054 - acc: 0.9799 - recall: 0.9398 - fbeta_score: 0.9592 - val_loss: 0.2174 - val_acc: 0.9512 - val_recall: 0.9268 - val_fbeta_score: 0.9443\n",
      "Epoch 404/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1076 - acc: 0.9783 - recall: 0.9267 - fbeta_score: 0.9511 - val_loss: 0.1798 - val_acc: 0.9659 - val_recall: 0.9317 - val_fbeta_score: 0.9494\n",
      "Epoch 405/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1117 - acc: 0.9734 - recall: 0.9311 - fbeta_score: 0.9513 - val_loss: 0.1754 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9458\n",
      "Epoch 406/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1156 - acc: 0.9718 - recall: 0.9349 - fbeta_score: 0.9522 - val_loss: 0.1833 - val_acc: 0.9561 - val_recall: 0.9659 - val_fbeta_score: 0.9569\n",
      "Epoch 407/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1075 - acc: 0.9794 - recall: 0.9349 - fbeta_score: 0.9554 - val_loss: 0.1740 - val_acc: 0.9659 - val_recall: 0.9415 - val_fbeta_score: 0.9551\n",
      "Epoch 408/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1153 - acc: 0.9783 - recall: 0.9219 - fbeta_score: 0.9494 - val_loss: 0.2026 - val_acc: 0.9512 - val_recall: 0.8976 - val_fbeta_score: 0.9300\n",
      "Epoch 409/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1245 - acc: 0.9745 - recall: 0.9061 - fbeta_score: 0.9401 - val_loss: 0.1783 - val_acc: 0.9610 - val_recall: 0.9707 - val_fbeta_score: 0.9400\n",
      "Epoch 410/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1224 - acc: 0.9734 - recall: 0.9240 - fbeta_score: 0.9482 - val_loss: 0.1970 - val_acc: 0.9610 - val_recall: 0.9268 - val_fbeta_score: 0.9485\n",
      "Epoch 411/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1209 - acc: 0.9734 - recall: 0.9240 - fbeta_score: 0.9488 - val_loss: 0.1851 - val_acc: 0.9610 - val_recall: 0.9463 - val_fbeta_score: 0.9534\n",
      "Epoch 412/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1172 - acc: 0.9761 - recall: 0.9371 - fbeta_score: 0.9554 - val_loss: 0.1881 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9525\n",
      "Epoch 413/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1130 - acc: 0.9772 - recall: 0.9381 - fbeta_score: 0.9544 - val_loss: 0.1857 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9499\n",
      "Epoch 414/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1107 - acc: 0.9772 - recall: 0.9343 - fbeta_score: 0.9564 - val_loss: 0.2061 - val_acc: 0.9561 - val_recall: 0.9415 - val_fbeta_score: 0.9411\n",
      "Epoch 415/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1224 - acc: 0.9767 - recall: 0.9311 - fbeta_score: 0.9510 - val_loss: 0.2189 - val_acc: 0.9512 - val_recall: 0.8732 - val_fbeta_score: 0.9083\n",
      "Epoch 416/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1313 - acc: 0.9696 - recall: 0.9202 - fbeta_score: 0.9426 - val_loss: 0.2172 - val_acc: 0.9512 - val_recall: 0.8976 - val_fbeta_score: 0.9214\n",
      "Epoch 417/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1187 - acc: 0.9718 - recall: 0.9257 - fbeta_score: 0.9487 - val_loss: 0.1758 - val_acc: 0.9756 - val_recall: 0.9512 - val_fbeta_score: 0.9601\n",
      "Epoch 418/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1101 - acc: 0.9783 - recall: 0.9267 - fbeta_score: 0.9496 - val_loss: 0.2440 - val_acc: 0.9463 - val_recall: 0.9073 - val_fbeta_score: 0.9250\n",
      "Epoch 419/500\n",
      "1843/1843 [==============================] - 0s 254us/step - loss: 0.1170 - acc: 0.9761 - recall: 0.9273 - fbeta_score: 0.9497 - val_loss: 0.1903 - val_acc: 0.9610 - val_recall: 0.9463 - val_fbeta_score: 0.9555\n",
      "Epoch 420/500\n",
      "1843/1843 [==============================] - 0s 260us/step - loss: 0.1104 - acc: 0.9734 - recall: 0.9273 - fbeta_score: 0.9494 - val_loss: 0.1786 - val_acc: 0.9707 - val_recall: 0.9610 - val_fbeta_score: 0.9635\n",
      "Epoch 421/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1133 - acc: 0.9772 - recall: 0.9495 - fbeta_score: 0.9627 - val_loss: 0.1979 - val_acc: 0.9512 - val_recall: 0.9268 - val_fbeta_score: 0.9404\n",
      "Epoch 422/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.1125 - acc: 0.9761 - recall: 0.9311 - fbeta_score: 0.9513 - val_loss: 0.1818 - val_acc: 0.9610 - val_recall: 0.9561 - val_fbeta_score: 0.9563\n",
      "Epoch 423/500\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.1110 - acc: 0.9772 - recall: 0.9376 - fbeta_score: 0.9564 - val_loss: 0.1676 - val_acc: 0.9707 - val_recall: 0.9561 - val_fbeta_score: 0.9609\n",
      "Epoch 424/500\n",
      "1843/1843 [==============================] - 0s 257us/step - loss: 0.1178 - acc: 0.9734 - recall: 0.9425 - fbeta_score: 0.9578 - val_loss: 0.2519 - val_acc: 0.9512 - val_recall: 0.8780 - val_fbeta_score: 0.9055\n",
      "Epoch 425/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1211 - acc: 0.9761 - recall: 0.9381 - fbeta_score: 0.9554 - val_loss: 0.1754 - val_acc: 0.9659 - val_recall: 0.9561 - val_fbeta_score: 0.9627\n",
      "Epoch 426/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.1190 - acc: 0.9767 - recall: 0.9457 - fbeta_score: 0.9611 - val_loss: 0.1789 - val_acc: 0.9659 - val_recall: 0.9463 - val_fbeta_score: 0.9555\n",
      "Epoch 427/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1105 - acc: 0.9772 - recall: 0.9490 - fbeta_score: 0.9594 - val_loss: 0.1965 - val_acc: 0.9659 - val_recall: 0.9366 - val_fbeta_score: 0.9499\n",
      "Epoch 428/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1181 - acc: 0.9745 - recall: 0.9403 - fbeta_score: 0.9593 - val_loss: 0.2057 - val_acc: 0.9659 - val_recall: 0.9463 - val_fbeta_score: 0.9599\n",
      "Epoch 429/500\n",
      "1843/1843 [==============================] - 0s 242us/step - loss: 0.1170 - acc: 0.9729 - recall: 0.9403 - fbeta_score: 0.9543 - val_loss: 0.2143 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9435\n",
      "Epoch 430/500\n",
      "1843/1843 [==============================] - 0s 248us/step - loss: 0.1033 - acc: 0.9810 - recall: 0.9338 - fbeta_score: 0.9568 - val_loss: 0.1912 - val_acc: 0.9610 - val_recall: 0.9220 - val_fbeta_score: 0.9442\n",
      "Epoch 431/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.1132 - acc: 0.9745 - recall: 0.9273 - fbeta_score: 0.9524 - val_loss: 0.1843 - val_acc: 0.9561 - val_recall: 0.9463 - val_fbeta_score: 0.9532\n",
      "Epoch 432/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1070 - acc: 0.9778 - recall: 0.9327 - fbeta_score: 0.9542 - val_loss: 0.2052 - val_acc: 0.9463 - val_recall: 0.9366 - val_fbeta_score: 0.9504\n",
      "Epoch 433/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.1115 - acc: 0.9788 - recall: 0.9414 - fbeta_score: 0.9593 - val_loss: 0.2211 - val_acc: 0.9512 - val_recall: 0.9317 - val_fbeta_score: 0.9401\n",
      "Epoch 434/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 224us/step - loss: 0.1182 - acc: 0.9745 - recall: 0.9338 - fbeta_score: 0.9502 - val_loss: 0.2014 - val_acc: 0.9561 - val_recall: 0.9512 - val_fbeta_score: 0.9579\n",
      "Epoch 435/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1128 - acc: 0.9767 - recall: 0.9392 - fbeta_score: 0.9583 - val_loss: 0.2273 - val_acc: 0.9561 - val_recall: 0.9366 - val_fbeta_score: 0.9499\n",
      "Epoch 436/500\n",
      "1843/1843 [==============================] - 0s 225us/step - loss: 0.1105 - acc: 0.9734 - recall: 0.9273 - fbeta_score: 0.9496 - val_loss: 0.1879 - val_acc: 0.9561 - val_recall: 0.9512 - val_fbeta_score: 0.9537\n",
      "Epoch 437/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1159 - acc: 0.9778 - recall: 0.9267 - fbeta_score: 0.9501 - val_loss: 0.2057 - val_acc: 0.9561 - val_recall: 0.9366 - val_fbeta_score: 0.9450\n",
      "Epoch 438/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1058 - acc: 0.9772 - recall: 0.9208 - fbeta_score: 0.9488 - val_loss: 0.2328 - val_acc: 0.9561 - val_recall: 0.8976 - val_fbeta_score: 0.9207\n",
      "Epoch 439/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1040 - acc: 0.9810 - recall: 0.9365 - fbeta_score: 0.9569 - val_loss: 0.1783 - val_acc: 0.9561 - val_recall: 0.9512 - val_fbeta_score: 0.9602\n",
      "Epoch 440/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1051 - acc: 0.9799 - recall: 0.9338 - fbeta_score: 0.9546 - val_loss: 0.1890 - val_acc: 0.9659 - val_recall: 0.9415 - val_fbeta_score: 0.9550\n",
      "Epoch 441/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1074 - acc: 0.9772 - recall: 0.9479 - fbeta_score: 0.9628 - val_loss: 0.2425 - val_acc: 0.9415 - val_recall: 0.9366 - val_fbeta_score: 0.9497\n",
      "Epoch 442/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1199 - acc: 0.9778 - recall: 0.9539 - fbeta_score: 0.9654 - val_loss: 0.2158 - val_acc: 0.9610 - val_recall: 0.9366 - val_fbeta_score: 0.9522\n",
      "Epoch 443/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1046 - acc: 0.9810 - recall: 0.9360 - fbeta_score: 0.9582 - val_loss: 0.1974 - val_acc: 0.9561 - val_recall: 0.9366 - val_fbeta_score: 0.9522\n",
      "Epoch 444/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1135 - acc: 0.9761 - recall: 0.9403 - fbeta_score: 0.9583 - val_loss: 0.2218 - val_acc: 0.9512 - val_recall: 0.9463 - val_fbeta_score: 0.9487\n",
      "Epoch 445/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1088 - acc: 0.9816 - recall: 0.9202 - fbeta_score: 0.9499 - val_loss: 0.1842 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9501\n",
      "Epoch 446/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1099 - acc: 0.9723 - recall: 0.9170 - fbeta_score: 0.9465 - val_loss: 0.1994 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9478\n",
      "Epoch 447/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1069 - acc: 0.9778 - recall: 0.9137 - fbeta_score: 0.9444 - val_loss: 0.2101 - val_acc: 0.9659 - val_recall: 0.9220 - val_fbeta_score: 0.9445\n",
      "Epoch 448/500\n",
      "1843/1843 [==============================] - 0s 219us/step - loss: 0.1156 - acc: 0.9756 - recall: 0.9273 - fbeta_score: 0.9511 - val_loss: 0.2022 - val_acc: 0.9756 - val_recall: 0.9610 - val_fbeta_score: 0.9653\n",
      "Epoch 449/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1262 - acc: 0.9729 - recall: 0.9181 - fbeta_score: 0.9471 - val_loss: 0.2112 - val_acc: 0.9659 - val_recall: 0.9220 - val_fbeta_score: 0.9411\n",
      "Epoch 450/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1245 - acc: 0.9729 - recall: 0.9164 - fbeta_score: 0.9453 - val_loss: 0.2019 - val_acc: 0.9610 - val_recall: 0.9220 - val_fbeta_score: 0.9419\n",
      "Epoch 451/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1169 - acc: 0.9740 - recall: 0.9311 - fbeta_score: 0.9524 - val_loss: 0.2021 - val_acc: 0.9561 - val_recall: 0.9366 - val_fbeta_score: 0.9499\n",
      "Epoch 452/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1152 - acc: 0.9772 - recall: 0.9295 - fbeta_score: 0.9524 - val_loss: 0.1816 - val_acc: 0.9610 - val_recall: 0.9512 - val_fbeta_score: 0.9581\n",
      "Epoch 453/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1120 - acc: 0.9756 - recall: 0.9425 - fbeta_score: 0.9586 - val_loss: 0.1703 - val_acc: 0.9707 - val_recall: 0.9659 - val_fbeta_score: 0.9661\n",
      "Epoch 454/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1142 - acc: 0.9821 - recall: 0.9501 - fbeta_score: 0.9657 - val_loss: 0.1890 - val_acc: 0.9561 - val_recall: 0.9512 - val_fbeta_score: 0.9535\n",
      "Epoch 455/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.1072 - acc: 0.9778 - recall: 0.9430 - fbeta_score: 0.9607 - val_loss: 0.1910 - val_acc: 0.9463 - val_recall: 0.9366 - val_fbeta_score: 0.9522\n",
      "Epoch 456/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1157 - acc: 0.9772 - recall: 0.9495 - fbeta_score: 0.9628 - val_loss: 0.2414 - val_acc: 0.9463 - val_recall: 0.9268 - val_fbeta_score: 0.9360\n",
      "Epoch 457/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1209 - acc: 0.9707 - recall: 0.9295 - fbeta_score: 0.9527 - val_loss: 0.2362 - val_acc: 0.9561 - val_recall: 0.9512 - val_fbeta_score: 0.9376\n",
      "Epoch 458/500\n",
      "1843/1843 [==============================] - 0s 265us/step - loss: 0.1085 - acc: 0.9756 - recall: 0.9550 - fbeta_score: 0.9635 - val_loss: 0.1945 - val_acc: 0.9561 - val_recall: 0.9366 - val_fbeta_score: 0.9458\n",
      "Epoch 459/500\n",
      "1843/1843 [==============================] - 0s 240us/step - loss: 0.1115 - acc: 0.9799 - recall: 0.9463 - fbeta_score: 0.9624 - val_loss: 0.1755 - val_acc: 0.9610 - val_recall: 0.9317 - val_fbeta_score: 0.9492\n",
      "Epoch 460/500\n",
      "1843/1843 [==============================] - 1s 303us/step - loss: 0.1127 - acc: 0.9794 - recall: 0.9235 - fbeta_score: 0.9521 - val_loss: 0.1704 - val_acc: 0.9707 - val_recall: 0.9415 - val_fbeta_score: 0.9571\n",
      "Epoch 461/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1098 - acc: 0.9761 - recall: 0.9376 - fbeta_score: 0.9569 - val_loss: 0.2007 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9499\n",
      "Epoch 462/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1137 - acc: 0.9778 - recall: 0.9506 - fbeta_score: 0.9651 - val_loss: 0.1947 - val_acc: 0.9610 - val_recall: 0.9512 - val_fbeta_score: 0.9558\n",
      "Epoch 463/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1078 - acc: 0.9794 - recall: 0.9550 - fbeta_score: 0.9661 - val_loss: 0.2135 - val_acc: 0.9659 - val_recall: 0.9366 - val_fbeta_score: 0.9499\n",
      "Epoch 464/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1183 - acc: 0.9761 - recall: 0.9376 - fbeta_score: 0.9567 - val_loss: 0.3093 - val_acc: 0.9024 - val_recall: 0.8341 - val_fbeta_score: 0.8694\n",
      "Epoch 465/500\n",
      "1843/1843 [==============================] - 0s 237us/step - loss: 0.1248 - acc: 0.9718 - recall: 0.9447 - fbeta_score: 0.9583 - val_loss: 0.2467 - val_acc: 0.9463 - val_recall: 0.9220 - val_fbeta_score: 0.9408\n",
      "Epoch 466/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1113 - acc: 0.9778 - recall: 0.9371 - fbeta_score: 0.9592 - val_loss: 0.2025 - val_acc: 0.9610 - val_recall: 0.9366 - val_fbeta_score: 0.9540\n",
      "Epoch 467/500\n",
      "1843/1843 [==============================] - 0s 246us/step - loss: 0.1165 - acc: 0.9761 - recall: 0.9181 - fbeta_score: 0.9473 - val_loss: 0.2163 - val_acc: 0.9512 - val_recall: 0.9415 - val_fbeta_score: 0.9481\n",
      "Epoch 468/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1115 - acc: 0.9805 - recall: 0.9403 - fbeta_score: 0.9603 - val_loss: 0.1945 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9571\n",
      "Epoch 469/500\n",
      "1843/1843 [==============================] - 0s 245us/step - loss: 0.1247 - acc: 0.9691 - recall: 0.9343 - fbeta_score: 0.9522 - val_loss: 0.2056 - val_acc: 0.9512 - val_recall: 0.9171 - val_fbeta_score: 0.9342\n",
      "Epoch 470/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1103 - acc: 0.9756 - recall: 0.9360 - fbeta_score: 0.9562 - val_loss: 0.1984 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9542\n",
      "Epoch 471/500\n",
      "1843/1843 [==============================] - 0s 226us/step - loss: 0.1099 - acc: 0.9788 - recall: 0.9485 - fbeta_score: 0.9633 - val_loss: 0.1926 - val_acc: 0.9707 - val_recall: 0.9512 - val_fbeta_score: 0.9579\n",
      "Epoch 472/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1129 - acc: 0.9783 - recall: 0.9441 - fbeta_score: 0.9598 - val_loss: 0.1597 - val_acc: 0.9659 - val_recall: 0.9659 - val_fbeta_score: 0.9704\n",
      "Epoch 473/500\n",
      "1843/1843 [==============================] - 0s 221us/step - loss: 0.0999 - acc: 0.9837 - recall: 0.9512 - fbeta_score: 0.9671 - val_loss: 0.2025 - val_acc: 0.9659 - val_recall: 0.9220 - val_fbeta_score: 0.9411\n",
      "Epoch 474/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1232 - acc: 0.9745 - recall: 0.9224 - fbeta_score: 0.9501 - val_loss: 0.1976 - val_acc: 0.9610 - val_recall: 0.9463 - val_fbeta_score: 0.9556\n",
      "Epoch 475/500\n",
      "1843/1843 [==============================] - 0s 223us/step - loss: 0.1109 - acc: 0.9772 - recall: 0.9376 - fbeta_score: 0.9571 - val_loss: 0.2323 - val_acc: 0.9512 - val_recall: 0.9171 - val_fbeta_score: 0.9362\n",
      "Epoch 476/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1095 - acc: 0.9767 - recall: 0.9409 - fbeta_score: 0.9600 - val_loss: 0.2181 - val_acc: 0.9561 - val_recall: 0.9317 - val_fbeta_score: 0.9497\n",
      "Epoch 477/500\n",
      "1843/1843 [==============================] - 0s 228us/step - loss: 0.1131 - acc: 0.9788 - recall: 0.9360 - fbeta_score: 0.9572 - val_loss: 0.1737 - val_acc: 0.9707 - val_recall: 0.9415 - val_fbeta_score: 0.9546\n",
      "Epoch 478/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1189 - acc: 0.9729 - recall: 0.9419 - fbeta_score: 0.9563 - val_loss: 0.1930 - val_acc: 0.9610 - val_recall: 0.9317 - val_fbeta_score: 0.9424\n",
      "Epoch 479/500\n",
      "1843/1843 [==============================] - 0s 243us/step - loss: 0.1079 - acc: 0.9778 - recall: 0.9479 - fbeta_score: 0.9627 - val_loss: 0.1650 - val_acc: 0.9610 - val_recall: 0.9610 - val_fbeta_score: 0.9567\n",
      "Epoch 480/500\n",
      "1843/1843 [==============================] - 0s 256us/step - loss: 0.1249 - acc: 0.9702 - recall: 0.9387 - fbeta_score: 0.9550 - val_loss: 0.2158 - val_acc: 0.9659 - val_recall: 0.9561 - val_fbeta_score: 0.9497\n",
      "Epoch 481/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1199 - acc: 0.9767 - recall: 0.9349 - fbeta_score: 0.9549 - val_loss: 0.2026 - val_acc: 0.9512 - val_recall: 0.9317 - val_fbeta_score: 0.9520\n",
      "Epoch 482/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1146 - acc: 0.9750 - recall: 0.9354 - fbeta_score: 0.9533 - val_loss: 0.2158 - val_acc: 0.9512 - val_recall: 0.9171 - val_fbeta_score: 0.9348\n",
      "Epoch 483/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1153 - acc: 0.9799 - recall: 0.9273 - fbeta_score: 0.9500 - val_loss: 0.2158 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9476\n",
      "Epoch 484/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1158 - acc: 0.9778 - recall: 0.9224 - fbeta_score: 0.9495 - val_loss: 0.1963 - val_acc: 0.9561 - val_recall: 0.8439 - val_fbeta_score: 0.8920\n",
      "Epoch 485/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1183 - acc: 0.9767 - recall: 0.9333 - fbeta_score: 0.9542 - val_loss: 0.1579 - val_acc: 0.9659 - val_recall: 0.9659 - val_fbeta_score: 0.9661\n",
      "Epoch 486/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1185 - acc: 0.9799 - recall: 0.9170 - fbeta_score: 0.9462 - val_loss: 0.1853 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9482\n",
      "Epoch 487/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1066 - acc: 0.9783 - recall: 0.9088 - fbeta_score: 0.9409 - val_loss: 0.1790 - val_acc: 0.9561 - val_recall: 0.9171 - val_fbeta_score: 0.9386\n",
      "Epoch 488/500\n",
      "1843/1843 [==============================] - 0s 233us/step - loss: 0.1060 - acc: 0.9783 - recall: 0.9289 - fbeta_score: 0.9534 - val_loss: 0.1966 - val_acc: 0.9561 - val_recall: 0.9220 - val_fbeta_score: 0.9466\n",
      "Epoch 489/500\n",
      "1843/1843 [==============================] - 0s 229us/step - loss: 0.1017 - acc: 0.9805 - recall: 0.9267 - fbeta_score: 0.9542 - val_loss: 0.3294 - val_acc: 0.8927 - val_recall: 0.7707 - val_fbeta_score: 0.8397\n",
      "Epoch 490/500\n",
      "1843/1843 [==============================] - 0s 232us/step - loss: 0.1321 - acc: 0.9669 - recall: 0.9463 - fbeta_score: 0.9549 - val_loss: 0.2388 - val_acc: 0.9610 - val_recall: 0.9610 - val_fbeta_score: 0.9586\n",
      "Epoch 491/500\n",
      "1843/1843 [==============================] - 0s 230us/step - loss: 0.1210 - acc: 0.9750 - recall: 0.9550 - fbeta_score: 0.9653 - val_loss: 0.1999 - val_acc: 0.9610 - val_recall: 0.9366 - val_fbeta_score: 0.9481\n",
      "Epoch 492/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1322 - acc: 0.9718 - recall: 0.9544 - fbeta_score: 0.9628 - val_loss: 0.2204 - val_acc: 0.9512 - val_recall: 0.9366 - val_fbeta_score: 0.9456\n",
      "Epoch 493/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1179 - acc: 0.9761 - recall: 0.9463 - fbeta_score: 0.9638 - val_loss: 0.2023 - val_acc: 0.9512 - val_recall: 0.9317 - val_fbeta_score: 0.9451\n",
      "Epoch 494/500\n",
      "1843/1843 [==============================] - 0s 234us/step - loss: 0.1225 - acc: 0.9723 - recall: 0.9387 - fbeta_score: 0.9544 - val_loss: 0.2075 - val_acc: 0.9561 - val_recall: 0.9463 - val_fbeta_score: 0.9532\n",
      "Epoch 495/500\n",
      "1843/1843 [==============================] - 0s 231us/step - loss: 0.1247 - acc: 0.9729 - recall: 0.9479 - fbeta_score: 0.9588 - val_loss: 0.2172 - val_acc: 0.9512 - val_recall: 0.9415 - val_fbeta_score: 0.9481\n",
      "Epoch 496/500\n",
      "1843/1843 [==============================] - 0s 235us/step - loss: 0.1168 - acc: 0.9778 - recall: 0.9425 - fbeta_score: 0.9585 - val_loss: 0.2604 - val_acc: 0.9220 - val_recall: 0.9366 - val_fbeta_score: 0.9074\n",
      "Epoch 497/500\n",
      "1843/1843 [==============================] - 0s 239us/step - loss: 0.1337 - acc: 0.9740 - recall: 0.9409 - fbeta_score: 0.9578 - val_loss: 0.2033 - val_acc: 0.9610 - val_recall: 0.9463 - val_fbeta_score: 0.9509\n",
      "Epoch 498/500\n",
      "1843/1843 [==============================] - 0s 238us/step - loss: 0.1148 - acc: 0.9772 - recall: 0.9360 - fbeta_score: 0.9549 - val_loss: 0.1890 - val_acc: 0.9610 - val_recall: 0.9512 - val_fbeta_score: 0.9579\n",
      "Epoch 499/500\n",
      "1843/1843 [==============================] - 0s 227us/step - loss: 0.1276 - acc: 0.9756 - recall: 0.9419 - fbeta_score: 0.9594 - val_loss: 0.1858 - val_acc: 0.9610 - val_recall: 0.9415 - val_fbeta_score: 0.9571\n",
      "Epoch 500/500\n",
      "1843/1843 [==============================] - 0s 255us/step - loss: 0.1234 - acc: 0.9745 - recall: 0.9430 - fbeta_score: 0.9575 - val_loss: 0.1937 - val_acc: 0.9561 - val_recall: 0.9024 - val_fbeta_score: 0.9268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1916b3b6470>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp5.fit(X_scale_train, y_cat_train,\n",
    "                epochs=500,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_split=0.1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               2400      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 34,502\n",
      "Trainable params: 33,702\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Aparentemente parece que es el mejor modelo, tanto en Accuracy como en Recall, pero no tengo seguridad de que al haber dos unidades de salida el recall no sea solo calculado para una neurona o sea ponderado y no tenga en cuenta que los datos son no balanceados. En la sección 1-4 saldremos de dudas usando la Curva Roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegir qué modelo utilizar y ajustarlo no es una tarea fácil. Habitualmente se prueban modelos sencillos y se va subiendo en complejidad si los resultados no son todo lo buenos que nos gustaría. La búsqueda de meta-parámetros es un proceso complejo que habitualmente necesita de cierta experiencia y conocimiento profundo de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://scikit-learn.org/stable/modules/linear_model.html\n",
    "* http://scikit-learn.org/stable/modules/neural_network.html\n",
    "* http://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
